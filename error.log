[info] welcome to sbt 1.11.0 (Oracle Corporation Java 20.0.2)
[info] loading settings for project llm4s-build-build-build from metals.sbt...
[info] loading project definition from /Users/krrishbiswas/Desktop/GSoC/llm4s/project/project/project
[info] loading settings for project llm4s-build-build from metals.sbt...
[info] loading project definition from /Users/krrishbiswas/Desktop/GSoC/llm4s/project/project
[success] Generated .bloop/llm4s-build-build.json
[success] Total time: 1 s, completed Jan 27, 2026, 4:28:47 PM
[info] loading settings for project llm4s-build from metals.sbt, plugins.sbt...
[info] loading project definition from /Users/krrishbiswas/Desktop/GSoC/llm4s/project
[success] Generated .bloop/llm4s-build.json
[success] Total time: 0 s, completed Jan 27, 2026, 4:28:48 PM
[info] loading settings for project llm4s from build.sbt...
[info] resolving key references (12166 settings) ...
[info] set current project to llm4s (in build file:/Users/krrishbiswas/Desktop/GSoC/llm4s/)
[info] compiling 288 Scala sources to /Users/krrishbiswas/Desktop/GSoC/llm4s/modules/core/target/scala-3.7.1/classes ...
[info] done compiling
[info] compiling 1 Scala source to /Users/krrishbiswas/Desktop/GSoC/llm4s/modules/core/target/scala-3.7.1/test-classes ...
[info] done compiling
[info] ModelMetadataSpec:
[info] ModelMetadata
[info] - should parse from JSON correctly
[info] - should handle missing optional fields
[info] - should correctly identify context window
[info] - should fall back to maxOutputTokens for context window
[info] - should check capabilities correctly
[info] - should detect deprecated models
[info] - should generate a readable description
[info] ModelMode
[info] - should parse from string correctly
[info] ModelPricing
[info] - should estimate cost correctly
[info] - should estimate cost with caching
[info] - should return None for missing pricing data
[info] HistoryCompressorSpec:
[info] HistoryCompressor.compressToDigest
[info] - should keep last K blocks verbatim
[info] - should create HISTORY_SUMMARY for older blocks
[info] - should be idempotent when summaries already exist
[info] HistoryCompressor
[info] - should extract identifiers from content
[info] - should extract URLs from content
[info] - should extract error messages from content
[info] - should extract decisions from content
[info] - should consolidate multiple digests when over cap
[info] HistoryCompressor
[info] - should handle empty message list
[info] - should handle single message
[info] - should handle keepLastK = 0 (compress everything)
[info] - should handle keepLastK greater than total blocks
[info] - should handle messages with tool interactions
[info] - should preserve message order after compression
[info] Llm4sConfigEmbeddingsInputsSpec:
[info] Llm4sConfig.embeddingsInputs
[info] - should return None values when no input/query config is provided
[info] - should respect llm4s.embeddings.inputPath and llm4s.embeddings.query
[info] - should respect llm4s.embeddings.inputPaths when provided directly
[info] OpenAIClientClosedStateTest:
[info] OpenAIClient
16:29:09.311 [pool-1-thread-1-ScalaTest-running-OpenAIClientClosedStateTest] INFO  org.llm4s.model.ModelRegistry$ -- Initializing ModelRegistry with embedded metadata
16:29:09.372 [pool-1-thread-1-ScalaTest-running-OpenAIClientClosedStateTest] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry initialized with 1754 models
[info] - should return ConfigurationError when complete() is called after close()
[info] - should return ConfigurationError when streamComplete() is called after close()
[info] - should allow close() to be called multiple times (idempotent)
16:29:10.865 [pool-1-thread-1-ScalaTest-running-OpenAIClientClosedStateTest] ERROR o.l.llmconnect.provider.OpenAIClient -- OpenAI completion failed for model gpt-4
com.azure.core.exception.ClientAuthenticationException: Status code 401, "{
    "error": {
        "message": "Incorrect API key provided: test-api*************************ting. You can find your API key at https://platform.openai.com/account/api-keys.",
        "type": "invalid_request_error",
        "param": null,
        "code": "invalid_api_key"
    }
}
"
	at com.azure.core.implementation.http.rest.RestProxyBase.instantiateUnexpectedException(RestProxyBase.java:390)
	at com.azure.core.implementation.http.rest.SyncRestProxy.ensureExpectedStatus(SyncRestProxy.java:133)
	at com.azure.core.implementation.http.rest.SyncRestProxy.handleRestReturnType(SyncRestProxy.java:211)
	at com.azure.core.implementation.http.rest.SyncRestProxy.invoke(SyncRestProxy.java:86)
	at com.azure.core.implementation.http.rest.RestProxyBase.invoke(RestProxyBase.java:124)
	at com.azure.core.http.rest.RestProxy.invoke(RestProxy.java:95)
	at jdk.proxy2/jdk.proxy2.$Proxy5.getChatCompletionsSync(Unknown Source)
	at com.azure.ai.openai.implementation.NonAzureOpenAIClientImpl.getChatCompletionsWithResponse(NonAzureOpenAIClientImpl.java:994)
	at com.azure.ai.openai.OpenAIClient.getChatCompletionsWithResponse(OpenAIClient.java:348)
	at com.azure.ai.openai.OpenAIClient.getChatCompletions(OpenAIClient.java:760)
	at org.llm4s.llmconnect.provider.OpenAIClient.complete$$anonfun$1$$anonfun$2$$anonfun$1(OpenAIClient.scala:102)
	at scala.util.Try$.apply(Try.scala:217)
	at org.llm4s.llmconnect.provider.OpenAIClient.complete$$anonfun$1$$anonfun$2(OpenAIClient.scala:102)
	at scala.util.Either.flatMap(Either.scala:360)
	at org.llm4s.llmconnect.provider.OpenAIClient.complete$$anonfun$1(OpenAIClient.scala:90)
	at scala.util.Either.flatMap(Either.scala:360)
	at org.llm4s.llmconnect.provider.OpenAIClient.complete(OpenAIClient.scala:87)
	at org.llm4s.llmconnect.provider.OpenAIClientClosedStateTest.testFun$proxy4$1(OpenAIClientClosedStateTest.scala:84)
	at org.llm4s.llmconnect.provider.OpenAIClientClosedStateTest.$init$$$anonfun$4(OpenAIClientClosedStateTest.scala:79)
	at org.scalatest.Transformer.apply$$anonfun$1(Transformer.scala:22)
	at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:31)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:21)
	at org.scalatest.flatspec.AnyFlatSpecLike$$anon$5.apply(AnyFlatSpecLike.scala:1717)
	at org.scalatest.TestSuite.withFixture(TestSuite.scala:196)
	at org.scalatest.TestSuite.withFixture$(TestSuite.scala:138)
	at org.scalatest.flatspec.AnyFlatSpec.withFixture(AnyFlatSpec.scala:1685)
	at org.scalatest.flatspec.AnyFlatSpecLike.invokeWithFixture$1(AnyFlatSpecLike.scala:1723)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTest$$anonfun$1(AnyFlatSpecLike.scala:1727)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTest(AnyFlatSpecLike.scala:1727)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTest$(AnyFlatSpecLike.scala:51)
	at org.scalatest.flatspec.AnyFlatSpec.runTest(AnyFlatSpec.scala:1685)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTests$$anonfun$1(AnyFlatSpecLike.scala:1785)
	at org.scalatest.SuperEngine.traverseSubNodes$1$$anonfun$1(Engine.scala:413)
	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)
	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)
	at scala.collection.immutable.List.foreach(List.scala:334)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:429)
	at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390)
	at org.scalatest.SuperEngine.traverseSubNodes$1$$anonfun$1(Engine.scala:427)
	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)
	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)
	at scala.collection.immutable.List.foreach(List.scala:334)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:429)
	at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTests(AnyFlatSpecLike.scala:1785)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTests$(AnyFlatSpecLike.scala:51)
	at org.scalatest.flatspec.AnyFlatSpec.runTests(AnyFlatSpec.scala:1685)
	at org.scalatest.Suite.run(Suite.scala:1114)
	at org.scalatest.Suite.run$(Suite.scala:564)
	at org.scalatest.flatspec.AnyFlatSpec.org$scalatest$flatspec$AnyFlatSpecLike$$super$run(AnyFlatSpec.scala:1685)
	at org.scalatest.flatspec.AnyFlatSpecLike.run$$anonfun$1(AnyFlatSpecLike.scala:1830)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:535)
	at org.scalatest.flatspec.AnyFlatSpecLike.run(AnyFlatSpecLike.scala:1830)
	at org.scalatest.flatspec.AnyFlatSpecLike.run$(AnyFlatSpecLike.scala:51)
	at org.scalatest.flatspec.AnyFlatSpec.run(AnyFlatSpec.scala:1685)
	at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)
	at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:414)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1623)
[info] - should succeed for operations before close() is called
[info] - should include model name in the closed error message
[info] ProviderConfigLoaderIntegrationSpec:
[info] Llm4sConfig.provider
[info] - should load OpenAI config from llm4s.* and defaults
[info] LLMErrorSpec:
[info] LLMError
[info] - should use smart constructors and unapply extractors correctly
[info] - should support pattern matching for all error types
[info] - should use smart constructors for RateLimitError with cleaner call sites
[info] - should properly categorize errors with trait-based inheritance
[info] - should use improved context map construction patterns
[info] - should provide type-safe error filtering
[info] - should integrate with cats Show
[info] - should maintain backward compatibility
[info] - should create AuthenticationError with smart constructors
[info] - should properly categorize errors as recoverable/non-recoverable
[info] - should construct context maps correctly per PR review
[info] - should use smart constructors for rate limiting
[info] Type-safe error filtering
[info] - should separate recoverable from non-recoverable errors
[info] WhisperAdapterTest:
[info] - whisper adapter handles bytes input
[info] QdrantVectorStoreSpec:
[info] QdrantVectorStore
[info] - should store and retrieve a single record
[info]   + Skipping test - QDRANT_TEST_URL not set 
[info] - should return None for non-existent record
[info]   + Skipping test - QDRANT_TEST_URL not set 
[info] - should upsert (replace) existing record
[info]   + Skipping test - QDRANT_TEST_URL not set 
[info] - should store multiple records in batch
[info]   + Skipping test - QDRANT_TEST_URL not set 
[info] - should delete a record
[info]   + Skipping test - QDRANT_TEST_URL not set 
[info] - should delete multiple records in batch
[info]   + Skipping test - QDRANT_TEST_URL not set 
[info] - should clear all records
[info]   + Skipping test - QDRANT_TEST_URL not set 
[info] - should search by vector similarity
[info]   + Skipping test - QDRANT_TEST_URL not set 
[info] - should filter records by metadata
[info]   + Skipping test - QDRANT_TEST_URL not set 
[info] - should combine filters with AND/OR
[info]   + Skipping test - QDRANT_TEST_URL not set 
[info] - should return correct statistics
[info]   + Skipping test - QDRANT_TEST_URL not set 
[info] - should paginate results with list
[info]   + Skipping test - QDRANT_TEST_URL not set 
[info] - should search with metadata filter
[info]   + Skipping test - QDRANT_TEST_URL not set 
[info] QdrantVectorStore factory
[info] - should create store from config
[info]   + Skipping test - QDRANT_TEST_URL not set 
[info] HttpToolsSpec:
[info] HttpConfig
[info] - should block localhost by default
[info] - should allow external domains by default
[info] - should restrict to allowed domains when specified
[info] - should validate methods
[info] HTTPTool
[info] - should reject blocked domains
[info] - should reject disallowed methods
[info] - should reject invalid URLs
[info] - should default to GET method
[info] HttpConfig.readOnly
[info] - should only allow read methods
[info] HttpConfig.restricted
[info] - should limit to specified domains
[info] ShellToolsSpec:
[info] ShellConfig
[info] - should allow configured commands
[info] - should reject non-allowed commands
[info] - should reject all commands when allowlist is empty
[info] ShellConfig.readOnly
[info] - should allow safe read-only commands
[info] - should not allow write commands
[info] ShellConfig.development
[info] - should allow dev tools
[info] ShellTool
[info] - should execute allowed commands
[info] - should reject non-allowed commands
[info] - should capture stderr
[info] - should respect timeout
[info] - should use configured working directory
[info] - should truncate large output
[info] ImageModelsTest:
[info] ImageMetadata
[info] - should create with default values
[info] - should create with custom values
[info] ProcessedImage
[info] - should create with valid data
[info] - should save to file successfully
[info] - should fail to save with invalid path
[info] - should prevent path traversal attacks
[info] ImageAnalysisResult
[info] - should create with all fields
[info] DetectedObject
[info] - should create with bounding box
[info] DetectedEmotion
[info] - should create with emotion and confidence
[info] BoundingBox
[info] - should create with coordinates
[info] ImageEmbedding
[info] - should calculate cosine similarity
[info] - should throw exception for different dimensions
[info] ImageFormat
[info] - should have correct string representations
[info] ImageOperation
[info] - should create resize operation
[info] - should create crop operation
[info] - should create rotate operation
[info] - should create blur operation
[info] - should create brightness adjustment
[info] - should create contrast adjustment
[info] ContextWindowConfigSpec:
[info] ContextWindowConfig
[info] - should have sensible defaults
[info] - should accept custom values
[info] - should support copy with modifications
[info] - should support equality
[info] PruningStrategy.OldestFirst
[info] - should be a singleton
[info] PruningStrategy.MiddleOut
[info] - should be a singleton
[info] PruningStrategy.RecentTurnsOnly
[info] - should store turn count
[info] - should support equality based on turns
[info] PruningStrategy.Custom
[info] - should store the function
[info] - should apply the custom function correctly
[info] PruningStrategy
[info] - should be pattern matchable
[info] ContextWindowConfig
[info] - should support token-based limiting
[info] - should support message-based limiting
[info] - should support both limits together
[info] ImageGenerationTest:
[info] - ImageSize provides correct dimensions
[info] - ImageFormat provides correct metadata
[info] - ImageGenerationOptions has sensible defaults
[info] - GeneratedImage decodes base64 data correctly
[info] - GeneratedImage can save to file
[info] - ImageGeneration creates correct client for StableDiffusion config
[info] - ImageGeneration creates correct client for HuggingFace config
[info] - stableDiffusionClient creates client with correct config
[info] - huggingFaceClient creates client with correct config
[info] - Config objects have correct default values
[info] - Config objects can be customized
[info] - Mock client generates image successfully
[info] - Mock client respects custom options
[info] - Mock client validates prompts
[info] - Mock client generates multiple images
[info] - Mock client validates image count
[info] - Mock client reports healthy status
[info] - Error types have correct messages
16:29:11.214 [pool-1-thread-1-ScalaTest-running-ImageGenerationTest] INFO  o.l.i.provider.StableDiffusionClient -- Generating 1 image(s) with prompt: test prompt
[info] - generateWithStableDiffusion handles connection errors gracefully
[info] ToolRegistrySpec:
[info] ToolRegistry.empty
[info] - should create an empty registry
[info] ToolRegistry
[info] - should hold provided tools
[info] ToolRegistry.execute
[info] - should execute a tool and return result
[info] - should return error for unknown function
[info] - should return error for invalid parameters
[info] - should return error for missing parameters
[info] ToolRegistry.executeAsync
[info] - should execute a tool asynchronously
[info] - should return error asynchronously for unknown function
[info] ToolRegistry.executeAll with Sequential strategy
[info] - should execute all requests in order
[info] ToolRegistry.executeAll with Parallel strategy
[info] - should execute all requests in parallel
[info] ToolRegistry.executeAll with ParallelWithLimit strategy
[info] - should execute in batches
[info] ToolRegistry.executeAll
[info] - should use Sequential as default strategy
[info] - should handle mixed success and failure
[info] - should handle empty request list
[info] ToolRegistry.getOpenAITools
[info] - should generate OpenAI tool definitions
[info] - should respect strict parameter
[info] ToolRegistry.getToolDefinitions
[info] - should return OpenAI format for openai provider
[info] - should return OpenAI format for anthropic provider
[info] - should return OpenAI format for gemini provider
[info] - should throw exception for unsupported provider
[info] ParameterValidationTest:
[info] ToolFunction
[info] - should provide clear error message for null arguments
[info] ToolFunction
[info] - should provide clear error message for missing required parameters
[info] ToolFunction
[info] - should provide clear error message for type mismatches
[info] ToolFunction
[info] - should provide clear error message for null values in required fields
[info] SafeParameterExtractor
[info] - should provide helpful error for accessing properties on non-objects
[info] SafeParameterExtractor
[info] - should list available properties when a required one is missing
[info] SafeParameterExtractor
[info] - should show root-level keys when root parameter is missing
[info] SafeParameterExtractor
[info] - should handle nested null values gracefully
[info] SafeParameterExtractor
[info] - should show correct keys for deeply nested missing parameters
[info] ToolFunction with complex nested parameters
[info] - should provide clear path information in errors
[info] ToolCallError
[info] - should format multiple errors nicely
[info] LocalImageProcessorTest:
[info] LocalImageProcessor
[info] - should analyze image with basic information
[info] - should resize image successfully
[info] - should maintain aspect ratio when resizing
[info] - should crop image successfully
[info] - should rotate image successfully
[info] - should apply blur successfully
[info] - should adjust brightness successfully
[info] - should adjust contrast successfully
[info] - should convert to grayscale successfully
[info] - should convert format successfully
[info] - should handle multiple operations in sequence
[info] - should fail with invalid file path
[info] - should fail with invalid image file
[info] - should fail with invalid resize dimensions
[info] - should fail with invalid crop dimensions
[info] - should handle WEBP format with fallback
[info] RAGGuardrailSpec:
[info] RAGContext
[info] - should combine chunks into single context
[info] - should provide chunks with sources
[info] - should handle missing sources gracefully
[info] - should detect complete sources
[info] GroundingGuardrail
[info] - should pass when response is well-grounded
[info] - should fail when response is not grounded
[info] - should pass when score equals threshold
[info] - should include ungrounded claims in error message when present
[info] - should handle empty chunks by failing in Block mode
[info] - should pass through with empty chunks in Warn mode
[info] - should include query and chunks in LLM request
[info] - should propagate LLM client errors
[info] - should fall back to score-only parsing
[info] - should fail when LLM response is unparseable
[info] - should allow processing in Warn mode when grounding fails
[info] - should fail in Fix mode (no auto-fix for grounding)
[info] - should fail in strict mode when any ungrounded claims exist
[info] - should pass in strict mode when no ungrounded claims
[info] GroundingGuardrail.balanced
[info] - should use 0.7 threshold
[info] GroundingGuardrail.lenient
[info] - should use 0.5 threshold
[info] GroundingGuardrail.monitoring
[info] - should warn instead of blocking
[info] GroundingGuardrail.validate
[info] - should pass through without context
[info] RAGGuardrail.all
[info] - should pass when all guardrails pass
[info] - should fail when any guardrail fails
[info] - should provide descriptive name
[info] GroundingResult
[info] - should correctly represent grounded state
[info] - should correctly represent ungrounded state
[info] ContextRelevanceGuardrail
[info] - should pass when chunks are relevant
[info] - should fail when chunks are irrelevant
[info] - should handle empty chunks
[info] - should pass through without context in standard validate
[info] ContextRelevanceGuardrail.strict
[info] - should require high relevance
[info] ContextRelevanceGuardrail.monitoring
[info] - should warn instead of blocking
[info] ContextRelevanceResult
[info] - should identify relevant chunk indices
[info] SourceAttributionGuardrail
[info] - should pass when sources are cited
[info] - should fail when sources are not cited
[info] - should pass with empty chunks (no sources to attribute)
[info] - should pass when attributions not required
[info] SourceAttributionGuardrail.strict
[info] - should require high-quality attributions
[info] SourceAttributionGuardrail.optional
[info] - should allow without citations
[info] SourceAttributionResult
[info] - should correctly represent citation state
[info] TopicBoundaryGuardrail
[info] - should pass when query is on topic
[info] - should fail when query is off topic
[info] - should pass with empty allowed topics (no restrictions)
[info] - should allow in Warn mode when off-topic
[info] TopicBoundaryGuardrail.strict
[info] - should require high relevance
[info] TopicBoundaryGuardrail.softwareDevelopment
[info] - should cover common dev topics
[info] TopicBoundaryResult
[info] - should correctly represent topic match
[info] RAGGuardrails.minimal
[info] - should include basic guardrails without LLM
[info] RAGGuardrails.standard
[info] - should include balanced guardrails
[info] RAGGuardrails.strict
[info] - should include comprehensive guardrails
[info] RAGGuardrails.monitoring
[info] - should use warn mode
[info] RAGGuardrails.custom
[info] - should allow custom combinations
[info] RAGGuardrails.allGuardrails
[info] - should flatten all guardrails
[info] SentenceChunkerSpec:
[info] ChunkingConfig
[info] - should have sensible defaults
[info] - should provide small config
[info] - should provide large config
[info] - should validate configuration
[info] ChunkMetadata
[info] - should be empty by default
[info] - should support fluent API
[info] - should mark as code block
[info] DocumentChunk
[info] - should report length correctly
[info] - should detect empty content
[info] SentenceChunker
[info] - should handle empty text
[info] - should return single chunk for short text
[info] - should split at sentence boundaries
[info] - should preserve abbreviations
[info] - should handle decimal numbers
[info] - should respect target size
[info] - should force split very long sentences
[info] - should add source metadata with chunkWithSource
[info] - should assign sequential indices
[info] SimpleChunker
[info] - should chunk at fixed size
[info] - should apply overlap
[info] ChunkerFactory
[info] - should create simple chunker
[info] - should create sentence chunker
[info] - should create chunker by name
[info] - should parse strategy from string
[info] - should auto-detect markdown content
[info] - should have a default chunker
[info] ConversationTokenCounterSpec:
[info] ConversationTokenCounter.forModel
16:29:11.895 [pool-1-thread-1-ScalaTest-running-ConversationTokenCounterSpec] INFO  o.l.c.ConversationTokenCounter$ -- Creating token counter for model 'gpt-4o' using TokenizerId(o200k_base)
[info] - should select correct tokenizer for GPT-4o models
16:29:12.129 [pool-1-thread-1-ScalaTest-running-ConversationTokenCounterSpec] INFO  o.l.c.ConversationTokenCounter$ -- Creating token counter for model 'gpt-4' using TokenizerId(cl100k_base)
[info] - should select correct tokenizer for GPT-4 models
16:29:12.131 [pool-1-thread-1-ScalaTest-running-ConversationTokenCounterSpec] INFO  o.l.c.ConversationTokenCounter$ -- Creating token counter for model 'claude-3-sonnet' using TokenizerId(cl100k_base)
[info] - should select correct tokenizer for Claude models
16:29:12.131 [pool-1-thread-1-ScalaTest-running-ConversationTokenCounterSpec] WARN  o.l.context.tokens.TokenizerMapping$ -- Unknown model 'unknown-model-xyz', using cl100k_base as fallback
16:29:12.131 [pool-1-thread-1-ScalaTest-running-ConversationTokenCounterSpec] INFO  o.l.c.ConversationTokenCounter$ -- Creating token counter for model 'unknown-model-xyz' using TokenizerId(cl100k_base)
[info] - should fallback gracefully for unknown models
[info] ConversationTokenCounter.openAI
[info] - should create counter with cl100k_base tokenizer
[info] ConversationTokenCounter.openAI_o200k
[info] - should create counter with o200k_base tokenizer
[info] ConversationTokenCounter.apply
[info] - should accept valid tokenizer IDs
16:29:12.132 [pool-1-thread-1-ScalaTest-running-ConversationTokenCounterSpec] ERROR o.l.c.ConversationTokenCounter$ -- Tokenizer not available for TokenizerId(invalid_tokenizer)
[info] - should fail for invalid tokenizer IDs
[info] ConversationTokenCounter.countMessage
[info] - should count user messages correctly
[info] - should count assistant messages with tool calls
[info] - should count tool messages correctly
[info] - should count system messages correctly
[info] - should include message overhead in count
[info] ConversationTokenCounter.countConversation
[info] - should sum all message tokens plus overhead
[info] - should return just overhead for empty conversation
[info] - should scale with conversation size
[info] ConversationTokenCounter.getTokenBreakdown
[info] - should return per-message counts
[info] - should provide message role in breakdown
[info] - should provide message preview in breakdown
[info] - should produce readable prettyPrint output
[info] ConversationTokenCounter
[info] - should produce consistent counts for same input
[info] - should count differently sized messages proportionally
[info] RAGWithMocksSpec:
[info] RAG.build
[info] - should create RAG with default configuration
[info] - should create RAG with custom embedding provider
[info] - should create RAG with LLM client
[info] - should fail when LLM reranking requested without LLM client
[info] - should fail when Cohere reranking requested without config
[info] RAG.ingestText
[info] - should ingest raw text content
[info] - should attach metadata to chunks
[info] RAG.ingestChunks
[info] - should ingest pre-chunked content
[info] RAG.ingest(path)
16:29:12.804 [pool-1-thread-1-ScalaTest-running-RAGWithMocksSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/rag-test15231636434068741308/test.txt (MIME: text/plain)
[info] - should ingest a text file
16:29:12.809 [pool-1-thread-1-ScalaTest-running-RAGWithMocksSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/rag-test3940215221828318906/doc3.md (MIME: text/x-web-markdown)
16:29:12.812 [pool-1-thread-1-ScalaTest-running-RAGWithMocksSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/rag-test3940215221828318906/doc1.txt (MIME: text/plain)
16:29:12.814 [pool-1-thread-1-ScalaTest-running-RAGWithMocksSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/rag-test3940215221828318906/doc2.txt (MIME: text/plain)
[info] - should ingest a directory of files
[info] RAG.ingest(loader)
[info] - should ingest from TextLoader
[info] - should handle loader failures gracefully
[info] - should skip empty documents when configured
[info] - should fail fast when configured
[info] RAG.query
[info] - should search for relevant chunks
[info] - should respect topK parameter
[info] RAG.queryWithAnswer
[info] - should fail without LLM client
[info] - should generate answer with LLM client
[info] RAG.sync
[info] - should add new documents
[info] - should detect unchanged documents
[info] RAG.needsUpdate
[info] - should return true for new documents
[info] RAG.deleteDocument
[info] - should remove document from store
[info] RAG.stats
[info] - should return correct statistics
[info] RAG.documentCount
[info] - should track ingested documents
[info] RAG.chunkCount
[info] - should track indexed chunks
[info] RAG.clear
[info] - should remove all indexed data
[info] RAG.close
[info] - should not throw exception
[info] RAG.hasPermissions
[info] - should return false without SearchIndex
[info] RAG.searchIndex
[info] - should return None without SearchIndex
[info] RAG.queryWithPermissions
[info] - should fail without SearchIndex
[info] RAG.ingestWithPermissions
[info] - should fail without SearchIndex
[info] RAG.deleteFromCollection
[info] - should fail without SearchIndex
[info] RAG.config
[info] - should expose the configuration
[info] RAG.builder
[info] - should return RAGConfig.default
[info] RAGConfigOps.build
[info] - should be accessible via implicit
[info] RequestTransformerSpec:
[info] - O-series models should reject non-1.0 temperature when dropUnsupported=false
[info] - O-series models should adjust temperature to 1.0 when dropUnsupported=true
[info] - O-series models should allow temperature=1.0
[info] - O-series models should reject top_p when dropUnsupported=false
[info] - O-series models should drop top_p when dropUnsupported=true
[info] - O-series models should reject presence_penalty when dropUnsupported=false
[info] - O-series models should drop presence_penalty when dropUnsupported=true
[info] - O-series models should reject frequency_penalty when dropUnsupported=false
[info] - O-series models should drop frequency_penalty when dropUnsupported=true
[info] - O-series models should report all violations when dropUnsupported=false
[info] - O-series models should fix all violations when dropUnsupported=true
[info] - O-series models should convert system messages to user messages
[info] - Models that support system messages should not transform them
[info] - O-series models should require fake streaming
[info] - Standard models should not require fake streaming
[info] - should detect O-series models by name pattern
[info] - O-series models should return disallowed params set
[info] - Standard models should return empty disallowed params set
[info] - custom overrides should take precedence over registry
[info] - TransformationResult.transform should transform both options and messages
[info] - TransformationResult.transform should fail if dropUnsupported=false and violations exist
[info] ChunkingUtilsSpec:
[info] - chunkText should split text into chunks of specified size
[info] - chunkText should handle overlap correctly
[info] - chunkText should return single chunk for text smaller than size
[info] - chunkText should handle empty text
[info] - chunkText should handle text exactly equal to chunk size
[info] - chunkText should throw for invalid size
[info] - chunkText should throw for overlap >= size
[info] - chunkText should throw for negative overlap
[info] - chunkAudio should window audio samples correctly
[info] - chunkAudio should pad final window when requested
[info] - chunkAudio should handle overlap correctly
[info] - chunkAudio should throw for invalid sample rate
[info] - chunkAudio should throw for invalid window seconds
[info] - chunkAudio should throw for invalid overlap ratio
[info] - chunkVideo should split frames into clips
[info] - chunkVideo should handle overlap correctly
[info] - chunkVideo should handle fewer frames than clip size
[info] - chunkVideo should throw for invalid fps
[info] - chunkVideo should throw for invalid clip seconds
[info] - chunkVideo handles generic types
[info] LLMProviderSpec:
[info] LLMProvider
[info] - should have all expected provider instances
[info] - should have exactly 5 providers
[info] LLMProvider.name
[info] - should return correct name for OpenAI
[info] - should return correct name for Azure
[info] - should return correct name for Anthropic
[info] - should return correct name for OpenRouter
[info] - should return correct name for Ollama
[info] LLMProvider.fromName
[info] - should parse 'openai' correctly
[info] - should parse 'azure' correctly
[info] - should parse 'anthropic' correctly
[info] - should parse 'openrouter' correctly
[info] - should parse 'ollama' correctly
[info] - should be case insensitive
[info] - should return None for unknown providers
[info] LLMProvider
[info] - should round-trip through name and fromName
[info] LLMProvider instances
[info] - should be distinguishable
[info] - should support pattern matching
[info] OpenAIRequestBodySpec:
[info] OpenAIRequestBody
[info] - should correctly serialize request with prompt and JPEG image data
[info] - should correctly serialize with PNG media type
[info] - should correctly serialize with WebP media type
[info] - should correctly serialize with GIF media type
[info] - should be serializable and deserializable
[info] - should produce valid JSON structure for API consumption
[info] - should handle all supported media types correctly
[info] HuggingFaceHttpClientTest:
[info] - should return a Left(error) on exception
[info] - should return a Right(value) on success
[info] GameToolsIntegrationTest:
[info] list_inventory tool schema
[info] - should have no required parameters
[info] add_inventory_item tool schema
[info] - should have 'item' as required parameter
[info] remove_inventory_item tool schema
[info] - should have 'item' as required parameter
[info] list_inventory OpenAI schema
[info] - should have empty required array
[info] add_inventory_item OpenAI schema
[info] - should have 'item' in required array
[info] remove_inventory_item OpenAI schema
[info] - should have 'item' in required array
[info] list_inventory
[info] - should accept null arguments (zero-parameter tool)
[info] list_inventory
[info] - should accept empty object arguments
[info] add_inventory_item
[info] - should reject null arguments
[info] add_inventory_item
[info] - should reject empty object (missing required 'item')
[info] remove_inventory_item
[info] - should reject null arguments
[info] remove_inventory_item
[info] - should reject empty object (missing required 'item')
[info] add_inventory_item
[info] - should successfully add an item with proper arguments
[info] add_inventory_item
[info] - should detect duplicate items
[info] remove_inventory_item
[info] - should successfully remove an item
[info] remove_inventory_item
[info] - should fail gracefully when item not in inventory
[info] list_inventory
[info] - should return current inventory state
[info] Game tools
[info] - should work together in a complete workflow
[info] ToolRegistry with game tools
[info] - should execute tools correctly
[info] ToolRegistry with game tools
[info] - should return proper errors for unknown tools
[info] ToolRegistry with game tools
[info] - should provide all tools in OpenAI format
[info] SSEParserTest:
[info] - parseEvent should parse simple SSE event
[info] - parseEvent should parse event with multiple fields
[info] - parseEvent should handle comments
[info] - parseEvent should handle multi-line data with newline joins
[info] - parseStream should parse multiple events
[info] - StreamingParser should accumulate chunks
[info] - StreamingParser should handle incomplete events
[info] - StreamingParser should handle OpenAI [DONE] message
[info] - StreamingParser should flush remaining data
[info] AgentToolCallingMultiProviderTest:
[info] Agent with Anthropic-style provider
16:29:12.907 [pool-1-thread-1-ScalaTest-running-AgentToolCallingMultiProviderTest] INFO  org.llm4s.agent.Agent -- Executing tool: add_inventory_item with arguments: {"item":"sword"}
16:29:12.908 [pool-1-thread-1-ScalaTest-running-AgentToolCallingMultiProviderTest] INFO  org.llm4s.agent.Agent -- Tool add_inventory_item completed successfully in 1ms. Result: {"success":true,"message":"Added 'sword' to inventory","item":"sword"}
[info] - should handle complete tool calling flow
[info] Agent with OpenAI-style provider
16:29:12.911 [pool-1-thread-1-ScalaTest-running-AgentToolCallingMultiProviderTest] INFO  org.llm4s.agent.Agent -- Executing tool: add_inventory_item with arguments: {"item":"sword"}
16:29:12.912 [pool-1-thread-1-ScalaTest-running-AgentToolCallingMultiProviderTest] INFO  org.llm4s.agent.Agent -- Tool add_inventory_item completed successfully in 1ms. Result: {"success":true,"message":"Added 'sword' to inventory","item":"sword"}
[info] - should handle complete tool calling flow
[info] Agent with Anthropic-style provider
16:29:12.913 [pool-1-thread-1-ScalaTest-running-AgentToolCallingMultiProviderTest] INFO  org.llm4s.agent.Agent -- Executing tool: add_inventory_item with arguments: {"item":"sword"}
16:29:12.913 [pool-1-thread-1-ScalaTest-running-AgentToolCallingMultiProviderTest] INFO  org.llm4s.agent.Agent -- Tool add_inventory_item completed successfully in 0ms. Result: {"success":true,"message":"Added 'sword' to inventory","item":"sword"}
16:29:12.913 [pool-1-thread-1-ScalaTest-running-AgentToolCallingMultiProviderTest] INFO  org.llm4s.agent.Agent -- Executing tool: add_inventory_item with arguments: {"item":"shield"}
16:29:12.913 [pool-1-thread-1-ScalaTest-running-AgentToolCallingMultiProviderTest] INFO  org.llm4s.agent.Agent -- Tool add_inventory_item completed successfully in 0ms. Result: {"success":true,"message":"Added 'shield' to inventory","item":"shield"}
[info] - should handle multiple tool calls
[info] Agent with OpenAI-style provider
16:29:12.914 [pool-1-thread-1-ScalaTest-running-AgentToolCallingMultiProviderTest] INFO  org.llm4s.agent.Agent -- Executing tool: add_inventory_item with arguments: {"item":"sword"}
16:29:12.914 [pool-1-thread-1-ScalaTest-running-AgentToolCallingMultiProviderTest] INFO  org.llm4s.agent.Agent -- Tool add_inventory_item completed successfully in 0ms. Result: {"success":true,"message":"Added 'sword' to inventory","item":"sword"}
16:29:12.914 [pool-1-thread-1-ScalaTest-running-AgentToolCallingMultiProviderTest] INFO  org.llm4s.agent.Agent -- Executing tool: add_inventory_item with arguments: {"item":"shield"}
16:29:12.914 [pool-1-thread-1-ScalaTest-running-AgentToolCallingMultiProviderTest] INFO  org.llm4s.agent.Agent -- Tool add_inventory_item completed successfully in 0ms. Result: {"success":true,"message":"Added 'shield' to inventory","item":"shield"}
[info] - should handle multiple tool calls
[info] RAGTypesSpec:
[info] EmbeddingProvider
[info] - should have correct names
[info] - should parse from string correctly
[info] - should return None for unknown provider
[info] - should have all values in values sequence
[info] RerankingStrategy.None
[info] - should be a singleton
[info] RerankingStrategy.Cohere
[info] - should have default model
[info] - should accept custom model
[info] RerankingStrategy.LLM
[info] - should be a singleton
[info] RAGSearchResult
[info] - should store all fields
[info] - should have default empty metadata
[info] - should have default None for scores
[info] - should support equality
[info] RAGAnswerResult
[info] - should store all fields
[info] - should have default None for usage
[info] RAGStats
[info] - should store statistics
[info] - should support equality
[info] MemorySpec:
[info] MemoryId
[info] - should generate unique IDs
[info] - should have string representation equal to value
[info] EntityId
[info] - should generate unique IDs
[info] - should normalize names correctly
[info] MemoryType
[info] - should parse built-in types from string
[info] - should handle case-insensitive parsing
[info] - should create custom types for unknown strings
[info] Memory
[info] - should be created with required fields
[info] - should support metadata operations
[info] - should clamp importance scores to [0.0, 1.0]
[info] - should track embedding status
[info] Memory factory methods
[info] - should create conversation memory
[info] - should create entity memory
[info] - should create knowledge memory
[info] - should create user fact memory
[info] - should create task memory
[info] PromptInjectionSpec:
[info] PromptInjectionDetector
[info] - should detect 'ignore previous instructions'
[info] - should detect 'forget instructions'
[info] - should detect 'disregard' patterns
[info] - should detect 'new instructions' patterns
[info] - should detect DAN jailbreak attempts
[info] - should detect evil roleplay requests
[info] - should detect 'no restrictions' patterns
[info] - should detect developer/admin mode attempts
[info] - should detect system prompt extraction attempts
[info] - should detect 'beginning text' extraction
[info] - should detect hypothetical scenario jailbreaks
[info] - should detect dangerous creative writing requests
[info] - should detect SQL injection patterns
[info] - should detect shell injection patterns
[info] - should detect script injection patterns
[info] - should respect sensitivity levels
[info] - should filter low severity patterns at low sensitivity
[info] - should block by default when injection detected
[info] - should warn but allow in warn mode
[info] - should block even in fix mode (no safe fix for injection)
[info] - should pass clean input through
[info] - should not flag legitimate requests mentioning instructions
[info] - should work with strict preset
[info] - should work with balanced preset
[info] - should work with monitoring preset
[info] - should work with instructionOverrideOnly preset
[info] - should work with jailbreakOnly preset
[info] InjectionPattern
[info] - should have all categories covered in default
[info] InjectionSensitivity
[info] - should have correct thresholds
[info] PromptInjectionDetector
[info] - should work with CompositeGuardrail.all
[info] - should work with PIIDetector in a chain
[info] OpenAIVisionClientTest:
[info] OpenAIVisionClient
[info] - should encode image to base64 successfully
[info] - should fail to encode non-existent image
[info] - should analyze image with default prompt
[info] - should analyze image with custom prompt
[info] - should extract text from image
[info] - should detect objects in image
[info] - should generate tags for image
[info] - should delegate preprocessing to local processor
[info] - should delegate format conversion to local processor
[info] - should delegate resizing to local processor
[info] - should handle file not found error
[info] - should handle invalid image file error
[info] - should use correct authorization header
[info] - should handle timeout errors gracefully
[info] - should handle network errors gracefully
[info] RAGASEvaluatorSpec:
[info] RAGASEvaluator
[info] - should evaluate a sample with all metrics
[info] - should evaluate sample without ground truth (only basic metrics)
[info] - should evaluate a batch of samples
[info] - should return empty summary for empty batch
[info] - should create evaluator with only specific metrics
[info] - should evaluate a single metric
[info] - should fail for unknown metric
[info] - should provide basic evaluator without ground truth metrics
[info] - should have correct metric constants
[info] - should evaluate dataset
[info] BenchmarkConfigSpec:
[info] EmbeddingConfig
[info] - should have correct provider names
[info] - should have sensible default dimensions
[info] - should provide pre-configured variants
[info] RAGExperimentConfig
[info] - should have a default configuration
[info] - should require a non-empty name
[info] - should require positive topK
[info] - should require rerankTopK >= topK
[info] - should create config for chunking strategy
[info] - should create config for embedding provider
[info] - should create config for fusion strategy
[info] - should generate full description
[info] BenchmarkSuite
[info] - should require at least one experiment
[info] - should provide chunking suite
[info] - should provide fusion suite
[info] - should provide embedding suite
[info] - should provide quick suite
[info] - should create quick version of a suite
[info] - should get experiment by name
16:29:16.285 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Initializing MCPToolRegistry with 0 MCP servers and 1 local tools
[info] CompletionSpec:
[info] - Completion.asText returns content
[info] - Completion.hasToolCalls returns true when tool calls present
[info] - Completion.hasToolCalls returns false when no tool calls
[info] - Completion.hasThinking returns true when thinking content present
[info] - Completion.hasThinking returns false when thinking is empty
[info] - Completion.fullContent includes thinking when present
[info] - Completion.fullContent returns only content when no thinking
[info] - TokenUsage.totalOutputTokens includes thinking tokens
[info] - TokenUsage.totalOutputTokens returns completionTokens when no thinking
[info] - TokenUsage.hasThinkingTokens returns true when thinking tokens present
[info] - TokenUsage.hasThinkingTokens returns false when thinking tokens is zero
[info] - StreamedChunk.hasThinking returns true when thinking delta present
[info] - StreamedChunk.hasContent returns true when content present
[info] - StreamedChunk.hasContent returns false when content is empty
[info] - CompletionChunk.isComplete returns true when finishReason is set
[info] - CompletionChunk.isComplete returns false when finishReason is None
[info] - CompletionChunk.asText returns content or empty string
[info] - ChunkDelta.empty creates empty delta
16:29:16.287 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Initializing MCPToolRegistry with 0 MCP servers and 1 local tools
16:29:16.288 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Initializing MCPToolRegistry with 0 MCP servers and 1 local tools
[info] MCPToolRegistryCacheSpec:
[info] MCPToolRegistry
[info] - should include local tools in tools list
[info] - should execute local tools successfully
16:29:16.290 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] WARN  org.llm4s.mcp.MCPToolRegistry -- Tool nonexistent_tool not found in any registry (local or MCP)
[info] - should return error for unknown tool
[info] MCPToolRegistry.clearCache
16:29:16.291 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Initializing MCPToolRegistry with 0 MCP servers and 0 local tools
16:29:16.291 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Clearing all tool caches
[info] - should clear all cached tools
16:29:16.291 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Initializing MCPToolRegistry with 0 MCP servers and 0 local tools
16:29:16.291 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Refreshing cache for all 0 MCP servers
16:29:16.292 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Cache refresh completed for all servers
16:29:16.292 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Initializing MCPToolRegistry with 0 MCP servers and 1 local tools
[info] MCPToolRegistry.refreshCache
[info] - should refresh cache for all servers
[info] MCPToolRegistry.getOpenAITools
[info] - should return tools in OpenAI format
[info] - should return empty array when no tools
[info] MCPToolRegistry.close
16:29:16.292 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Initializing MCPToolRegistry with 0 MCP servers and 0 local tools
16:29:16.292 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Initializing MCPToolRegistry with 0 MCP servers and 0 local tools
16:29:16.292 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Closing 0 MCP clients
16:29:16.293 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- All MCP clients closed
[info] - should close all MCP clients
[info] MCPToolRegistry.closeMCPClients
[info] - should be idempotent
[info] MCPToolRegistry.getAllTools
[info] - should combine local and MCP tools
[info] - should return empty when no tools configured
[info] MCPToolRegistry
16:29:16.293 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Initializing MCPToolRegistry with 0 MCP servers and 0 local tools
16:29:16.293 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Closing 0 MCP clients
16:29:16.293 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- All MCP clients closed
16:29:16.293 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Closing 0 MCP clients
16:29:16.293 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- All MCP clients closed
16:29:16.293 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Initializing MCPToolRegistry with 0 MCP servers and 1 local tools
16:29:16.294 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Initializing MCPToolRegistry with 0 MCP servers and 0 local tools
16:29:16.294 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Initializing MCPToolRegistry with 1 MCP servers and 0 local tools
16:29:16.294 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Closing 0 MCP clients
16:29:16.294 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- All MCP clients closed
[info] - should respect initializeOnStartup=false
[info] - should support custom cache TTL
16:29:16.294 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Initializing MCPToolRegistry with 0 MCP servers and 0 local tools
16:29:16.294 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Closing 0 MCP clients
16:29:16.294 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- All MCP clients closed
16:29:16.294 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Initializing MCPToolRegistry with 0 MCP servers and 1 local tools
[info] CachedTools
16:29:16.307 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- Closing 0 MCP clients
16:29:16.307 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryCacheSpec] INFO  org.llm4s.mcp.MCPToolRegistry -- All MCP clients closed
[info] - should detect expiration correctly
[info] EmbeddingsConfigSpec:
[info] Llm4sConfig.embeddings
[info] - should load OpenAI embeddings config via llm4s.*
[info] - should load VoyageAI embeddings config via llm4s.*
[info] - should load Ollama embeddings config via llm4s.*
[info] - should load Ollama embeddings config with defaults
[info] ProviderConfigLoaderTest:
[info] - OpenAIConfig.load returns Right on success
[info] - OpenAIConfig.load returns Left when api key missing
[info] - AzureConfig.load returns Right with defaults when version missing
[info] - AzureConfig.load returns Left when endpoint missing
[info] - AnthropicConfig.load returns Left when api key missing
[info] - OllamaConfig.load returns Left when base url missing
[info] - ProviderConfigLoader.from handles provider prefixes and inference
[info] - ProviderConfigLoader.from respects OpenRouter base URL inference
[info] ImageProcessingConfigTest:
[info] OpenAIVisionConfig
[info] - should have default timeout values
[info] - should accept custom timeout values
[info] AnthropicVisionConfig
[info] - should have default timeout values
[info] - should accept custom timeout values
[info] AgentSpec:
[info] Agent.initialize
[info] - should create initial state with query
[info] - should include system message
[info] - should append system prompt addition
[info] - should include tools in state
[info] - should include handoff tools when handoffs are provided
[info] - should store completion options
[info] Agent.runStep
[info] - should transition InProgress to Complete when no tool calls
[info] - should transition InProgress to WaitingForTools when tool calls present
[info] - should return error on LLM failure
[info] - should pass tools to LLM via completion options
[info] Agent.runStep (WaitingForTools)
16:29:16.364 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- Executing tool: calculator with arguments: {"a":2,"b":2,"operation":"add"}
16:29:16.366 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- Tool calculator completed successfully in 2ms. Result: {"result":4}
[info] - should execute tools and transition to InProgress
16:29:16.367 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- Executing tool: nonexistent_tool with arguments: {"param":"value"}
16:29:16.367 [pool-1-thread-1-ScalaTest-running-AgentSpec] WARN  org.llm4s.agent.Agent -- Tool nonexistent_tool failed in 0ms with error: Tool call 'nonexistent_tool' is not a recognized tool
[info] - should handle tool execution errors gracefully
[info] Agent.runStep (Complete)
[info] - should remain in Complete state
[info] Agent.runStep (Failed)
[info] - should remain in Failed state
[info] Agent.run
[info] - should execute until completion
16:29:16.371 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- Executing tool: calculator with arguments: {"a":2,"b":2,"operation":"add"}
16:29:16.372 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- Tool calculator completed successfully in 1ms. Result: {"result":4}
[info] - should execute tools and continue to completion
16:29:16.373 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- Executing tool: calculator with arguments: {"a":1,"b":1,"operation":"add"}
16:29:16.373 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- Tool calculator completed successfully in 0ms. Result: {"result":2}
[info] - should respect maxSteps limit
[info] - should validate input with guardrails
[info] - should validate output with guardrails
[info] Agent.continueConversation
[info] - should continue from a completed state
[info] - should reject continuation from incomplete state
[info] - should allow continuation from failed state
[info] Agent.runMultiTurn
[info] - should execute multiple turns sequentially
[info] - should stop on first error
[info] Agent.runWithEvents
[info] - should emit events during execution
[info] - should emit tool events when tools are called
[info] Agent.runCollectingEvents
[info] - should return state and all events
[info] Agent.formatStateAsMarkdown
[info] - should format state as markdown
16:29:16.392 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- Executing tool: calculator with arguments: {"a":10,"b":5,"operation":"divide"}
16:29:16.392 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- Tool calculator completed successfully in 0ms. Result: {"result":2}
[info] - should include tool calls in markdown
16:29:16.392 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] ========================================
16:29:16.392 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Initializing new agent with query
16:29:16.392 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Query: Test debug mode
[info] Agent debug mode
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Tools: calculator
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Input guardrails: 
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Output guardrails: 
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Handoffs: 0
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] ========================================
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] ========================================
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Starting Agent.run
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Max steps: unlimited
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Trace log: disabled
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Initial status: InProgress
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] ========================================
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] ========================================
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] ITERATION 1
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Current status: InProgress
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Steps remaining: unlimited
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Conversation messages: 1
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] ========================================
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Running completion step
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Status: InProgress -> requesting LLM completion
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Available tools: calculator
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Conversation history: 1 messages
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] LLM response received
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Response type: text
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Response content: Debug response
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Status: InProgress -> Complete (no tool calls)
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] ========================================
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Agent completed
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Final status: Complete
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] Total iterations: 2
16:29:16.393 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- [DEBUG] ========================================
[info] - should execute successfully with debug=true
[info] Agent with handoffs
16:29:16.394 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- Executing tool: handoff_to_agent_35c7b10b with arguments: {"reason":"Need specialist"}
16:29:16.394 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- Tool handoff_to_agent_35c7b10b completed successfully in 0ms. Result: {"handoff_requested":true,"handoff_id":"handoff_to_agent_35c7b10b","reason":"Need specialist"}
16:29:16.395 [pool-1-thread-1-ScalaTest-running-AgentSpec] INFO  org.llm4s.agent.Agent -- Handoff requested: Handoff: For specialist help
[info] - should detect handoff tool calls
[info] MockLLMClient
[info] - should return configured context window
[info] - should calculate context budget correctly
[info] RAGSpec:
[info] EmbeddingProvider
[info] - should parse from string correctly
[info] - should have correct names
[info] - should list all values
[info] RerankingStrategy
[info] - should have correct case objects
[info] - should have default Cohere model
[info] RAGSearchResult
[info] - should create with required fields
[info] - should create with optional fields
[info] RAGAnswerResult
[info] - should create with all fields
[info] RAGStats
[info] - should create with counts
[info] RAGConfig
[info] - should have sensible defaults
[info] - should support fluent embedding configuration
[info] - should support fluent chunking configuration
[info] - should support fluent fusion configuration
[info] - should support fluent reranking configuration
[info] - should support fluent storage configuration
[info] - should support fluent answer generation configuration
[info] RAGConfig.default
[info] - should equal empty RAGConfig
[info] RAGConfig.production
[info] - should configure persistent storage
[info] RAGConfig.development
[info] - should configure for testing
[info] RAG.builder
[info] - should return default config
[info] RAGConfigOps.build
[info] - should be accessible via implicit
[info] InMemoryStoreSpec:
[info] InMemoryStore
[info] - should start empty
[info] - should store and retrieve a memory by ID
[info] - should return None for non-existent memory ID
[info] - should store multiple memories
[info] - should recall memories with filter
[info] - should respect limit in recall
[info] - should delete a memory by ID
[info] - should delete memories matching a filter
[info] - should update a memory
[info] - should return error when updating non-existent memory
[info] - should search memories by keyword
[info] - should return empty results for blank search queries
[info] - should return recent memories in descending order
[info] - should get entity memories
[info] - should get conversation history in chronological order
[info] - should clear all memories
[info] - should check if memory exists
[info] - should enforce max memories limit
[info] - should get important memories
[info] JSONValidatorSpec:
[info] - valid JSON without schema passes
[info] - invalid JSON string fails
[info] - valid JSON satisfies required fields
[info] - missing fields fails validation
[info] - required field check fails if root is not an object
[info] - empty required array passes any object
[info] - schema without required field passes any valid JSON
[info] BenchmarkReportSpec:
[info] BenchmarkReport.console
[info] - should produce readable output
[info] - should show winner announcement
[info] - should handle failed experiments
[info] BenchmarkReport.consoleDetailed
[info] - should include timing information
[info] BenchmarkReport.json
[info] - should produce valid JSON
[info] - should include all experiment details
[info] - should handle compact format
[info] BenchmarkReport.markdown
[info] - should produce valid markdown
[info] - should format winner in summary table
[info] BenchmarkReport.comparison
[info] - should show comparison details
[info] OllamaRoutingTest:
[info] - provider-based getClientResult returns OllamaClient
[info] - OllamaConfig.from(reader) uses provided base URL
[info] OllamaClientSpec:
[info] - ollama chat request sends assistant content as a plain string
[info] PermissionTypesSpec:
[info] PrincipalId
[info] - should identify users with positive IDs
[info] - should identify groups with negative IDs
[info] - should create users via factory method
[info] - should create groups with negative IDs via factory method
[info] - should reject zero in fromRaw
[info] ExternalPrincipal
[info] - should parse user identifiers
[info] - should parse group identifiers
[info] - should generate correct external IDs
[info] - should reject invalid format
[info] CollectionPath
[info] - should create valid paths
[info] - should create root paths
[info] - should compute parent paths
[info] - should compute depth correctly
[info] - should reject empty paths
[info] - should reject invalid characters
[info] - should detect child relationships
[info] - should detect descendant relationships
[info] CollectionPattern.All
[info] - should match all collections
[info] CollectionPattern.Exact
[info] - should match exact paths only
[info] CollectionPattern.ImmediateChildren
[info] - should match only direct children
[info] CollectionPattern.AllDescendants
[info] - should match the prefix and all descendants
[info] CollectionPattern.parse
[info] - should parse * as All
[info] - should parse path/* as ImmediateChildren
[info] - should parse path/** as AllDescendants
[info] - should parse plain path as Exact
[info] UserAuthorization
[info] - should check principal inclusion
[info] - should convert to array for SQL
[info] UserAuthorization.forUser
[info] - should create authorization with user and groups
[info] UserAuthorization.Anonymous
[info] - should have no principals
[info] UserAuthorization.Admin
[info] - should be an admin
[info] ChunkWithEmbedding
[info] - should compute dimensions
[info] - should implement equals correctly
[info] - should implement hashCode correctly
[info] - should not equal non-ChunkWithEmbedding objects
[info] - should support metadata
[info] PrincipalId.toString
[info] - should format user IDs correctly
[info] - should format group IDs correctly
[info] - should format zero ID correctly
[info] PrincipalId.user
[info] - should reject non-positive IDs
[info] PrincipalId.group
[info] - should reject non-positive IDs
[info] PrincipalId.fromRaw
[info] - should accept positive values as users
[info] - should accept negative values as groups
[info] ExternalPrincipal.User
[info] - should expose value correctly
[info] ExternalPrincipal.Group
[info] - should expose value correctly
[info] CollectionPath.name
[info] - should return the last segment
[info] CollectionPath.child
[info] - should create a valid child path
[info] - should reject invalid child names
[info] CollectionPath.root
[info] - should create a root collection
[info] - should reject invalid root names
[info] CollectionPath.value
[info] - should return the full path string
[info] UserAuthorization.asSeq
[info] - should return principal IDs as sequence
[info] UserAuthorization.withPrincipal
[info] - should add a principal
[info] UserAuthorization.withPrincipals
[info] - should add multiple principals
[info] UserAuthorization.fromRawIds
[info] - should create authorization from valid IDs
[info] - should fail if any ID is zero
[info] - should handle empty sequence
[info] UserAuthorization.forUser
[info] - should reject group IDs as user ID
[info] - should reject user IDs in groups set
[info] CollectionStats
[info] - should report isEmpty correctly
[info] CollectionPattern.All.patternString
[info] - should return *
[info] CollectionPattern.Exact.patternString
[info] - should return the path
[info] CollectionPattern.ImmediateChildren.patternString
[info] - should return path/*
[info] CollectionPattern.AllDescendants.patternString
[info] - should return path/**
[info] Collection
[info] - should report isPublic correctly
[info] - should report isRoot correctly
[info] - should return correct name
[info] - should return correct depth
[info] - should allow query for public collections
[info] - should allow query for admin on restricted collections
[info] - should allow query for authorized users on restricted collections
[info] - should deny query for unauthorized users on restricted collections
[info] - should support metadata
[info] CollectionConfig
[info] - should report isPublic correctly
[info] - should compute parentPath correctly
[info] - should add single principal with withQueryableBy
[info] - should add multiple principals with withQueryableBy
[info] - should accumulate principals across multiple withQueryableBy calls
[info] - should convert to leaf with asLeaf
[info] - should convert to parent with asParent
[info] - should add single metadata entry with withMetadata
[info] - should add multiple metadata entries with withMetadata
[info] - should accumulate metadata across multiple withMetadata calls
[info] CollectionConfig.publicLeaf
[info] - should create a public leaf collection
[info] CollectionConfig.restrictedLeaf
[info] - should create a restricted leaf collection
[info] CollectionConfig.publicParent
[info] - should create a public parent collection
[info] CollectionConfig.restrictedParent
[info] - should create a restricted parent collection
[info] AgentEventSpec:
[info] AgentEvent.TextDelta
[info] - should be created with factory method
[info] AgentEvent.TextComplete
[info] - should be created with factory method
[info] AgentEvent.ToolCallStarted
[info] - should be created with factory method
[info] AgentEvent.ToolCallCompleted
[info] - should be created with factory method
[info] AgentEvent.ToolCallFailed
[info] - should capture error information
[info] AgentEvent.AgentStarted
[info] - should be created with factory method
[info] AgentEvent.StepStarted
[info] - should be created with factory method
[info] AgentEvent.StepCompleted
[info] - should be created with factory method
[info] AgentEvent.AgentFailed
[info] - should be created with factory method
[info] - should accept None for stepNumber
[info] AgentEvent.HandoffStarted
[info] - should capture handoff information
[info] AgentEvent.HandoffCompleted
[info] - should indicate success status
[info] AgentEvent.InputGuardrailStarted
[info] - should capture guardrail name
[info] AgentEvent.InputGuardrailCompleted
[info] - should indicate pass/fail
[info] AgentEvent.OutputGuardrailStarted
[info] - should capture guardrail name
[info] AgentEvent.OutputGuardrailCompleted
[info] - should indicate pass/fail
[info] All AgentEvent types
[info] - should have timestamps
[info] Event timestamps
[info] - should be ordered when created sequentially
[info] WebCrawlerLoaderSpec:
[info] WebCrawlerLoader
[info] - should be created with a single seed URL
[info] - should be created with multiple seed URLs
[info] - should support fluent configuration
[info] - should add metadata to documents
[info] - should add seed URLs with withSeed
[info] - should report estimatedCount as None
[info] - should have a descriptive description
[info] WebCrawlerLoader.forDocs
[info] - should use polite configuration
[info] WebCrawlerLoader.singlePage
[info] - should not follow links
[info] WebCrawlerLoader
[info] - should be combinable with other loaders
[info] - should support DocumentLoader trait methods
[info] ContextRecallSpec:
[info] ContextRecall
[info] - should have correct metadata
[info] - should return score 1.0 when all facts are covered
[info] - should return score 0.5 when half the facts are covered
[info] - should return score 0.0 when no facts are covered
[info] - should return score 1.0 when no facts in ground truth
[info] - should fail when ground truth is missing
[info] - should return score 1.0 when ground truth is empty
[info] - should return score 0.0 when no contexts provided
[info] - should handle JSON response wrapped in markdown code blocks
[info] - should include details about facts in result
[info] AnswerRelevancySpec:
[info] AnswerRelevancy
[info] - should have correct metadata
[info] - should return high score when generated questions are similar to original
[info] - should return lower score when generated questions are dissimilar
[info] - should return score 0.0 for empty answer
[info] - should return score 0.0 for empty question
[info] - should handle JSON response wrapped in markdown code blocks
[info] - should include details about generated questions in result
[info] - should reject invalid number of generated questions
[info] - should use default number of questions
[info] SpeechIntegrationTest:
[info] - AudioPreprocessing should handle mono conversion
[info] - AudioPreprocessing should handle resampling
[info] - AudioPreprocessing should compose multiple operations
[info] - VoskSpeechToText should handle configuration
[info] - WhisperSpeechToText should build correct CLI arguments
--text Hello world --out /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/llm4s-tts-5554432579988631249.wav --voice en-female --lang en --rate 1.2 --pitch 2.0 --gain 3.0
[info] - Tacotron2TextToSpeech should handle voice options
[info] - AudioIO should handle WAV and raw PCM output
[info] - AudioConverter should compose operations
[info] AnsiColorsSpec:
[info] AnsiColors
[info] - should define RESET as escape code
[info] - should define foreground colors with correct escape codes
[info] - should define BOLD as escape code
[info] AnsiColors.separator
[info] - should create default separator of 60 equals signs
[info] - should create separator with custom character
[info] - should create separator with custom length
[info] - should create separator with custom character and length
[info] - should handle zero length
[info] AnsiColors.colorize
[info] - should wrap text with color and reset
[info] - should handle empty text
[info] - should work with any color
[info] AnsiColors.boldColor
[info] - should wrap text with bold, color, and reset
[info] - should handle empty text
[info] - should work with any color
[info] AnsiColors
[info] - should produce valid output for console printing
[info] - should allow composing multiple colors
[info] HuggingFaceClientTest:
[info] buildPayload
[info] - should create a valid JSON payload with all parameters
[info] - should create a payload with minimal options
[info] - should handle special characters in the prompt
[info] - should create a payload with custom guidance scale and inference steps
[info] - should create a payload with a specific seed
[info] buildPayload
[info] - should successfully create a valid payload string
[info] - should create a payload with all custom options
[info] - should handle empty prompt correctly
[info] - should handle special characters in the prompt correctly
[info] S3LoaderSpec:
[info] S3Loader.apply
[info] - should create a loader with default settings
[info] - should accept custom settings
[info] S3Loader.forLocalStack
[info] - should create loader for LocalStack testing
[info] S3Loader.withCredentials
[info] - should create loader with explicit credentials
[info] S3Loader.++
[info] - should combine two loaders
[info] ToolFunctionSpec:
[info] ToolFunction.toOpenAITool
[info] - should generate correct OpenAI format
[info] - should set strict to true by default
[info] - should allow setting strict to false
[info] - should include parameter schema
[info] ToolFunction.execute
[info] - should execute with valid parameters
[info] - should return HandlerError for handler failures
[info] - should return NullArguments for null input with required params
[info] - should handle null input for zero-parameter tools
[info] - should handle empty object for zero-parameter tools
[info] ToolFunction.executeEnhanced
[info] - should execute with enhanced error reporting
[info] - should return InvalidArguments for parameter errors
[info] - should handle null input for zero-parameter tools
[info] - should return NullArguments for null input with required params
[info] ToolBuilder
[info] - should build a tool with handler
[info] - should throw exception when building without handler
[info] - should allow replacing handler with withHandler
[info] ToolFunction
[info] - should expose name and description
[info] - should expose schema
[info] SimpleMemoryManagerSpec:
[info] SimpleMemoryManager
[info] - should start with empty stats
[info] - should record a user message
[info] - should record different message types
[info] - should record a complete conversation
[info] - should record entity facts
[info] - should record user facts
[info] - should record knowledge
[info] - should record task outcomes
[info] - should get conversation context
[info] - should get entity context
[info] - should get user context
[info] - should get relevant context for a query
[info] - should return empty context when no memories exist
[info] - should return empty conversation context for non-existent conversation
[info] - should track memory stats correctly
[info] - should use default importance from config
[info] - should use provided importance over default
[info] SimpleMemoryManager.forTesting
[info] - should create a testing instance
[info] TypedAgentSpec:
[info] TypedAgent.fromFunction
[info] - should create a working functional agent
[info] TypedAgent.fromUnsafeFunction
[info] - should handle exceptions safely
[info] TypedAgent.fromFuture
[info] - should handle Future operations properly
[info] TypedAgent.fromFuture
16:29:16.636 [scala-execution-context-global-73] WARN  o.l.agent.orchestration.TypedAgent$ -- Async agent failing-future-agent [f7d0c48d-013d-4d20-8abf-4eea1cafd220] failed with exception
java.lang.RuntimeException: Future failed
	at org.llm4s.agent.orchestration.TypedAgentSpec.$anonfun$8(TypedAgentSpec.scala:47)
	at org.llm4s.agent.orchestration.TypedAgent$$anon$2.execute(TypedAgent.scala:85)
	at org.llm4s.agent.orchestration.TypedAgentSpec.testFun$proxy4$1(TypedAgentSpec.scala:50)
	at org.llm4s.agent.orchestration.TypedAgentSpec.$init$$$anonfun$4(TypedAgentSpec.scala:45)
	at org.scalatest.Transformer.apply$$anonfun$1(Transformer.scala:22)
	at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:31)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:21)
	at org.scalatest.flatspec.AnyFlatSpecLike$$anon$5.apply(AnyFlatSpecLike.scala:1717)
	at org.scalatest.TestSuite.withFixture(TestSuite.scala:196)
	at org.scalatest.TestSuite.withFixture$(TestSuite.scala:138)
	at org.scalatest.flatspec.AnyFlatSpec.withFixture(AnyFlatSpec.scala:1685)
	at org.scalatest.flatspec.AnyFlatSpecLike.invokeWithFixture$1(AnyFlatSpecLike.scala:1723)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTest$$anonfun$1(AnyFlatSpecLike.scala:1727)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTest(AnyFlatSpecLike.scala:1727)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTest$(AnyFlatSpecLike.scala:51)
	at org.scalatest.flatspec.AnyFlatSpec.runTest(AnyFlatSpec.scala:1685)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTests$$anonfun$1(AnyFlatSpecLike.scala:1785)
	at org.scalatest.SuperEngine.traverseSubNodes$1$$anonfun$1(Engine.scala:413)
	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)
	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)
	at scala.collection.immutable.List.foreach(List.scala:334)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:429)
	at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390)
	at org.scalatest.SuperEngine.traverseSubNodes$1$$anonfun$1(Engine.scala:427)
	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)
	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)
	at scala.collection.immutable.List.foreach(List.scala:334)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:429)
	at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTests(AnyFlatSpecLike.scala:1785)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTests$(AnyFlatSpecLike.scala:51)
	at org.scalatest.flatspec.AnyFlatSpec.runTests(AnyFlatSpec.scala:1685)
	at org.scalatest.Suite.run(Suite.scala:1114)
	at org.scalatest.Suite.run$(Suite.scala:564)
	at org.scalatest.flatspec.AnyFlatSpec.org$scalatest$flatspec$AnyFlatSpecLike$$super$run(AnyFlatSpec.scala:1685)
	at org.scalatest.flatspec.AnyFlatSpecLike.run$$anonfun$1(AnyFlatSpecLike.scala:1830)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:535)
	at org.scalatest.flatspec.AnyFlatSpecLike.run(AnyFlatSpecLike.scala:1830)
	at org.scalatest.flatspec.AnyFlatSpecLike.run$(AnyFlatSpecLike.scala:51)
	at org.scalatest.flatspec.AnyFlatSpec.run(AnyFlatSpec.scala:1685)
	at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)
	at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:414)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1623)
[info] - should handle Future failures
[info] TypedAgent.constant
[info] - should always return the same value
[info] TypedAgent.simpleFailure
[info] - should always fail with the specified error
[info] TypedAgent composition
[info] - should work with different input/output types
[info] TypedAgent with long-running operation
[info] - should complete eventually
[info] HandoffSpec:
[info] Handoff
[info] - should create with target agent
[info] - should create with reason
[info] - should generate unique handoff ID
[info] - should generate handoff ID with correct format
[info] - should generate human-readable name with reason
[info] - should generate human-readable name without reason
[info] Handoff companion object
[info] - should create simple handoff with to()
[info] - should create handoff with reason using to(agent, reason)
[info] HandoffRequested status
[info] - should contain handoff and reason
[info] - should serialize without target agent reference
[info] AgentToolFailureTest:
[info] Agent
16:29:16.750 [pool-1-thread-1-ScalaTest-running-AgentToolFailureTest] INFO  org.llm4s.agent.Agent -- Executing tool: add_inventory_item with arguments: null
16:29:16.750 [pool-1-thread-1-ScalaTest-running-AgentToolFailureTest] WARN  org.llm4s.agent.Agent -- Tool add_inventory_item failed in 0ms with error: Tool call 'add_inventory_item' received null arguments - expected an object with required parameters
[info] - should handle tool execution failures gracefully without creating empty messages
[info] Agent
16:29:16.751 [pool-1-thread-1-ScalaTest-running-AgentToolFailureTest] INFO  org.llm4s.agent.Agent -- Executing tool: test_tool with arguments: {}
16:29:16.751 [pool-1-thread-1-ScalaTest-running-AgentToolFailureTest] WARN  org.llm4s.agent.Agent -- Tool test_tool failed in 0ms with error: Tool call 'test_tool' failed with error: 
[info] - should handle tool execution with empty error messages
[info] Agent
16:29:16.752 [pool-1-thread-1-ScalaTest-running-AgentToolFailureTest] INFO  org.llm4s.agent.Agent -- Executing tool: special_char_tool with arguments: {}
16:29:16.752 [pool-1-thread-1-ScalaTest-running-AgentToolFailureTest] WARN  org.llm4s.agent.Agent -- Tool special_char_tool failed in 0ms with error: Tool call 'special_char_tool' failed with error: Error with "quotes" and \ backslash
[info] - should handle tool execution errors with special characters
[info] ToolCallDeserializerSpec:
[info] - StandardToolCallDeserializer should parse standard format tool calls
[info] - StandardToolCallDeserializer should parse multiple tool calls
[info] - OpenRouterToolCallDeserializer should parse nested array format
[info] - StandardToolCallDeserializer should handle empty array
[info] - OpenRouterToolCallDeserializer should handle empty nested array
[info] - StandardToolCallDeserializer should parse complex arguments
[info] LLMCompressorSpec:
[info] LLMCompressor.squeezeDigest
16:29:16.756 [pool-1-thread-1-ScalaTest-running-LLMCompressorSpec] INFO  org.llm4s.context.LLMCompressor$ -- Starting LLM digest squeeze with cap: 100 tokens
[info] - should skip compression when no HISTORY_SUMMARY messages present
16:29:16.757 [pool-1-thread-1-ScalaTest-running-LLMCompressorSpec] INFO  org.llm4s.context.LLMCompressor$ -- Starting LLM digest squeeze with cap: 500 tokens
16:29:16.757 [pool-1-thread-1-ScalaTest-running-LLMCompressorSpec] INFO  org.llm4s.context.LLMCompressor$ -- Starting LLM digest squeeze with cap: 10 tokens
[info] - should skip compression when digests already within cap
16:29:16.757 [pool-1-thread-1-ScalaTest-running-LLMCompressorSpec] INFO  org.llm4s.context.LLMCompressor$ -- Found 1 [HISTORY_SUMMARY] messages to squeeze
16:29:16.758 [pool-1-thread-1-ScalaTest-running-LLMCompressorSpec] INFO  org.llm4s.context.LLMCompressor$ -- Digest squeeze complete: 434  22 tokens
[info] - should preserve non-HISTORY_SUMMARY messages
16:29:16.758 [pool-1-thread-1-ScalaTest-running-LLMCompressorSpec] INFO  org.llm4s.context.LLMCompressor$ -- Starting LLM digest squeeze with cap: 192 tokens
16:29:16.759 [pool-1-thread-1-ScalaTest-running-LLMCompressorSpec] INFO  org.llm4s.context.LLMCompressor$ -- Found 1 [HISTORY_SUMMARY] messages to squeeze
16:29:16.759 [pool-1-thread-1-ScalaTest-running-LLMCompressorSpec] INFO  org.llm4s.context.LLMCompressor$ -- Digest squeeze complete: 384  22 tokens
[info] - should compress HISTORY_SUMMARY messages when over cap
[info] LLMCompressor
16:29:16.759 [pool-1-thread-1-ScalaTest-running-LLMCompressorSpec] INFO  org.llm4s.context.LLMCompressor$ -- Starting LLM digest squeeze with cap: 100 tokens
[info] - should handle empty message list
16:29:16.759 [pool-1-thread-1-ScalaTest-running-LLMCompressorSpec] INFO  org.llm4s.context.LLMCompressor$ -- Starting LLM digest squeeze with cap: 500 tokens
16:29:16.759 [pool-1-thread-1-ScalaTest-running-LLMCompressorSpec] INFO  org.llm4s.context.LLMCompressor$ -- Starting LLM digest squeeze with cap: 20 tokens
[info] - should handle single HISTORY_SUMMARY message
16:29:16.759 [pool-1-thread-1-ScalaTest-running-LLMCompressorSpec] INFO  org.llm4s.context.LLMCompressor$ -- Found 2 [HISTORY_SUMMARY] messages to squeeze
16:29:16.759 [pool-1-thread-1-ScalaTest-running-LLMCompressorSpec] INFO  org.llm4s.context.LLMCompressor$ -- Digest squeeze complete: 292  44 tokens
[info] - should handle multiple HISTORY_SUMMARY messages
[info] TracingConfigSpec:
[info] Llm4sConfig.tracing (Langfuse settings)
[info] - should provide defaults when not configured
[info] - should load overridden values from -D llm4s.tracing.langfuse.*
[info] S3DocumentSourceSpec:
[info] S3DocumentSource
[info] - should use default extensions
[info] - should allow custom extensions
[info] - should use default region
[info] - should allow custom region
[info] - should use empty prefix by default
[info] - should allow custom prefix
[info] - should allow endpoint override for LocalStack
[info] S3DocumentSource.withCredentials
[info] - should create source with explicit credentials
[info] S3DocumentSource.forLocalStack
[info] - should create source configured for LocalStack
[info] - should allow custom port
[info] S3DocumentSource.withPrefix
[info] - should create copy with new prefix
[info] S3DocumentSource.withExtensions
[info] - should create copy with new extensions
[info] S3DocumentSource.withMetadata
[info] - should create copy with additional metadata
[info] S3DocumentSource.withEndpoint
[info] - should create copy with endpoint override
[info] S3DocumentSource.description
[info] - should include bucket and prefix
[info] - should handle empty prefix
[info] S3DocumentSource.estimatedCount
[info] - should return None (S3 doesn't provide cheap count)
[info] S3DocumentSource.defaultExtensions
[info] - should include common document types
[info] ProviderConfigSpec:
[info] - OpenAIConfig.fromValues creates config with correct model
[info] - OpenAIConfig.fromValues sets correct context window for gpt-4o
[info] - OpenAIConfig.fromValues sets correct context window for gpt-4
[info] - OpenAIConfig.fromValues throws for empty apiKey
[info] - OpenAIConfig.fromValues throws for empty baseUrl
[info] - AnthropicConfig.fromValues creates config with correct model
[info] - AnthropicConfig.fromValues sets large context window for claude-3
[info] - AnthropicConfig.fromValues throws for empty apiKey
[info] - AzureConfig.fromValues creates config with correct model
[info] - AzureConfig.fromValues throws for empty endpoint
[info] - OllamaConfig.fromValues creates config with correct model
[info] - OllamaConfig.fromValues sets correct context window for llama2
[info] - OllamaConfig.fromValues sets context window for mistral
[info] - OllamaConfig.fromValues throws for empty baseUrl
[info] - OllamaConfig.fromValues sets reserveCompletion for all models
[info] - All config types implement ProviderConfig trait
[info] AnthropicVisionClientTest:
[info] AnthropicVisionClient
[info] - should detect media type correctly
[info] - should encode image to base64 successfully
[info] - should fail to encode non-existent image
[info] - should analyze image with default prompt
[info] - should analyze image with custom prompt
[info] - should extract text from image
[info] - should detect objects in image
[info] - should generate tags for image
[info] - should delegate preprocessing to local processor
[info] - should delegate format conversion to local processor
[info] - should delegate resizing to local processor
[info] - should handle file not found error
[info] - should handle invalid image file error
[info] - should use correct media type in API call
[info] SemanticBlocksSpec:
[info] SemanticBlocks.groupIntoSemanticBlocks
[info] - should pair user and assistant messages into blocks
[info] - should handle standalone assistant messages
[info] - should include tool messages in the current block
[info] - should create system message blocks
[info] - should handle empty message list
[info] - should handle consecutive user messages
[info] - should handle consecutive assistant messages
[info] - should handle tool message without preceding user message
[info] SemanticBlock
[info] - should add assistant message and clear expecting flag
[info] - should add tool message without changing expecting flag
[info] - should provide meaningful block summary
[info] SemanticBlock.startUserBlock
[info] - should create block expecting response
[info] SemanticBlock.standaloneAssistant
[info] - should create non-expecting block
[info] SemanticBlock.standaloneTool
[info] - should create tool block
[info] SemanticBlocks
[info] - should handle realistic multi-turn conversation
[info] - should preserve message order within blocks
[info] Llm4sConfigCrossVersionSpec:
[info] PureConfig
[info] - should load a simple nested configuration identically in Scala 2 and Scala 3
[info] - should support overriding values via HOCON merging
[info] EnhancedErrorMessagesTest:
[info] Enhanced error messages
[info] - should clearly indicate null arguments
[info] Enhanced error messages
[info] - should clearly indicate missing required parameters
[info] Enhanced error messages
[info] - should clearly indicate null values for required parameters
[info] Enhanced error messages
[info] - should clearly indicate type mismatches
[info] Enhanced error messages
[info] - should handle execution errors consistently
[info] ToolParameterError messages
[info] - should be clear and consistent
[info] ToolCallError messages
[info] - should have consistent format
[info] SafeParameterExtractor (enhanced mode)
[info] - should provide helpful information about available properties
[info] SafeParameterExtractor (enhanced mode)
[info] - should handle nested parameters correctly
[info] SafeParameterExtractor (enhanced mode)
[info] - should handle optional parameters correctly
[info] Tacotron2AdapterTest:
--text hi --out /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/llm4s-tts-17413086732204902423.wav --voice v --lang en --rate 1.1 --pitch 2.0 --gain 3.0
[info] - options assemble CLI flags
[info] ErrorRecoverySpec:
[info] ErrorRecovery.recoverWithBackoff
[info] - should return success immediately on first try
[info] - should retry on recoverable errors
[info] - should not retry on non-recoverable errors
[info] - should return ExecutionError after max attempts
[info] - should retry on TimeoutError
[info] - should use retry delay from RateLimitError when available
[info] CircuitBreaker
[info] - should start in Closed state
[info] - should allow successful calls in Closed state
[info] - should track failures in Closed state
[info] - should open after reaching failure threshold
[info] - should reset failure count on success
[info] - should transition from Open to HalfOpen after recovery timeout
[info] - should close circuit on success in HalfOpen state
[info] - should reopen circuit on failure in HalfOpen state
[info] - should work with default parameters
[info] CircuitState
[info] - should have Closed, Open, and HalfOpen states
[info] ErrorRecovery
[info] - should handle mixed error types correctly
[info] - should combine with CircuitBreaker for comprehensive error handling
[info] StreamingAccumulatorTest:
[info] - should accumulate content from multiple chunks
[info] - should handle chunks with no content
[info] - should track message ID
[info] - should accumulate tool calls
[info] - should track finish reason
[info] - should update token counts
[info] - should create completion with accumulated data
[info] - should clear accumulator state
[info] - should create snapshot of current state
[info] - should handle partial tool call accumulation
[info] - should assemble tool call arguments from raw JSON fragments
[info] - should accumulate thinking content from chunks
[info] - should return None for thinking when no thinking content
[info] - should handle mixed content and thinking chunks
[info] - should include thinking in completion
[info] - should add thinking delta directly
[info] - should track thinking tokens
[info] - should include thinking tokens in snapshot
[info] - should clear thinking content on clear
[info] ConsoleInterfaceSpec:
[info] MessageType
[info] - should have Info type
[info] - should have Success type
[info] - should have Warning type
[info] - should have Error type
[info] - should have AssistantResponse type
[info] - should have Show instance
[info] ConsoleConfig
[info] - should have sensible defaults
[info] - should have color scheme for all message types
[info] - should allow custom prompt symbols
[info] - should allow custom color scheme
[info] ConsoleConfig.StyleConfig
[info] - should have sensible defaults
[info] - should allow custom styles
[info] - should be included in ConsoleConfig
[info] - should allow custom styles in ConsoleConfig
[info] ShowInstances.showAssistantError
[info] - should format IO errors
[info] - should format EOF errors
[info] - should format Display errors
[info] - should format other errors using message
[info] ShowInstances.showLLMError
[info] - should format LLM errors
[info] SemanticChunkerSpec:
[info] SemanticChunker
[info] - should have correct default values
[info] - should create chunker with default parameters
[info] - should create chunker with custom similarity threshold
[info] - should create chunker with custom batch size
[info] - should reject invalid similarity threshold
[info] - should reject invalid batch size
[info] - should handle empty text
[info] - should return single chunk for short text
[info] - should split at topic boundaries based on embedding similarity
[info] - should preserve abbreviations when splitting sentences
[info] - should handle decimal numbers
[info] - should force split very long single sentences
[info] - should assign sequential indices
[info] - should respect minimum chunk size
[info] - should handle text with no sentence boundaries
[info] ChunkerFactory
[info] - should create semantic chunker
[info] - should create semantic chunker with custom parameters
[info] - should fall back to sentence chunker when creating by name without embedding client
[info] - should fall back to sentence chunker when creating by strategy enum without embedding client
[info] AnthropicRequestBodySpec:
[info] AnthropicRequestBody
[info] - should correctly serialize request with prompt and image data
[info] - should correctly serialize with PNG media type
[info] - should correctly serialize with WebP media type
[info] - should be serializable and deserializable
[info] - should produce valid JSON structure for API consumption
[info] PgSearchIndexSpec:
[info] PgPrincipalStore
[info] - should create and lookup users !!! CANCELED !!!
[info]   PgSearchIndexSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (PgSearchIndexSpec.scala:55)
[info] - should create groups with negative IDs !!! CANCELED !!!
[info]   PgSearchIndexSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (PgSearchIndexSpec.scala:55)
[info] - should return existing ID on duplicate getOrCreate !!! CANCELED !!!
[info]   PgSearchIndexSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (PgSearchIndexSpec.scala:55)
[info] - should support batch operations !!! CANCELED !!!
[info]   PgSearchIndexSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (PgSearchIndexSpec.scala:55)
[info] PgCollectionStore
[info] - should create and retrieve collections !!! CANCELED !!!
[info]   PgSearchIndexSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (PgSearchIndexSpec.scala:55)
[info] - should create hierarchical collections !!! CANCELED !!!
[info]   PgSearchIndexSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (PgSearchIndexSpec.scala:55)
[info] - should reject child permissions that are not subset of parent !!! CANCELED !!!
[info]   PgSearchIndexSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (PgSearchIndexSpec.scala:55)
[info] - should allow child permissions that are subset of parent !!! CANCELED !!!
[info]   PgSearchIndexSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (PgSearchIndexSpec.scala:55)
[info] - should list collections by pattern !!! CANCELED !!!
[info]   PgSearchIndexSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (PgSearchIndexSpec.scala:55)
[info] - should filter accessible collections by user permissions !!! CANCELED !!!
[info]   PgSearchIndexSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (PgSearchIndexSpec.scala:55)
[info] - should update collection permissions !!! CANCELED !!!
[info]   PgSearchIndexSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (PgSearchIndexSpec.scala:55)
[info] - should delete collections !!! CANCELED !!!
[info]   PgSearchIndexSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (PgSearchIndexSpec.scala:55)
[info] - should get collection stats !!! CANCELED !!!
[info]   PgSearchIndexSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (PgSearchIndexSpec.scala:55)
[info] PgSearchIndex
[info] - should ingest and query with permissions !!! CANCELED !!!
[info]   PgSearchIndexSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (PgSearchIndexSpec.scala:55)
[info] - should respect document-level readable_by permissions !!! CANCELED !!!
[info]   PgSearchIndexSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (PgSearchIndexSpec.scala:55)
[info] - should delete documents correctly !!! CANCELED !!!
[info]   PgSearchIndexSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (PgSearchIndexSpec.scala:55)
[info] - should allow same documentId in different collections without overwriting !!! CANCELED !!!
[info]   PgSearchIndexSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (PgSearchIndexSpec.scala:55)
[info] PgSchemaManager
[info] - should be idempotent !!! CANCELED !!!
[info]   PgSearchIndexSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (PgSearchIndexSpec.scala:55)
[info] ConfigReaderPrecedenceSpec:
[info] LLMConfig
[info] - should read llm4s.* values from test application.conf
[info] - should allow -D system property to override application.conf
[info] PgVectorStoreSpec:
[info] PgVectorStore
[info] - should store and retrieve a single record
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should return None for non-existent record
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should upsert (replace) existing record
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should store multiple records in batch
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should delete a record
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should delete multiple records in batch
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should clear all records
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should search by vector similarity
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should filter records by metadata
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should combine filters with AND/OR
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should return correct statistics
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should paginate results with list
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should search with metadata filter
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] PgVectorStore factory
[info] - should create store from config
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] PIIGuardrailSpec:
[info] PIIPatterns
[info] - should detect SSN in various formats
[info] - should not detect invalid SSNs
[info] - should detect credit card numbers
[info] - should detect email addresses
[info] - should detect phone numbers
[info] - should detect IP addresses
[info] - should mask detected PII with placeholders
[info] - should return original text when no PII found
[info] - should provide summary of detected PII
[info] PIIDetector
[info] - should block when PII is detected (default mode)
[info] - should pass when no PII is present
[info] - should mask PII when in Fix mode
[info] - should allow processing in Warn mode
[info] - should detect only specified PII types
[info] - should work with strict preset
[info] - should work with masking preset
[info] - should work with financial preset
[info] PIIMasker
[info] - should always mask PII and never block
[info] - should return unchanged text when no PII present
[info] - should mask only specified PII types
[info] - should work with transform method
[info] - should detect if text contains PII
[info] - should provide summary of PII to be masked
[info] - should work with financial preset
[info] - should work with contactInfo preset
[info] GuardrailAction
[info] - should have Block as default
[info] GuardrailResult
[info] - should correctly report success status
[info] - should correctly report blocked status
[info] - should correctly report warnings
[info] - should extract value via toOption
[info] PIIDetector
[info] - should work with CompositeGuardrail.all
[info] - should work in a pipeline with PIIMasker
[info] UniversalEncoderSpec:
16:30:49.273 [pool-1-thread-1-ScalaTest-running-UniversalEncoderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/test-encoder-15076808651112981036.txt (MIME: text/plain)
[info] - encodeFromPath should encode text file content
16:30:49.279 [pool-1-thread-1-ScalaTest-running-UniversalEncoderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/test-encoder-9214172516371784105.txt (MIME: text/plain)
[info] - encodeFromPath should chunk text when chunking is enabled
[info] - encodeFromPath should return error for non-existent file
16:30:49.282 [pool-1-thread-1-ScalaTest-running-UniversalEncoderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/test-encoder-12728892726132474640.json (MIME: application/json)
16:30:49.289 [pool-1-thread-1-ScalaTest-running-UniversalEncoderSpec] ERROR o.l.l.extractors.UniversalExtractor$ -- [UnknownType] No text extractor for MIME type: application/json
[info] - encodeFromPath processes JSON-like text files
16:30:49.293 [pool-1-thread-1-ScalaTest-running-UniversalEncoderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/test-encoder-5361628480462740216.txt (MIME: text/plain)
[info] - encodeFromPath with experimental stubs handles various content
16:30:49.295 [pool-1-thread-1-ScalaTest-running-UniversalEncoderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/test-encoder-12475706603884479310.txt (MIME: text/plain)
[info] - encodeFromPath should include correct metadata in vectors
16:30:49.300 [pool-1-thread-1-ScalaTest-running-UniversalEncoderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/test-encoder-15413942149670584986.txt (MIME: text/plain)
[info] - encodeFromPath should generate chunk IDs
16:30:49.302 [pool-1-thread-1-ScalaTest-running-UniversalEncoderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/test-encoder-10120243199587226832.txt (MIME: text/plain)
[info] - encodeFromPath should return normalized vectors
[info] ZeroParameterToolTest:
[info] Zero-parameter tool
[info] - should work with empty object arguments
[info] Zero-parameter tool
[info] - should accept null arguments and treat them as empty object
[info] Zero-parameter tool schema
[info] - should generate correct JSON schema
[info] Multiple zero-parameter tools
[info] - should work correctly
[info] Zero-parameter tool handler
[info] - should not attempt to extract any parameters
[info] Tool with required parameters
[info] - should still reject null arguments
[info] Llm4sConfigTracingSpec:
[info] Llm4sConfig.tracing
[info] - should load tracing settings from llm4s.* defaults
[info] DocumentRefSpec:
[info] DocumentRef
[info] - should extract extension from path
[info] - should handle no extension
[info] - should extract filename from path
[info] - should handle path without slashes
[info] - should convert to DocumentVersion when etag is present
[info] - should return None for toVersion when no etag
[info] CommandSpec:
[info] Command.parse
[info] - should parse /help command
[info] - should parse /help with extra text
[info] - should be case insensitive for /help
[info] - should parse /new command
[info] - should parse /new with extra text
[info] - should be case insensitive for /new
[info] - should parse /save with title
[info] - should parse /save with multi-word title
[info] - should parse /save without title using default
[info] - should parse /save with only whitespace using default
[info] - should be case insensitive for /save
[info] - should parse /load with title
[info] - should parse /load with quoted title
[info] - should parse /load with multi-word title
[info] - should return error for /load without title
[info] - should return error for /load with only whitespace
[info] - should be case insensitive for /load
[info] - should parse /sessions command
[info] - should parse /sessions with extra text
[info] - should be case insensitive for /sessions
[info] - should parse /quit command
[info] - should parse /quit with extra text
[info] - should be case insensitive for /quit
[info] - should return error for unknown commands
[info] - should return error for non-command input
[info] - should return error for empty command
[info] - should return error for invalid slash commands
[info] MemoryFilterSpec:
[info] MemoryFilter.All
[info] - should match all memories
[info] MemoryFilter.None
[info] - should match no memories
[info] MemoryFilter.ByType
[info] - should filter by memory type
[info] MemoryFilter.ByTypes
[info] - should filter by multiple memory types
[info] MemoryFilter.ByMetadata
[info] - should filter by exact metadata match
[info] MemoryFilter.HasMetadata
[info] - should filter by metadata key existence
[info] MemoryFilter.MetadataContains
[info] - should filter by metadata substring
[info] MemoryFilter.ByEntity
[info] - should filter by entity ID
[info] MemoryFilter.ByConversation
[info] - should filter by conversation ID
[info] MemoryFilter.ByTimeRange
[info] - should filter by timestamp range
[info] MemoryFilter.MinImportance
[info] - should filter by importance threshold
[info] MemoryFilter.ContentContains
[info] - should filter by content substring
[info] - should be case-sensitive when configured
[info] MemoryFilter.And
[info] - should combine filters with AND logic
[info] MemoryFilter.Or
[info] - should combine filters with OR logic
[info] MemoryFilter.Not
[info] - should negate a filter
[info] MemoryFilter operators
[info] - should support && operator
[info] - should support || operator
[info] - should support unary_! operator
[info] MemoryFilter.Custom
[info] - should support custom predicates
[info] MemoryFilter convenience methods
[info] - should provide shorthand filters
[info] MemoryFilter.all
[info] - should combine multiple filters with AND
[info] MemoryFilter.any
[info] - should combine multiple filters with OR
[info] - should return None filter for empty sequence
[info] GlobPatternMatcherSpec:
[info] GlobPatternMatcher.matches
[info] - should match literal strings
[info] - should match single asterisk wildcard (non-path-crossing)
[info] - should match double asterisk wildcard (path-crossing)
[info] - should match question mark wildcard (single char)
[info] - should escape regex special characters
[info] - should be case insensitive
[info] GlobPatternMatcher.matchesAny
[info] - should return true if any pattern matches
[info] - should handle empty patterns list
[info] GlobPatternMatcher.filter
[info] - should filter URLs by include and exclude patterns
[info] - should include all when include patterns is empty
[info] LLMConnectEnvReaderRoutingTest:
[info] - LLMConnect.getClient returns OpenRouterClient when OpenAI baseUrl points to openrouter.ai
[info] - LLMConnect.getClient returns OllamaClient for Ollama provider
[info] PoliciesSpec:
[info] Policies.withRetry
16:30:49.337 [scala-execution-context-global-77] WARN  o.l.agent.orchestration.Policies$ -- Agent flaky failed on attempt 1 of 3, retrying: NodeExecutionError: Node execution failed [flaky:flaky]: Temporary failure[component=node-execution,nodeId=flaky,nodeName=flaky,recoverable=true]
16:30:49.349 [scala-execution-context-global-74] WARN  o.l.agent.orchestration.Policies$ -- Agent flaky failed on attempt 2 of 3, retrying: NodeExecutionError: Node execution failed [flaky:flaky]: Temporary failure[component=node-execution,nodeId=flaky,nodeName=flaky,recoverable=true]
16:30:49.374 [scala-execution-context-global-74] INFO  o.l.agent.orchestration.Policies$ -- Agent flaky succeeded on attempt 3 of 3
[info] - should retry recoverable failures
16:30:49.375 [scala-execution-context-global-74] ERROR o.l.agent.orchestration.Policies$ -- Agent non-recoverable-failure failed with non-recoverable error on attempt 1: PlanValidationError(Plan validation failed: Non-recoverable error,None,List())
[info] Policies.withRetry
[info] - should not retry non-recoverable failures
[info] Policies.withRetry
[info] - should succeed immediately if first attempt succeeds
[info] Policies.withTimeout
16:30:49.480 [scala-execution-context-global-77] WARN  o.l.agent.orchestration.Policies$ -- Agent slow timed out after 100 milliseconds
[info] - should timeout slow operations
[info] Policies.withTimeout
[info] - should succeed for fast operations
[info] Policies.withFallback
16:30:49.492 [scala-execution-context-global-76] WARN  o.l.agent.orchestration.Policies$ -- Primary agent recoverable-failure failed, trying fallback fallback: NodeExecutionError(Node execution failed [test:recoverable]: Recoverable error,test,recoverable,None,true)
16:30:49.492 [scala-execution-context-global-76] INFO  o.l.agent.orchestration.Policies$ -- Fallback agent fallback succeeded after primary recoverable-failure failed
[info] - should use fallback when primary fails
[info] Policies.withFallback
[info] - should use primary when it succeeds
[info] Policies.withFallback
16:30:49.493 [scala-execution-context-global-77] WARN  o.l.agent.orchestration.Policies$ -- Primary agent primary failed, trying fallback fallback: NodeExecutionError(Node execution failed [primary:primary]: Primary failure,primary,primary,None,true)
16:30:49.493 [scala-execution-context-global-77] ERROR o.l.agent.orchestration.Policies$ -- Both primary primary and fallback fallback agents failed. Primary: NodeExecutionError(Node execution failed [primary:primary]: Primary failure,primary,primary,None,true), Fallback: NodeExecutionError(Node execution failed [fallback:fallback]: Fallback failure,fallback,fallback,None,true)
[info] - should return primary error when both fail
[info] Policies.withPolicies
16:30:49.494 [scala-execution-context-global-75] WARN  o.l.agent.orchestration.Policies$ -- Agent policy-test-timeout failed on attempt 1 of 3, retrying: NodeExecutionError: Node execution failed [test:test]: Temporary failure[component=node-execution,nodeId=test,nodeName=test,recoverable=true]
16:30:49.507 [scala-execution-context-global-75] WARN  o.l.agent.orchestration.Policies$ -- Agent policy-test-timeout failed on attempt 2 of 3, retrying: NodeExecutionError: Node execution failed [test:test]: Temporary failure[component=node-execution,nodeId=test,nodeName=test,recoverable=true]
16:30:49.529 [scala-execution-context-global-74] INFO  o.l.agent.orchestration.Policies$ -- Agent policy-test-timeout succeeded on attempt 3 of 3
[info] - should combine multiple policies correctly
16:30:49.530 [scala-execution-context-global-75] WARN  o.l.agent.orchestration.Policies$ -- Agent always-failing failed on attempt 1 of 2, retrying: NodeExecutionError: Node execution failed [failing:failing]: Always fails[component=node-execution,nodeId=failing,nodeName=failing,recoverable=true]
16:30:49.531 [scala-execution-context-global-75] ERROR o.l.agent.orchestration.Policies$ -- Agent always-failing exhausted all 2 attempts, final error: NodeExecutionError(Node execution failed [failing:failing]: Always fails,failing,failing,None,true)
16:30:49.531 [scala-execution-context-global-77] WARN  o.l.agent.orchestration.Policies$ -- Primary agent always-failing-retry failed, trying fallback fallback: NodeExecutionError(Node execution failed [failing:failing]: Always fails,failing,failing,None,true)
16:30:49.531 [scala-execution-context-global-77] INFO  o.l.agent.orchestration.Policies$ -- Fallback agent fallback succeeded after primary always-failing-retry failed
[info] Policies.withPolicies
[info] - should use fallback when retries are exhausted
[info] Policy composition
16:30:49.582 [scala-execution-context-global-74] WARN  o.l.agent.orchestration.Policies$ -- Agent slow-then-success timed out after 50 milliseconds
16:30:49.582 [scala-execution-context-global-74] ERROR o.l.agent.orchestration.Policies$ -- Agent slow-then-success-timeout failed with non-recoverable error on attempt 1: AgentTimeoutError(Agent 'slow-then-success' timed out after 50ms,slow-then-success,50)
16:30:49.582 [scala-execution-context-global-74] WARN  o.l.agent.orchestration.Policies$ -- Primary agent slow-then-success-timeout-retry failed, trying fallback fallback: AgentTimeoutError(Agent 'slow-then-success' timed out after 50ms,slow-then-success,50)
16:30:49.582 [scala-execution-context-global-74] INFO  o.l.agent.orchestration.Policies$ -- Fallback agent fallback succeeded after primary slow-then-success-timeout-retry failed
[info] - should have correct ordering (timeout -> retry -> fallback)
[info] FaithfulnessSpec:
[info] Faithfulness
[info] - should have correct metadata
[info] - should return score 1.0 when all claims are supported
[info] - should return score 0.5 when half claims are supported
[info] - should return score 0.0 when no claims are supported
[info] - should return score 1.0 for empty answer (no claims to verify)
[info] - should return score 0.0 when no contexts provided
[info] - should return score 1.0 when no claims extracted
[info] - should handle JSON response wrapped in markdown code blocks
[info] - should reject invalid batch size
[info] - should include details about claims in result
[info] VectorStoreSpec:
[info] VectorStore
[info] - should store and retrieve a single record
[info] - should return None for non-existent record
[info] - should upsert (replace) existing record
[info] - should store multiple records in batch
[info] - should delete a record
[info] - should delete multiple records in batch
[info] - should clear all records
[info] - should search by vector similarity
[info] - should filter records by metadata
[info] - should combine filters with AND/OR
[info] - should return correct statistics
[info] - should paginate results with list
[info] - should search with metadata filter
[info] VectorStoreFactory
[info] - should create in-memory SQLite store
[info] - should create store from config
[info] - should create store from provider name
[info] - should reject unknown provider
[info] VectorRecord
[info] - should create with auto-generated ID
[info] - should support metadata operations
[info] MetadataFilter
[info] - should support DSL syntax
[info] RAGWithSearchIndexBugSpec:
[info] RAGConfig.withSearchIndex with non-Pg SearchIndex
[info] - should NOT set pgVectorConnectionString (expected for non-Pg)
[info] RAGConfig.withSearchIndex with PgSearchIndex
[info] - should automatically configure pgVectorConnectionString (FIX) !!! CANCELED !!!
[info]   RAGWithSearchIndexBugSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (RAGWithSearchIndexBugSpec.scala:62)
[info] RAG created with non-Pg SearchIndex
[info] - should use in-memory storage for regular ingest (expected)
[info] PgSearchIndex used via withSearchIndex
[info] - should persist vectors that can be queried !!! CANCELED !!!
[info]   RAGWithSearchIndexBugSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (RAGWithSearchIndexBugSpec.scala:62)
[info] - should show that RAG.stats uses in-memory when only withSearchIndex is used (demonstrating the bug) !!! CANCELED !!!
[info]   RAGWithSearchIndexBugSpec.this.searchIndex.isDefined was false PostgreSQL with pgvector not available (RAGWithSearchIndexBugSpec.scala:62)
[info] ConversationConvenienceMethodsSpec:
[info] Conversation.fromPrompts
[info] - should create a valid conversation with system and user messages
[info] - should validate message content is not empty
[info] - should fail when user prompt is empty
[info] - should fail when both prompts are empty
[info] - should trim whitespace and fail on whitespace-only prompts
[info] - should preserve leading/trailing whitespace in valid prompts
[info] Conversation.userOnly
[info] - should create a valid conversation with single user message
[info] - should fail when prompt is empty
[info] - should fail when prompt is whitespace-only
[info] - should preserve leading/trailing whitespace in valid prompts
[info] Conversation.systemOnly
[info] - should create a valid conversation with single system message
[info] - should fail when prompt is empty
[info] - should fail when prompt is whitespace-only
[info] - should preserve leading/trailing whitespace in valid prompts
[info] Conversation.lastMessage
[info] - should return the last message in a conversation
[info] - should return None for an empty conversation
[info] - should return the only message in a single-message conversation
[info] Conversation.messageCount
[info] - should return correct count for multi-message conversation
[info] - should return 0 for empty conversation
[info] - should return 1 for single-message conversation
[info] Conversation.filterByRole
[info] - should filter user messages
[info] - should filter system messages
[info] - should filter assistant messages
[info] - should return empty sequence when no messages match role
[info] - should return empty sequence for empty conversation
[info] Convenience methods
[info] - should work together for common workflow
[info] - should chain operations functionally
[info] EmbeddingServiceSpec:
[info] MockEmbeddingService
[info] - should generate embeddings with correct dimensions
[info] - should generate normalized unit vectors
[info] - should generate deterministic embeddings for same content
[info] - should generate different embeddings for different content
[info] - should batch embed multiple texts
[info] FileSystemToolsSpec:
[info] FileConfig
[info] - should block system paths by default
[info] - should allow paths when allowedPaths is set
[info] - should block paths in blocklist even if in allowlist
[info] WriteConfig
[info] - should require explicit allowed paths
[info] ReadFileTool
[info] - should read existing files
[info] - should deny access to blocked paths
[info] - should return error for non-existent files
[info] - should limit lines when max_lines is specified
[info] ListDirectoryTool
[info] - should list directory contents
[info] - should hide hidden files by default
[info] - should include hidden files when requested
[info] FileInfoTool
[info] - should get file information
[info] - should report non-existent file info
[info] WriteFileTool
[info] - should write to allowed paths
[info] - should deny write to non-allowed paths
[info] - should support append mode
[info] DocumentLoaderSpec:
[info] Document
[info] - should create with auto-generated ID
[info] - should compute content hash for versioning
[info] - should preserve metadata when adding more
[info] DocumentVersion
[info] - should generate consistent hashes for same content
[info] - should generate different hashes for different content
[info] DocumentHints
[info] - should provide markdown preset
[info] - should provide code preset
[info] - should provide skip hint with reason
[info] TextLoader
[info] - should load documents from content
[info] - should create multiple documents from pairs
[info] - should build documents fluently
[info] FileLoader
[info] - should fail for non-existent files
[info] - should fail when path is a directory
16:30:49.648 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/test.txt (MIME: text/plain)
[info] - should successfully load a text file
16:30:49.649 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/test.txt (MIME: text/plain)
[info] - should detect prose hints for text files
16:30:49.650 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/readme.md (MIME: text/x-web-markdown)
[info] - should detect markdown hints for .md files
16:30:49.651 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/Example.scala (MIME: text/x-scala)
[info] - should detect code hints for .scala files
16:30:49.652 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/test.txt (MIME: text/plain)
[info] - should include version information
16:30:49.652 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/test.txt (MIME: text/plain)
[info] - should attach custom metadata
[info] - should have estimatedCount of 1
[info] - should provide description
[info] FileLoader companion object
[info] - should create from string path
[info] - should create from string path with metadata
[info] - should create from File object
[info] DirectoryLoader
[info] - should fail for non-existent directories
[info] - should fail when path is a file
16:30:49.655 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/Example.scala (MIME: text/x-scala)
16:30:49.656 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/readme.md (MIME: text/x-web-markdown)
16:30:49.656 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/test.txt (MIME: text/plain)
16:30:49.657 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/subdir/nested.txt (MIME: text/plain)
16:30:49.658 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/subdir/deep/deep.txt (MIME: text/plain)
[info] - should load files from directory
16:30:49.659 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/test.txt (MIME: text/plain)
16:30:49.659 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/subdir/nested.txt (MIME: text/plain)
16:30:49.660 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/subdir/deep/deep.txt (MIME: text/plain)
[info] - should filter by extensions
[info] - should add extension with withExtension
[info] - should strip dot from extensions
16:30:49.662 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/test.txt (MIME: text/plain)
16:30:49.663 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/subdir/nested.txt (MIME: text/plain)
16:30:49.664 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/subdir/deep/deep.txt (MIME: text/plain)
16:30:49.664 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/test.txt (MIME: text/plain)
[info] - should load non-recursively when recursive is false
16:30:49.677 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/test.txt (MIME: text/plain)
16:30:49.678 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/test.txt (MIME: text/plain)
16:30:49.679 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/subdir/nested.txt (MIME: text/plain)
16:30:49.680 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/subdir/deep/deep.txt (MIME: text/plain)
[info] - should respect maxDepth
16:30:49.680 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/test.txt (MIME: text/plain)
16:30:49.681 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/subdir/nested.txt (MIME: text/plain)
16:30:49.681 [pool-1-thread-1-ScalaTest-running-DocumentLoaderSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/document-loader-test4709533073541806380/subdir/deep/deep.txt (MIME: text/plain)
[info] - should attach metadata to all documents
[info] - should provide estimated count
[info] - should return None for estimated count on non-existent directory
[info] - should provide description
[info] DirectoryLoader companion object
[info] - should create from string path
[info] - should create from string path with extensions
[info] - should create from File object
[info] - should have default extensions
[info] DirectoryLoader.markdown
[info] - should only load markdown files
[info] DirectoryLoader.code
[info] - should load code files
[info] DirectoryLoader.text
[info] - should only load text files
[info] DirectoryLoader.pdf
[info] - should only load PDF files
[info] DirectoryLoader.docx
[info] - should only load Word documents
[info] DocumentLoaders.combine
[info] - should combine multiple loaders
[info] DocumentLoaders.filter
[info] - should filter documents by predicate
[info] DocumentLoaders.map
[info] - should transform documents
[info] DocumentLoaders.take
[info] - should limit number of documents
[info] DocumentLoader.++
[info] - should combine loaders using operator
[info] LoadResult
[info] - should create success results
[info] - should create failure results
[info] - should create skipped results
[info] LoadStats
[info] - should calculate derived statistics
[info] - should report no errors when all successful
[info] SyncStats
[info] - should calculate total and changed counts
[info] InMemoryDocumentRegistry
[info] - should register and retrieve versions
[info] - should return None for unknown documents
[info] - should unregister documents
[info] - should list all document IDs
[info] - should clear all registrations
[info] LoadingConfig
[info] - should have sensible defaults
[info] - should provide strict preset
[info] - should provide lenient preset
[info] - should provide high performance preset
[info] - should support fluent configuration
[info] DocumentLoaders.empty
[info] - should return no documents
[info] DocumentLoaders.successesOnly
[info] - should filter out failures and skips
[info] DocumentLoaders.fromIterator
[info] - should create loader from iterator
[info] - should use default description
[info] DocumentLoaders.fromDocuments
[info] - should create loader from sequence
[info] DocumentLoaders.defer
[info] - should lazily create the loader
[info] - should cache the underlying loader
[info] DocumentLoaders.withMetadata
[info] - should add metadata to all documents
[info] DocumentLoaders.withHints
[info] - should add hints to all documents
[info] - should merge with existing hints
[info] DocumentLoaders.drop
[info] - should skip first n documents
[info] - should handle drop more than available
[info] - should update estimatedCount correctly
[info] DocumentLoaders.combine estimatedCount
[info] - should sum all counts when all defined
[info] - should return None when any count is undefined
[info] DocumentLoaders.filter
[info] - should preserve errors in output
[info] DocumentLoaders.map
[info] - should preserve errors
[info] - should preserve estimatedCount
[info] DocumentLoaders.take
[info] - should update estimatedCount
[info] - should not exceed original count
[info] TextLoader.empty
[info] - should return no documents
[info] TextLoader.apply(content)
[info] - should create with auto-generated ID
[info] TextLoader.apply(content, id, metadata)
[info] - should create with metadata
[info] TextLoader.fromMap
[info] - should create from ID -> content map
[info] TextLoader.fromContents
[info] - should create with auto-generated IDs
[info] TextLoader.withDocument(doc)
[info] - should add a document
[info] TextLoaderBuilder.add(doc)
[info] - should add a document object
[info] LoadResult.isSuccess
[info] - should return correct values
[info] LoadResult.isFailure
[info] - should return correct values
[info] LoadResult.isSkipped
[info] - should return correct values
[info] LoadResult.toOption
[info] - should return Some for success, None otherwise
[info] Document.length
[info] - should return content length
[info] Document.isEmpty
[info] - should return true for empty content
[info] Document.nonEmpty
[info] - should return true for non-empty content
[info] LoadStats.formattedErrors
[info] - should return formatted error list
[info] - should return empty string when no errors
[info] SyncStats.hasChanges
[info] - should return true when any changes
[info] DocumentHints.merge
[info] - should combine hints with skipReason
[info] - should prefer this instance's values over other
[info] DocumentHints.shouldSkip
[info] - should return true when skip reason is set
[info] DocumentVersion.isDifferentFrom
[info] - should detect changes
[info] LoadingConfig.withContinueOnError
[info] - should set failFast to false
[info] LoadingConfig.withVersioning
[info] - should enable versioning
[info] - should disable versioning
[info] LoadingConfig.withSkipEmpty
[info] - should enable skip empty
[info] - should disable skip empty
[info] LoadingConfig.withHints
[info] - should enable hints
[info] - should disable hints
[info] LoadingConfig.conservative
[info] - should have lower parallelism
[info] PgKeywordIndexSpec:
[info] PgKeywordIndex
[info] - should index and retrieve a single document
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should return None for non-existent document
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should upsert (replace) existing document
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should index multiple documents in batch
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should search for matching documents
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should rank results by relevance
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should search with phrase matching using quotes
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should search with OR operator
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should search with highlighted snippets
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should filter results by metadata
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should delete a document
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should delete multiple documents in batch
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should delete documents by ID prefix
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should clear all documents
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should return correct statistics
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should handle empty search query gracefully
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should handle empty batch operations
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should combine metadata filters with AND
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should combine metadata filters with OR
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should handle special characters in content
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should handle metadata with special characters
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] PgKeywordIndex factory
[info] - should create index from config
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] - should create index from JDBC URL
[info]   + Skipping test - PGVECTOR_TEST_URL not set 
[info] AgentStateSpec:
[info] AgentState.addMessage
[info] - should add a single message to conversation
[info] - should append to existing messages
[info] - should not mutate original state
[info] AgentState.addMessages
[info] - should add multiple messages at once
[info] - should handle empty sequence
[info] AgentState.log
[info] - should add log entry
[info] - should append to existing logs
[info] AgentState.withStatus
[info] - should update status
[info] - should update to Failed status with error
[info] AgentState.toApiConversation
[info] - should inject system message at beginning
[info] - should return conversation as-is when no system message
[info] AgentState.pruneConversation with OldestFirst
[info] - should not prune when under limit
[info] - should remove oldest messages when over limit
[info] - should preserve system message when configured
[info] AgentState.pruneConversation with MiddleOut
[info] - should keep start and end messages
[info] - should preserve system message when configured
[info] AgentState.pruneConversation with RecentTurnsOnly
[info] - should keep only recent turns
[info] - should keep all turns when fewer than limit
[info] - should preserve system message when configured
[info] AgentState.pruneConversation with Custom
[info] - should apply custom function
[info] AgentState.pruneConversation with token limit
[info] - should prune based on token count
[info] AgentState.saveToFile and loadFromFile
[info] - should round-trip state to file
[info] - should return error for non-existent file
[info] - should return error for invalid JSON
[info] AgentState
[info] - should handle empty conversation
[info] - should chain multiple operations
[info] - should preserve tools reference through operations
[info] - should preserve completionOptions through operations
[info] RAGAsyncSpec:
[info] ingestAsync
[info] - should complete a Future
[info] syncAsync
[info] - should support change detection structure
[info] LoadStats.fromResults
[info] - should aggregate results correctly
[info] SyncStats
[info] - should track changes correctly
[info] - should report no changes when empty
[info] LoadingConfig
[info] - should configure parallelism for async operations
[info] - should support custom parallelism settings
[info] Future operations
[info] - should work with execution context
[info] - should support Future.sequence for batch processing pattern
[info] DocumentFormatSpec:
[info] DocumentFormat.fromMimeType
[info] - should convert PDF MIME type
[info] - should convert DOCX MIME type
[info] - should convert text MIME types
[info] - should convert JSON and XML
[info] - should return Unknown for unrecognized types
[info] DocumentFormat.fromExtension
[info] - should detect format from file extension
[info] - should handle case insensitivity
[info] - should return Unknown for unrecognized extensions
[info] SessionManagerSpec:
[info] SessionManager.saveSession
16:30:49.712 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session test-session with title: Test Session
16:30:49.716 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test4144242209919423549/Test_Session.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test4144242209919423549/Test_Session.md
[info] - should save session with default title
16:30:49.718 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session test-session with title: My Session
16:30:49.718 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test13746696879985674677/My_Session.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test13746696879985674677/My_Session.md
[info] - should create both JSON and markdown files
[info] - should return error when no agent state to save
16:30:49.719 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session test-session with title: Test/Session:With*Special?Chars
16:30:49.719 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test2648627977789953050/Test_Session_With_Special_Chars.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test2648627977789953050/Test_Session_With_Special_Chars.md
[info] - should sanitize special characters in title
[info] SessionManager.loadSession
16:30:49.720 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session original-session with title: LoadTest
16:30:49.720 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test11859659451468642865/LoadTest.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test11859659451468642865/LoadTest.md
16:30:49.721 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully loaded session: LoadTest from /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test11859659451468642865/LoadTest.json
[info] - should load previously saved session
16:30:49.722 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session test-session with title: ContentTest
16:30:49.722 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test5562985598935392298/ContentTest.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test5562985598935392298/ContentTest.md
16:30:49.722 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully loaded session: ContentTest from /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test5562985598935392298/ContentTest.json
[info] - should preserve conversation content
[info] - should return error for non-existent session
[info] SessionManager.listRecentSessions
16:30:49.723 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session s1 with title: Session1
16:30:49.723 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test9180010082631067246/Session1.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test9180010082631067246/Session1.md
16:30:49.733 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session s2 with title: Session2
16:30:49.734 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test9180010082631067246/Session2.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test9180010082631067246/Session2.md
16:30:49.747 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session s3 with title: Session3
16:30:49.747 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test9180010082631067246/Session3.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test9180010082631067246/Session3.md
[info] - should list saved sessions
16:30:49.748 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session s1 with title: Session1
16:30:49.749 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session1.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session1.md
16:30:49.755 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session s2 with title: Session2
16:30:49.755 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session2.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session2.md
16:30:49.762 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session s3 with title: Session3
16:30:49.762 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session3.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session3.md
16:30:49.768 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session s4 with title: Session4
16:30:49.769 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session4.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session4.md
16:30:49.775 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session s5 with title: Session5
16:30:49.776 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session5.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session5.md
16:30:49.782 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session s6 with title: Session6
16:30:49.783 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session6.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session6.md
16:30:49.788 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session s7 with title: Session7
16:30:49.789 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session7.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session7.md
16:30:49.795 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session s8 with title: Session8
16:30:49.796 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session8.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session8.md
16:30:49.802 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session s9 with title: Session9
16:30:49.803 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session9.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session9.md
16:30:49.810 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session s10 with title: Session10
16:30:49.811 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session10.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14403237994709860895/Session10.md
[info] - should limit number of results
16:30:49.819 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session s1 with title: OldSession
16:30:49.820 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test15185253987167493085/OldSession.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test15185253987167493085/OldSession.md
16:30:49.870 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session s2 with title: NewSession
16:30:49.871 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test15185253987167493085/NewSession.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test15185253987167493085/NewSession.md
[info] - should return most recent sessions first
[info] - should return empty list for empty directory
[info] SessionManager
16:30:49.872 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session log-test with title: LogTest
16:30:49.872 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test4984824329525070538/LogTest.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test4984824329525070538/LogTest.md
16:30:49.873 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully loaded session: LogTest from /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test4984824329525070538/LogTest.json
[info] - should round-trip session with logs
16:30:49.873 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session query-test with title: QueryTest
16:30:49.873 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14370401179699515950/QueryTest.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14370401179699515950/QueryTest.md
16:30:49.873 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully loaded session: QueryTest from /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test14370401179699515950/QueryTest.json
[info] - should round-trip session with initial query
16:30:49.874 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session status-test-0 with title: StatusTest0
16:30:49.874 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test18322364091444193077/StatusTest0.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test18322364091444193077/StatusTest0.md
16:30:49.874 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully loaded session: StatusTest0 from /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test18322364091444193077/StatusTest0.json
16:30:49.874 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session status-test-1 with title: StatusTest1
16:30:49.875 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test18322364091444193077/StatusTest1.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test18322364091444193077/StatusTest1.md
16:30:49.875 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully loaded session: StatusTest1 from /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test18322364091444193077/StatusTest1.json
16:30:49.875 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session status-test-2 with title: StatusTest2
16:30:49.875 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test18322364091444193077/StatusTest2.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test18322364091444193077/StatusTest2.md
16:30:49.875 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully loaded session: StatusTest2 from /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test18322364091444193077/StatusTest2.json
16:30:49.875 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Saving session status-test-3 with title: StatusTest3
16:30:49.875 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully saved session JSON: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test18322364091444193077/StatusTest3.json and markdown: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test18322364091444193077/StatusTest3.md
16:30:49.876 [pool-1-thread-1-ScalaTest-running-SessionManagerSpec] INFO  org.llm4s.assistant.SessionManager -- Successfully loaded session: StatusTest3 from /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/session-manager-test18322364091444193077/StatusTest3.json
[info] - should round-trip session with different statuses
[info] HandoffIntegrationSpec:
[info] Agent with handoffs
[info] - should create handoff tools
16:30:49.878 [pool-1-thread-1-ScalaTest-running-HandoffIntegrationSpec] INFO  org.llm4s.agent.Agent -- Executing tool: handoff_to_agent_3e100573 with arguments: "{\"reason\": \"Requires advanced math\"}"
16:30:49.878 [pool-1-thread-1-ScalaTest-running-HandoffIntegrationSpec] WARN  org.llm4s.agent.Agent -- Tool handoff_to_agent_3e100573 failed in 0ms with error: Tool call 'handoff_to_agent_3e100573' failed with error: cannot access parameter 'reason' because parent 'root' is string, not an object
[info] - should detect handoff from tool call
[info] - should preserve context when preserveContext = true
[info] - should not preserve context when preserveContext = false
[info] Handoff state building
[info] - should transfer system message when configured
[info] IntegrationSpec:
[info] Complete document processing workflow
16:30:49.883 [pool-1-thread-1-ScalaTest-running-IntegrationSpec] INFO  o.l.agent.orchestration.PlanRunner -- Starting plan execution with 4 nodes and 3 edges
16:30:49.886 [scala-execution-context-global-72] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed successfully with 4 results
16:30:49.886 [scala-execution-context-global-72] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed
[info] - should execute successfully
[info] Error recovery in complex workflow
16:30:49.887 [pool-1-thread-1-ScalaTest-running-IntegrationSpec] INFO  o.l.agent.orchestration.PlanRunner -- Starting plan execution with 3 nodes and 1 edges
16:30:49.887 [scala-execution-context-global-72] WARN  o.l.agent.orchestration.Policies$ -- Agent failing-processor failed on attempt 1 of 2, retrying: NodeExecutionError: Node execution failed [failing:failing-processor]: Simulated processing failure[component=node-execution,nodeId=failing,nodeName=failing-processor,recoverable=true]
16:30:49.900 [scala-execution-context-global-233] ERROR o.l.agent.orchestration.Policies$ -- Agent failing-processor exhausted all 2 attempts, final error: NodeExecutionError(Node execution failed [failing:failing-processor]: Simulated processing failure,failing,failing-processor,None,true)
16:30:49.900 [scala-execution-context-global-74] ERROR o.l.agent.orchestration.PlanRunner -- Batch 1 had 1 failures
16:30:49.900 [scala-execution-context-global-75] ERROR o.l.agent.orchestration.PlanRunner -- Plan execution failed: NodeExecutionError(Node execution failed [failing:failing-processor]: Simulated processing failure,failing,failing-processor,None,true)
16:30:49.900 [scala-execution-context-global-75] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed
[info] - should handle partial failures gracefully
[info] Performance test with parallel execution
16:30:49.901 [pool-1-thread-1-ScalaTest-running-IntegrationSpec] INFO  o.l.agent.orchestration.PlanRunner -- Starting plan execution with 4 nodes and 0 edges
16:30:49.953 [scala-execution-context-global-234] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed successfully with 4 results
16:30:49.953 [scala-execution-context-global-234] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed
[info] - should demonstrate concurrency benefits
[info] Complex DAG with multiple merge points
16:30:49.954 [pool-1-thread-1-ScalaTest-running-IntegrationSpec] INFO  o.l.agent.orchestration.PlanRunner -- Starting plan execution with 5 nodes and 4 edges
16:30:49.955 [scala-execution-context-global-236] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed successfully with 5 results
16:30:49.955 [scala-execution-context-global-236] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed
[info] - should execute correctly
[info] Workflow with policies and error handling
16:30:49.955 [pool-1-thread-1-ScalaTest-running-IntegrationSpec] INFO  o.l.agent.orchestration.PlanRunner -- Starting plan execution with 2 nodes and 1 edges
16:30:49.956 [scala-execution-context-global-236] WARN  o.l.agent.orchestration.TypedAgent$ -- Async agent network-call [48471d79-62d1-4f8f-96e7-bed0eb78db00] failed with exception
java.lang.RuntimeException: Network timeout
	at org.llm4s.agent.orchestration.IntegrationSpec.$anonfun$22(IntegrationSpec.scala:222)
	at org.llm4s.agent.orchestration.TypedAgent$$anon$2.execute(TypedAgent.scala:85)
	at org.llm4s.agent.orchestration.Policies$$anon$4.execute(Policies.scala:168)
	at org.llm4s.agent.orchestration.Policies$$anon$2.attempt$1(Policies.scala:88)
	at org.llm4s.agent.orchestration.Policies$$anon$2.execute(Policies.scala:128)
	at org.llm4s.agent.orchestration.Policies$$anon$8.execute(Policies.scala:208)
	at org.llm4s.agent.orchestration.PlanRunner.$anonfun$3(PlanRunner.scala:274)
	at scala.util.Try$.apply(Try.scala:217)
	at org.llm4s.agent.orchestration.PlanRunner.executeNode(PlanRunner.scala:282)
	at org.llm4s.agent.orchestration.PlanRunner.executeLimitedConcurrency$1$$anonfun$1(PlanRunner.scala:150)
	at scala.collection.immutable.List.map(List.scala:247)
	at org.llm4s.agent.orchestration.PlanRunner.executeLimitedConcurrency$1(PlanRunner.scala:149)
	at org.llm4s.agent.orchestration.PlanRunner.executeBatch$1(PlanRunner.scala:179)
	at org.llm4s.agent.orchestration.PlanRunner.executeBatchesSequentially$1(PlanRunner.scala:213)
	at org.llm4s.agent.orchestration.PlanRunner.executeBatches(PlanRunner.scala:219)
	at org.llm4s.agent.orchestration.PlanRunner.executeWithContext(PlanRunner.scala:99)
	at org.llm4s.agent.orchestration.PlanRunner.$anonfun$1(PlanRunner.scala:64)
	at org.llm4s.agent.orchestration.MDCContext$.withValues(MDCContext.scala:57)
	at org.llm4s.agent.orchestration.PlanRunner.execute(PlanRunner.scala:65)
	at org.llm4s.agent.orchestration.IntegrationSpec.testFun$proxy5$1(IntegrationSpec.scala:253)
	at org.llm4s.agent.orchestration.IntegrationSpec.$init$$$anonfun$5(IntegrationSpec.scala:216)
	at org.scalatest.Transformer.apply$$anonfun$1(Transformer.scala:22)
	at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:31)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:21)
	at org.scalatest.flatspec.AnyFlatSpecLike$$anon$5.apply(AnyFlatSpecLike.scala:1717)
	at org.scalatest.TestSuite.withFixture(TestSuite.scala:196)
	at org.scalatest.TestSuite.withFixture$(TestSuite.scala:138)
	at org.scalatest.flatspec.AnyFlatSpec.withFixture(AnyFlatSpec.scala:1685)
	at org.scalatest.flatspec.AnyFlatSpecLike.invokeWithFixture$1(AnyFlatSpecLike.scala:1723)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTest$$anonfun$1(AnyFlatSpecLike.scala:1727)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTest(AnyFlatSpecLike.scala:1727)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTest$(AnyFlatSpecLike.scala:51)
	at org.scalatest.flatspec.AnyFlatSpec.runTest(AnyFlatSpec.scala:1685)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTests$$anonfun$1(AnyFlatSpecLike.scala:1785)
	at org.scalatest.SuperEngine.traverseSubNodes$1$$anonfun$1(Engine.scala:413)
	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)
	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)
	at scala.collection.immutable.List.foreach(List.scala:334)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:429)
	at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390)
	at org.scalatest.SuperEngine.traverseSubNodes$1$$anonfun$1(Engine.scala:427)
	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)
	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)
	at scala.collection.immutable.List.foreach(List.scala:334)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:429)
	at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTests(AnyFlatSpecLike.scala:1785)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTests$(AnyFlatSpecLike.scala:51)
	at org.scalatest.flatspec.AnyFlatSpec.runTests(AnyFlatSpec.scala:1685)
	at org.scalatest.Suite.run(Suite.scala:1114)
	at org.scalatest.Suite.run$(Suite.scala:564)
	at org.scalatest.flatspec.AnyFlatSpec.org$scalatest$flatspec$AnyFlatSpecLike$$super$run(AnyFlatSpec.scala:1685)
	at org.scalatest.flatspec.AnyFlatSpecLike.run$$anonfun$1(AnyFlatSpecLike.scala:1830)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:535)
	at org.scalatest.flatspec.AnyFlatSpecLike.run(AnyFlatSpecLike.scala:1830)
	at org.scalatest.flatspec.AnyFlatSpecLike.run$(AnyFlatSpecLike.scala:51)
	at org.scalatest.flatspec.AnyFlatSpec.run(AnyFlatSpec.scala:1685)
	at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)
	at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:414)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1623)
16:30:49.956 [scala-execution-context-global-236] WARN  o.l.agent.orchestration.Policies$ -- Agent network-call-timeout failed on attempt 1 of 3, retrying: NodeExecutionError: Node execution failed [48471d79-62d1-4f8f-96e7-bed0eb78db00:network-call]: Async operation failed: Network timeout[nodeName=network-call,cause=RuntimeException,component=node-execution,nodeId=48471d79-62d1-4f8f-96e7-bed0eb78db00,recoverable=true]
16:30:50.058 [scala-execution-context-global-235] WARN  o.l.agent.orchestration.TypedAgent$ -- Async agent network-call [48471d79-62d1-4f8f-96e7-bed0eb78db00] failed with exception
java.lang.RuntimeException: Network timeout
	at org.llm4s.agent.orchestration.IntegrationSpec.$anonfun$22(IntegrationSpec.scala:222)
	at org.llm4s.agent.orchestration.TypedAgent$$anon$2.execute(TypedAgent.scala:85)
	at org.llm4s.agent.orchestration.Policies$$anon$4.execute(Policies.scala:168)
	at org.llm4s.agent.orchestration.Policies$$anon$2.attempt$1(Policies.scala:88)
	at org.llm4s.agent.orchestration.Policies$$anon$2.attempt$1$$anonfun$1$$anonfun$2(Policies.scala:109)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at org.llm4s.agent.orchestration.MDCContext$$anon$2.run$$anonfun$1(MDCContext.scala:68)
	at org.llm4s.agent.orchestration.MDCContext$$anon$2.run$$anonfun$adapted$1(MDCContext.scala:68)
	at org.llm4s.agent.orchestration.MDCContext$.withContext(MDCContext.scala:44)
	at org.llm4s.agent.orchestration.MDCContext$$anon$2.run(MDCContext.scala:68)
	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1423)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1312)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1843)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1808)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)
16:30:50.058 [scala-execution-context-global-235] WARN  o.l.agent.orchestration.Policies$ -- Agent network-call-timeout failed on attempt 2 of 3, retrying: NodeExecutionError: Node execution failed [48471d79-62d1-4f8f-96e7-bed0eb78db00:network-call]: Async operation failed: Network timeout[nodeName=network-call,cause=RuntimeException,component=node-execution,nodeId=48471d79-62d1-4f8f-96e7-bed0eb78db00,recoverable=true]
16:30:50.263 [scala-execution-context-global-228] INFO  o.l.agent.orchestration.Policies$ -- Agent network-call-timeout succeeded on attempt 3 of 3
16:30:50.264 [scala-execution-context-global-235] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed successfully with 2 results
16:30:50.264 [scala-execution-context-global-235] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed
[info] - should demonstrate production-ready resilience
[info] SessionStateSpec:
[info] SessionState
[info] - should create with no agent state
[info] - should have a default created timestamp
[info] - should create new session with withNewSession
[info] SessionInfo
[info] - should store all fields correctly
[info] - should serialize to JSON
[info] SessionSummary
[info] - should store all fields correctly
[info] - should serialize to JSON
[info] SessionState.localDateTimeRW
[info] - should serialize LocalDateTime to string
[info] - should handle various datetime formats
[info] LLMRerankerSpec:
[info] LLMReranker
[info] - should have correct default values
[info] - should create reranker with default parameters
[info] - should create reranker with custom batch size
[info] - should create reranker with custom system prompt
[info] - should reject invalid batch size
[info] - should return empty results for empty documents
[info] - should parse JSON array of scores
[info] - should handle markdown code block wrapping
[info] - should handle scores as strings
[info] - should clamp scores to valid range
[info] - should respect topK parameter
[info] - should return documents when returnDocuments is true
[info] - should not return documents when returnDocuments is false
[info] - should include provider metadata
[info] - should pad with neutral scores when LLM returns fewer scores
[info] - should handle LLM errors gracefully
[info] - should send correct messages to LLM
[info] RerankerFactory
[info] - should create LLM reranker
[info] - should create LLM reranker with custom parameters
[info] ThrowableOpsSpec:
[info] ThrowableOps.toLLMError
[info] - should convert SocketTimeoutException to NetworkError
[info] - should convert ConnectException to NetworkError
[info] - should convert exception with 401 in message to AuthenticationError
[info] - should convert exception with 429 in message to RateLimitError
[info] - should prioritize authentication error when both 401 and 429 are present in message
[info] - should convert unknown exception to UnknownError
[info] - should handle exception with null message
[info] - should use custom ErrorMapper when provided
[info] - should use explicit mapper over implicit
[info] DefaultErrorMapper
[info] - should handle all network-related exceptions
[info] - should detect HTTP status codes in exception messages
[info] - should preserve exception type in UnknownError context
[info] ThrowableOps
[info] - should work with nested exceptions
[info] - should handle Error subclasses
[info] - should handle exceptions with empty message
[info] LLMError from Throwable
[info] - should be usable in error handling patterns
[info] - should preserve recoverability based on error type
[info] AudioValidationsSpec:
[info] validateInputNotEmpty
[info] - should accept non-empty audio payloads
[info] - should reject empty audio payloads
[info] validateFrameSize
[info] - should accept audio payloads aligned to frame size
[info] - should reject payloads with partial frames
[info] validateSampleRate
[info] - should accept positive sample rates
[info] - should reject non-positive sample rates
[info] validateNumChannels
[info] - should accept positive channel counts
[info] - should reject non-positive channel counts
[info] validateBitDepth
[info] - should accept 16-bit audio
[info] - should reject unsupported bit depths
[info] validateSampleRateIsNotTooHigh
[info] - should accept sample rates at or below 48kHz
[info] - should reject overly high sample rates
[info] DeterministicCompressorSpec:
[info] DeterministicCompressor.compressToCap
16:30:50.312 [pool-1-thread-1-ScalaTest-running-DeterministicCompressorSpec] INFO  o.l.context.DeterministicCompressor$ -- Compression complete: 13  13 tokens
[info] - should return messages unchanged when under cap
16:30:50.315 [pool-1-thread-1-ScalaTest-running-DeterministicCompressorSpec] INFO  o.l.context.DeterministicCompressor$ -- Compression complete: 2533  64 tokens
[info] - should apply tool compaction by default
16:30:50.315 [pool-1-thread-1-ScalaTest-running-DeterministicCompressorSpec] INFO  o.l.context.DeterministicCompressor$ -- Compression complete: 22  22 tokens
[info] - should skip subjective edits when disabled (default)
16:30:50.315 [pool-1-thread-1-ScalaTest-running-DeterministicCompressorSpec] INFO  o.l.context.DeterministicCompressor$ -- Compression complete: 31  31 tokens
[info] - should apply subjective rules when enabled and over cap
[info] CompressionRule.removeFillerWords
[info] - should clean transcript-like content
[info] - should preserve code blocks unchanged
[info] - should preserve JSON content unchanged
[info] - should never modify user messages
[info] CompressionRule.compressRepetitiveContent
[info] - should deduplicate repeated sentences
[info] - should handle single sentence content
[info] CompressionRule.truncateVerboseResponses
[info] - should truncate very long assistant responses
[info] - should not truncate short responses
[info] - should never truncate user messages
[info] - should never truncate tool messages
[info] CompressionRule.consolidateExamples
[info] - should consolidate multiple example messages
[info] - should not consolidate non-example messages
[info] CompressionRule.removeRedundantPhrases
[info] - should remove 'as I mentioned before'
[info] - should remove 'like I said'
[info] DeterministicCompressor
16:30:50.319 [pool-1-thread-1-ScalaTest-running-DeterministicCompressorSpec] INFO  o.l.context.DeterministicCompressor$ -- Compression complete: 0  0 tokens
[info] - should handle empty message list
16:30:50.319 [pool-1-thread-1-ScalaTest-running-DeterministicCompressorSpec] INFO  o.l.context.DeterministicCompressor$ -- Compression complete: 35  35 tokens
[info] - should handle mixed message types
16:30:50.320 [pool-1-thread-1-ScalaTest-running-DeterministicCompressorSpec] INFO  o.l.context.DeterministicCompressor$ -- Compression complete: 50  50 tokens
[info] - should preserve message order
[info] AsyncToolExecutionSpec:
[info] ToolExecutionStrategy.Sequential
[info] - should be the default
[info] ToolExecutionStrategy.ParallelWithLimit
[info] - should require positive concurrency
[info] ToolRegistry.executeAsync
[info] - should execute a tool asynchronously
[info] - should return error for unknown function
[info] ToolRegistry.executeAll
[info] - should execute requests sequentially with Sequential strategy
[info] - should execute requests in parallel with Parallel strategy
[info] - should respect concurrency limit with ParallelWithLimit strategy
[info] - should handle mixed success and failure results
[info] - should handle empty request list
[info] - should handle single request
[info] - should use Sequential by default
[info] Llm4sConfigTextModelSpec:
[info] Llm4sConfig.textEmbeddingModel
[info] - should return OpenAI text model settings with dimensions from the registry
[info] EmbedxV2Spec:
[info] - Non-text: image/audio/video  501 by default (stubs disabled)
[info] - Experimental stubs: image/audio/video produce vectors and experimental=true !!! CANCELED !!!
[info]   ENABLE_EXPERIMENTAL_STUBS!=true; set it to run this test. (EmbedxV2Spec.scala:156)
16:30:50.933 [pool-1-thread-1-ScalaTest-running-EmbedxV2Spec] INFO  o.l.llmconnect.utils.ModelSelector$ -- [ModelSelector] Image model: openclip-vit-b32 (512 dims)
16:30:50.933 [pool-1-thread-1-ScalaTest-running-EmbedxV2Spec] INFO  o.l.llmconnect.utils.ModelSelector$ -- [ModelSelector] Audio model: wav2vec2-base (768 dims)
16:30:50.933 [pool-1-thread-1-ScalaTest-running-EmbedxV2Spec] INFO  o.l.llmconnect.utils.ModelSelector$ -- [ModelSelector] Video model: timesformer-base (768 dims)
[info] - Local model dimensions (Image/Audio/Video) match registry
[info] SQLiteMemoryStoreSpec:
[info] SQLiteMemoryStore
[info] - should store and retrieve a memory
[info] - should return None for non-existent memory
[info] - should update existing memory on store with same ID
[info] - should store and retrieve memory with all fields
[info] - should recall memories by type
[info] - should recall memories by conversation ID
[info] - should recall memories by entity ID
[info] - should recall memories by time range
[info] - should recall memories by minimum importance
[info] - should recall memories with metadata filter
[info] - should support combined filters with And
[info] - should support combined filters with Or
[info] - should support Not filter
[info] - should search memories using full-text search
[info] - should delete a memory
[info] - should delete matching memories
[info] - should update a memory
[info] - should return error when updating non-existent memory
[info] - should count all memories
[info] - should count memories with filter
[info] - should clear all memories
[info] - should get recent memories in order
[info] - should respect limit in recall
[info] - should handle custom memory types
[info] - should handle special characters in content
[info] - should handle special characters in metadata
[info] SQLiteMemoryStore.apply
[info] - should create store with file path
[info] TracingSettingsSpec:
[info] Llm4sConfig.tracing + Tracing.create
[info] - should return Console tracing by default
[info] RobotsTxtParserSpec:
[info] RobotsTxtParser.parse
[info] - should parse simple disallow rules
[info] - should parse allow rules
[info] - should prefer longer matching rules
[info] - should parse crawl-delay
[info] - should use specific user-agent rules over wildcard
[info] - should support multiple user-agent lines in a group
[info] - should not fall back to wildcard when specific group has no rules
[info] - should fall back to wildcard when no specific match
[info] - should treat regex metacharacters as literals
[info] - should ignore comments
[info] - should handle empty content
[info] RobotsTxt.isAllowed
[info] - should allow all paths by default
[info] - should handle root disallow
[info] - should allow ties go to allow rules
[info] - should handle empty disallow rule
[info] RobotsTxtParser wildcard patterns
[info] - should support * wildcard
[info] - should support $ anchor for exact end matching
[info] - should support * and $ together
[info] RobotsTxt.empty
[info] - should have no rules
[info] RobotsTxtParser.parse edge cases
[info] - should handle crawl-delay with decimal value
[info] - should handle invalid crawl-delay gracefully
[info] - should handle multiple groups separated by blank lines
[info] - should handle empty value for user-agent
[info] - should handle empty value for allow/disallow
[info] - should handle unknown directives gracefully
[info] - should handle malformed lines
[info] - should handle user-agent followed by directive then more user-agents
[info] RobotsTxtParser.clearCache
[info] - should clear the cache
[info] RobotsTxtParser.getRules
[info] - should return empty rules for invalid URL
[info] - should return empty rules for URL with no host
[info] RobotsTxtParser.isAllowed
[info] - should return true for invalid URL
[info] - should return true for URL with no host
[info] RobotsTxtParser rule selection
[info] - should prefer exact user-agent match over prefix
[info] - should select wildcard when no other match
[info] - should return empty when no matching groups
[info] MCPServerConfigSpec:
[info] MCPServerConfig
[info] - should have default timeout of 30 seconds
[info] - should allow custom timeout
[info] MCPServerConfig.stdio
[info] - should create stdio transport config
[info] - should accept custom timeout
[info] - should pass name to transport
[info] MCPServerConfig.streamableHTTP
[info] - should create streamable HTTP transport config
[info] - should accept custom timeout
[info] - should pass name to transport
[info] MCPServerConfig.sse
[info] - should create SSE transport config
[info] - should accept custom timeout
[info] - should pass name to transport
[info] StdioTransport
[info] - should store command and name
[info] - should be sealed under MCPTransport
[info] SSETransport
[info] - should store url and name
[info] - should be sealed under MCPTransport
[info] StreamableHTTPTransport
[info] - should store url and name
[info] - should be sealed under MCPTransport
[info] MCPTransport
[info] - should support exhaustive pattern matching
[info] ConsoleTracingSpec:
[info] ConsoleTracing

[33m[1m--- CUSTOM EVENT ---[0m
[90mTimestamp: 2026-01-27T11:00:50.981299Z[0m
[33mName: Test event occurred[0m
[33mData: {}[0m

[info] - should trace events without throwing

[36m[1m--- TOOL EXECUTED ---[0m
[90mTimestamp: 2026-01-27T11:00:50.982424Z[0m
[36mTool: calculator[0m
[36mSuccess: true[0m
[36mDuration: 0ms[0m
[33mInput: {"operation": "add", "a": 1, "b": 2}[0m
[32mOutput: 3[0m

[info] - should trace tool calls without throwing

[36m[1m============================================================[0m
[36m[1mERROR OCCURRED[0m
[36m[1m============================================================[0m
[90mTimestamp: 2026-01-27T11:00:50.982669Z[0m
[31mType: RuntimeException[0m
[31mMessage: Something went wrong[0m
[31mContext: [0m

[info] - should trace errors without throwing

[36m[1m============================================================[0m
[36m[1mERROR OCCURRED[0m
[36m[1m============================================================[0m
[90mTimestamp: 2026-01-27T11:00:50.982829Z[0m
[31mType: RuntimeException[0m
[31mMessage: Outer error[0m
[31mContext: [0m

[info] - should trace errors with nested cause

[34m[1m--- AGENT STATE UPDATED ---[0m
[90mTimestamp: 2026-01-27T11:00:50.983021Z[0m
[34mStatus: InProgress[0m
[34mMessages: 0[0m
[34mLogs: 0[0m

[info] - should trace agent state with minimal configuration

[34m[1m--- AGENT STATE UPDATED ---[0m
[90mTimestamp: 2026-01-27T11:00:50.983166Z[0m
[34mStatus: Complete[0m
[34mMessages: 3[0m
[34mLogs: 2[0m

[info] - should trace agent state with full configuration

[34m[1m--- AGENT STATE UPDATED ---[0m
[90mTimestamp: 2026-01-27T11:00:50.983260Z[0m
[34mStatus: InProgress[0m
[34mMessages: 2[0m
[34mLogs: 0[0m

[info] - should trace agent state with system message

[34m[1m--- AGENT STATE UPDATED ---[0m
[90mTimestamp: 2026-01-27T11:00:50.983414Z[0m
[34mStatus: Complete[0m
[34mMessages: 3[0m
[34mLogs: 0[0m

[info] - should trace agent state with assistant tool calls

[34m[1m--- AGENT STATE UPDATED ---[0m
[90mTimestamp: 2026-01-27T11:00:50.983511Z[0m
[34mStatus: InProgress[0m
[34mMessages: 0[0m
[34mLogs: 5[0m

[info] - should trace agent state with various log types

[36m[1m============================================================[0m
[36m[1mCOMPLETION RECEIVED[0m
[36m[1m============================================================[0m
[90mTimestamp: 2026-01-27T11:00:50.983701Z[0m
[32mModel: gpt-4[0m
[32mID: cmpl-123456[0m
[32mTool Calls: 0[0m
[32mContent: Hello, I'm an AI assistant.[0m

[info] - should trace completion with token usage

[36m[1m============================================================[0m
[36m[1mCOMPLETION RECEIVED[0m
[36m[1m============================================================[0m
[90mTimestamp: 2026-01-27T11:00:50.983886Z[0m
[32mModel: gpt-4[0m
[32mID: cmpl-789[0m
[32mTool Calls: 0[0m
[32mContent: Response without usage[0m

[info] - should trace completion without token usage

[36m[1m============================================================[0m
[36m[1mCOMPLETION RECEIVED[0m
[36m[1m============================================================[0m
[90mTimestamp: 2026-01-27T11:00:50.984035Z[0m
[32mModel: gpt-4[0m
[32mID: cmpl-tools[0m
[32mTool Calls: 1[0m
[32mContent: I'll search for that.[0m

[info] - should trace completion with tool calls

[35m[1m--- TOKEN USAGE ---[0m
[90mTimestamp: 2026-01-27T11:00:50.984215Z[0m
[35mModel: gpt-4[0m
[35mOperation: completion[0m
[35mPrompt Tokens: 1000[0m
[35mCompletion Tokens: 500[0m
[35mTotal Tokens: 1500[0m

[info] - should trace token usage with non-zero values

[35m[1m--- TOKEN USAGE ---[0m
[90mTimestamp: 2026-01-27T11:00:50.984370Z[0m
[35mModel: gpt-4[0m
[35mOperation: empty_request[0m
[35mPrompt Tokens: 0[0m
[35mCompletion Tokens: 0[0m
[35mTotal Tokens: 0[0m

[info] - should trace token usage with zero values

[35m[1m--- TOKEN USAGE ---[0m
[90mTimestamp: 2026-01-27T11:00:50.984471Z[0m
[35mModel: gpt-4-32k[0m
[35mOperation: large_context[0m
[35mPrompt Tokens: 100000[0m
[35mCompletion Tokens: 50000[0m
[35mTotal Tokens: 150000[0m

[info] - should trace token usage with large values

[36m[1m--- TOOL EXECUTED ---[0m
[90mTimestamp: 2026-01-27T11:00:50.984572Z[0m
[36mTool: tool[0m
[36mSuccess: true[0m
[36mDuration: 0ms[0m
[33mInput: {"key":"value","key":"value","key":"value","key":"value","key":"value","key":"value","key":"value","...[0m
[32mOutput: result[0m

[info] - should handle truncation of long JSON in tool calls

[36m[1m============================================================[0m
[36m[1mCOMPLETION RECEIVED[0m
[36m[1m============================================================[0m
[90mTimestamp: 2026-01-27T11:00:50.984684Z[0m
[32mModel: gpt-4[0m
[32mID: cmpl-long[0m
[32mTool Calls: 0[0m
[32mContent: AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA...[0m

[info] - should handle truncation of long content in completions

[36m[1m--- TOOL EXECUTED ---[0m
[90mTimestamp: 2026-01-27T11:00:50.984782Z[0m
[36mTool: tool[0m
[36mSuccess: true[0m
[36mDuration: 0ms[0m
[33mInput: {}[0m
[32mOutput: Result: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx...[0m

[info] - should handle very long tool output
[info] - should use AnsiColors constants for formatting
[info] ContextManagerSpec:
[info] ContextManager.create
[info] - should create manager with valid config
[info] - should reject invalid headroom percentage
[info] ContextManager.withDefaults
[info] - should create manager with default configuration
[info] ContextManager.manageContext
16:30:50.987 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Starting new context management pipeline for 2 messages, budget: 1000 tokens
16:30:50.987 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Applying tool deterministic compaction
16:30:50.987 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  o.l.context.DeterministicCompressor$ -- Compression complete: 23  23 tokens
[info] - should skip all steps when conversation fits budget
16:30:50.990 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Starting new context management pipeline for 40 messages, budget: 100 tokens
16:30:50.990 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Applying tool deterministic compaction
16:30:50.990 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  o.l.context.DeterministicCompressor$ -- Compression complete: 711  711 tokens
16:30:50.990 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Applying history compression with deterministic digest
16:30:50.992 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.TokenWindow$ -- Trimming conversation: 475 > 92 tokens (effective budget)
16:30:50.992 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.TokenWindow$ -- Trimmed to 5 messages (removed 20 messages), digest pinned
16:30:50.992 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Starting new context management pipeline for 40 messages, budget: 200 tokens
[info] - should apply steps in correct order
16:30:50.992 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Applying tool deterministic compaction
16:30:50.992 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  o.l.context.DeterministicCompressor$ -- Compression complete: 711  711 tokens
16:30:50.992 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Applying history compression with deterministic digest
16:30:50.993 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.TokenWindow$ -- Trimming conversation: 475 > 184 tokens (effective budget)
16:30:50.993 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.TokenWindow$ -- Trimmed to 10 messages (removed 15 messages), digest pinned
[info] - should achieve budget target in multi-step scenario
16:30:50.993 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Starting new context management pipeline for 4 messages, budget: 100 tokens
[info] - should skip deterministic compression when disabled
16:30:50.993 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Starting new context management pipeline for 40 messages, budget: 100 tokens
16:30:50.993 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Applying tool deterministic compaction
16:30:50.993 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  o.l.context.DeterministicCompressor$ -- Compression complete: 711  711 tokens
16:30:50.993 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Applying history compression with deterministic digest
16:30:50.994 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.TokenWindow$ -- Trimming conversation: 475 > 92 tokens (effective budget)
16:30:50.994 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.TokenWindow$ -- Trimmed to 5 messages (removed 20 messages), digest pinned
[info] - should skip LLM compression when disabled
16:30:50.994 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Starting new context management pipeline for 40 messages, budget: 100 tokens
16:30:50.994 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Applying tool deterministic compaction
16:30:50.994 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  o.l.context.DeterministicCompressor$ -- Compression complete: 711  711 tokens
16:30:50.994 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Applying history compression with deterministic digest
16:30:50.994 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.TokenWindow$ -- Trimming conversation: 475 > 92 tokens (effective budget)
16:30:50.994 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.TokenWindow$ -- Trimmed to 5 messages (removed 20 messages), digest pinned
[info] - should skip LLM compression when no client provided
[info] ManagedConversation
16:30:50.995 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Starting new context management pipeline for 6 messages, budget: 50 tokens
16:30:50.995 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Applying tool deterministic compaction
16:30:50.995 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  o.l.context.DeterministicCompressor$ -- Compression complete: 81  81 tokens
16:30:50.995 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Applying history compression with deterministic digest
16:30:50.995 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.TokenWindow$ -- Trimming conversation: 91 > 46 tokens (effective budget)
16:30:50.995 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.TokenWindow$ -- Trimmed to 3 messages (removed 3 messages)
16:30:50.995 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Starting new context management pipeline for 2 messages, budget: 1000 tokens
16:30:50.995 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Applying tool deterministic compaction
[info] - should calculate correct summary statistics
16:30:50.995 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  o.l.context.DeterministicCompressor$ -- Compression complete: 23  23 tokens
[info] - should provide readable summary
[info] ContextStep
[info] - should provide correct summary for applied step
[info] - should provide correct summary for skipped step
[info] ContextConfig.default
[info] - should have reasonable default values
16:30:50.995 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Starting new context management pipeline for 0 messages, budget: 100 tokens
[info] ContextConfig.legacy
16:30:50.995 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Applying tool deterministic compaction
16:30:50.995 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  o.l.context.DeterministicCompressor$ -- Compression complete: 0  0 tokens
[info] - should support backward compatible configuration
16:30:50.995 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Starting new context management pipeline for 1 messages, budget: 100 tokens
16:30:50.995 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Applying tool deterministic compaction
[info] ContextManager
16:30:50.995 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  o.l.context.DeterministicCompressor$ -- Compression complete: 6  6 tokens
[info] - should handle empty conversation
16:30:50.995 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Starting new context management pipeline for 5 messages, budget: 100 tokens
16:30:50.995 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  org.llm4s.context.ContextManager -- Applying tool deterministic compaction
[info] - should handle single message conversation
16:30:50.995 [pool-1-thread-1-ScalaTest-running-ContextManagerSpec] INFO  o.l.context.DeterministicCompressor$ -- Compression complete: 71  71 tokens
[info] - should handle conversation with existing HISTORY_SUMMARY
16:30:50.997 [pool-1-thread-1-ScalaTest-running-TokenWindowSpec] INFO  org.llm4s.context.TokenWindow$ -- Trimming conversation: 721 > 92 tokens (effective budget)
[info] TokenWindowSpec:
[info] TokenWindow.trimToBudget
[info] - should return original conversation when within budget
16:30:50.997 [pool-1-thread-1-ScalaTest-running-TokenWindowSpec] INFO  org.llm4s.context.TokenWindow$ -- Trimmed to 4 messages (removed 36 messages)
16:30:50.997 [pool-1-thread-1-ScalaTest-running-TokenWindowSpec] INFO  org.llm4s.context.TokenWindow$ -- Trimming conversation: 81 > 46 tokens (effective budget)
16:30:50.997 [pool-1-thread-1-ScalaTest-running-TokenWindowSpec] INFO  org.llm4s.context.TokenWindow$ -- Trimmed to 2 messages (removed 3 messages), digest pinned
[info] - should trim oldest messages when over budget
[info] - should preserve pinned HISTORY_SUMMARY messages
16:30:50.997 [pool-1-thread-1-ScalaTest-running-TokenWindowSpec] INFO  org.llm4s.context.TokenWindow$ -- Trimming conversation: 91 > 80 tokens (effective budget)
16:30:50.997 [pool-1-thread-1-ScalaTest-running-TokenWindowSpec] INFO  org.llm4s.context.TokenWindow$ -- Trimmed to 5 messages (removed 1 messages)
[info] - should apply headroom percentage correctly
[info] - should reject negative budget
[info] - should reject zero budget
[info] - should reject invalid headroom percentage (negative)
[info] - should reject invalid headroom percentage (>=1.0)
[info] - should reject empty conversation
[info] TokenWindow.fitsInBudget
[info] - should return true when conversation fits
[info] - should return false when conversation exceeds budget
[info] - should account for headroom in budget check
16:30:50.997 [pool-1-thread-1-ScalaTest-running-TokenWindowSpec] INFO  org.llm4s.context.TokenWindow$ -- Trimming conversation: 91 > 27 tokens (effective budget)
16:30:50.997 [pool-1-thread-1-ScalaTest-running-TokenWindowSpec] INFO  org.llm4s.context.TokenWindow$ -- Trimmed to 1 messages (removed 5 messages)
[info] TokenWindow.getUsageInfo
[info] - should calculate correct utilization percentage
[info] - should report correct withinBudget status
[info] TokenWindow
[info] - should handle single message conversation
[info] - should trim to single message if budget is very tight
[info] AudioPreprocessingTest:
[info] - toMono keeps mono identical
[info] AgentGuardrailsIntegrationSpec:
[info] Agent.run with input guardrails
[info] - should validate input before processing
[info] - should pass when input validation succeeds
[info] - should apply multiple input guardrails
[info] Agent.run with output guardrails
[info] - should validate output before returning
[info] - should pass when output validation succeeds
[info] - should apply multiple output guardrails
[info] Agent.run with both input and output guardrails
[info] - should validate both
[info] - should fail on input validation first
[info] Agent.continueConversation with guardrails
[info] - should validate new message
[info] - should validate output on continuation
[info] - should work in multi-turn conversations
[info] Guardrails
[info] - should not interfere with normal operation when empty
[info] BenchmarkResultSpec:
[info] TimingInfo
[info] - should format milliseconds correctly
[info] - should format seconds correctly
[info] - should calculate average per item
[info] - should return None for avgPerItem when itemCount is 0
[info] - should measure execution time
[info] ExperimentResult
[info] - should create failed result
[info] - should create successful result
[info] - should calculate total time from timings
[info] BenchmarkResults
[info] - should calculate rankings
[info] - should track success and failure counts
[info] - should compare two experiments
[info] - should return None for comparison with missing experiment
[info] - should calculate average scores
[info] ExperimentComparison
[info] - should calculate improvement metrics
[info] - should detect regression
[info] RAGConfigSpec:
[info] RAGConfig
[info] - should have sensible defaults
[info] RAGConfig.default
[info] - should return default configuration
[info] RAGConfig.development
[info] - should have in-memory storage and smaller topK
[info] RAGConfig.production
[info] - should use SQLite storage
[info] RAGConfig.withEmbeddings
[info] - should set provider
[info] - should set provider and model
[info] - should set provider, model, and dimensions
[info] RAGConfig.withEmbeddingDimensions
[info] - should override dimensions
[info] RAGConfig.withChunking
[info] - should set chunking strategy
[info] - should set strategy with custom config
[info] - should set strategy with size and overlap
[info] RAGConfig.withFusion
[info] - should set fusion strategy
[info] RAGConfig.withRRF
[info] - should set RRF fusion with default k
[info] - should set RRF fusion with custom k
[info] RAGConfig.withWeightedScore
[info] - should set weighted score fusion
[info] RAGConfig.vectorOnly
[info] - should set vector-only fusion
[info] RAGConfig.keywordOnly
[info] - should set keyword-only fusion
[info] RAGConfig.withTopK
[info] - should set number of results
[info] RAGConfig.withReranking
[info] - should set reranking strategy
[info] RAGConfig.withCohereReranking
[info] - should set Cohere reranking with default model
[info] - should set Cohere reranking with custom model
[info] RAGConfig.withLLMReranking
[info] - should set LLM reranking
[info] RAGConfig.withRerankTopK
[info] - should set rerank candidates count
[info] RAGConfig.withSQLite
[info] - should set both paths
[info] RAGConfig.inMemory
[info] - should clear storage paths
[info] RAGConfig.withPgVector()
[info] - should set default pgvector configuration
[info] RAGConfig.withPgVector(tableName)
[info] - should set pgvector with custom table
[info] RAGConfig.withPgVector(full)
[info] - should set all pgvector parameters
[info] RAGConfig.withSQLite
[info] - should clear pgvector settings
[info] RAGConfig.withSystemPrompt
[info] - should set system prompt
[info] RAGConfig.withDocuments(path)
[info] - should add directory loader
[info] RAGConfig.withDocuments(loader)
[info] - should add custom loader
[info] RAGConfig.withDocuments(loaders)
[info] - should add multiple loaders
[info] RAGConfig.withLoadingConfig
[info] - should set loading config
[info] RAGConfig.failOnLoadError
[info] - should set fail fast
[info] RAGConfig.withParallelism
[info] - should set parallelism
[info] RAGConfig.withBatchSize
[info] - should set batch size
[info] RAGConfig
[info] - should support fluent chaining
[info] RAGConfig
[info] - should be immutable
[info] TracingSpec:
[info] TracingMode.fromString
[info] - should parse langfuse mode
[info] - should parse console mode
[info] - should parse noop mode
16:30:51.066 [pool-1-thread-1-ScalaTest-running-TracingSpec] WARN  org.llm4s.trace.TracingMode$ -- Unknown tracing mode 'unknown', falling back to NoOp
16:30:51.066 [pool-1-thread-1-ScalaTest-running-TracingSpec] WARN  org.llm4s.trace.TracingMode$ -- Unknown tracing mode '', falling back to NoOp
16:30:51.066 [pool-1-thread-1-ScalaTest-running-TracingSpec] WARN  org.llm4s.trace.TracingMode$ -- Unknown tracing mode 'invalid', falling back to NoOp
[info] - should default to NoOp for unknown modes
[info] NoOpTracing
[info] - should return success for all operations
[info] - should support convenience methods
[info] ConsoleTracing

[33m[1m--- CUSTOM EVENT ---[0m
[90mTimestamp: 2026-01-27T11:00:51.067844Z[0m
[33mName: test[0m
[33mData: {}[0m


[36m[1m--- TOOL EXECUTED ---[0m
[90mTimestamp: 2026-01-27T11:00:51.067961Z[0m
[36mTool: tool[0m
[36mSuccess: true[0m
[36mDuration: 0ms[0m
[33mInput: input[0m
[32mOutput: output[0m


[36m[1m============================================================[0m
[36m[1mERROR OCCURRED[0m
[36m[1m============================================================[0m
[90mTimestamp: 2026-01-27T11:00:51.068011Z[0m
[31mType: RuntimeException[0m
[31mMessage: test[0m
[31mContext: context[0m


[34m[1m--- AGENT STATE UPDATED ---[0m
[info] - should return success for all operations
[90mTimestamp: 2026-01-27T11:00:51.068089Z[0m
[34mStatus: InProgress[0m
[34mMessages: 1[0m
[34mLogs: 1[0m


[36m[1m============================================================[0m
[36m[1mCOMPLETION RECEIVED[0m
[36m[1m============================================================[0m
[90mTimestamp: 2026-01-27T11:00:51.068157Z[0m
[32mModel: gpt-4[0m
[32mID: comp-123[0m
[32mTool Calls: 0[0m
[32mContent: Hello[0m

[info] - should handle agent state tracing

[35m[1m--- TOKEN USAGE ---[0m
[90mTimestamp: 2026-01-27T11:00:51.068222Z[0m
[35mModel: gpt-4[0m
[35mOperation: completion[0m
[35mPrompt Tokens: 100[0m
[35mCompletion Tokens: 50[0m
[35mTotal Tokens: 150[0m

[info] - should handle completion tracing
[info] - should handle token usage tracing

[32m[1m--- AGENT INITIALIZED ---[0m
[90mTimestamp: 2026-01-27T11:00:51.068361Z[0m
[32mQuery: query[0m
[32mTools: tool1[0m


[36m[1m============================================================[0m
[36m[1mCOMPLETION RECEIVED[0m
[36m[1m============================================================[0m
[90mTimestamp: 2026-01-27T11:00:51.068434Z[0m
[32mModel: model[0m
[32mID: id[0m
[32mTool Calls: 0[0m
[32mContent: content[0m


[36m[1m--- TOOL EXECUTED ---[0m
[90mTimestamp: 2026-01-27T11:00:51.068471Z[0m
[36mTool: tool[0m
[36mSuccess: true[0m
[36mDuration: 100ms[0m
[33mInput: in[0m
[32mOutput: out[0m


[36m[1m============================================================[0m
[36m[1mERROR OCCURRED[0m
[36m[1m============================================================[0m
[90mTimestamp: 2026-01-27T11:00:51.068509Z[0m
[31mType: Exception[0m
[31mMessage: e[0m
[31mContext: ctx[0m


[35m[1m--- TOKEN USAGE ---[0m
[90mTimestamp: 2026-01-27T11:00:51.068547Z[0m
[35mModel: m[0m
[35mOperation: o[0m
[35mPrompt Tokens: 1[0m
[35mCompletion Tokens: 1[0m
[35mTotal Tokens: 2[0m


[34m[1m--- AGENT STATE UPDATED ---[0m
[90mTimestamp: 2026-01-27T11:00:51.068577Z[0m
[34mStatus: running[0m
[34mMessages: 5[0m
[34mLogs: 10[0m


[35m[1m--- EMBEDDING USAGE ---[0m
[90mTimestamp: 2026-01-27T11:00:51.068603Z[0m
[35mModel: m[0m
[35mOperation: o[0m
[35mInput Count: 5[0m
[35mPrompt Tokens: 100[0m
[35mTotal Tokens: 100[0m


[33m[1m--- COST RECORDED ---[0m
[90mTimestamp: 2026-01-27T11:00:51.068644Z[0m
[33mModel: m[0m
[33mOperation: o[0m
[33mToken Count: 100[0m
[33mCost Type: t[0m
[33mCost (USD): $0.001000[0m


[36m[1m--- RAG OPERATION COMPLETED ---[0m
[90mTimestamp: 2026-01-27T11:00:51.068747Z[0m
[36mOperation: search[0m
[36mDuration: 150ms[0m

[info] - should trace all event types without error
[info] Tracing.create
[info] - should create NoOp tracing for NoOp mode
[info] - should create Console tracing for Console mode
[info] - should create Langfuse tracing for Langfuse mode
[info] TracingComposer.combine
[info] - should combine multiple tracers
[info] - should succeed if at least one tracer succeeds
[info] - should fail if all tracers fail
[info] TracingComposer.filter
[info] - should only trace events matching predicate
[info] - should delegate other methods to underlying tracer
[info] TracingComposer.transform
[info] - should transform events before tracing
[info] Tracing convenience methods
[info] - should create correct events for traceEmbeddingUsage
[info] - should create correct events for traceCost
[info] - should create correct events for traceRAGOperation
[info] LLMConnectResultTest:
[info] - getClientResult returns OpenAIClient for openai/ model
[info] - getClientResult returns OpenRouterClient when base URL is OpenRouter
[info] - getClientResult returns OpenAIClient for Azure provider
[info] TypesSpec:
[info] ModelName
[info] - should create valid model names
[info] - should reject invalid model names
[info] - should have common constants
[info] - should report isEmpty and nonEmpty correctly
[info] - should convert to string via toString
[info] - should create from string without validation via fromString
[info] ProviderName
[info] - should create valid provider names
[info] - should reject empty provider names
[info] - should normalize to lowercase
[info] - should have common constants
[info] ApiKey
[info] - should hide value in toString
[info] - should reveal value when requested
[info] - should mask value showing only first 4 characters
[info] - should validate minimum length
[info] ConversationId
[info] - should generate unique IDs
[info] - should create valid IDs
[info] - should reject empty IDs
[info] - should trim whitespace
[info] CompletionId
[info] - should generate unique IDs
[info] - should create valid IDs
[info] - should reject empty IDs
[info] ToolName
[info] - should create valid tool names
[info] - should reject invalid tool names with special characters
[info] - should validate with isValid method
[info] ToolCallId
[info] - should generate unique IDs
[info] - should create valid IDs
[info] - should reject empty IDs
[info] Url
[info] - should create valid URLs
[info] - should reject invalid URLs
[info] - should validate with isValid method
[info] FilePath
[info] - should extract extension
[info] - should convert to string via toString
[info] PaginationInfo
[info] - should store pagination data
[info] CompressionTarget
[info] - should create valid targets
[info] - should reject invalid ratios
[info] - should validate with isValid
[info] - should have preset constants
[info] HeadroomPercent
[info] - should create valid headroom
[info] - should reject invalid headroom
[info] - should validate with isValid
[info] - should have preset constants
[info] - should convert to string
[info] - should provide asRatio
[info] ContentSize
[info] - should create from string
[info] - should create from bytes
[info] - should convert to KB and MB
[info] - should check threshold
[info] - should convert to string
[info] TokenEstimate
[info] - should store token count
[info] - should create with accuracy
[info] ArtifactKey
[info] - should generate unique keys
[info] - should create from content with hash
[info] - should create same key for same content
[info] - should create different keys for different content
[info] ContextSummary
[info] - should estimate token length
[info] SemanticBlockId
[info] - should generate short IDs
[info] AgentId
[info] - should generate unique IDs
[info] PlanId
[info] - should generate unique IDs
[info] Result.success
[info] - should create a Right
[info] Result.failure
[info] - should create a Left
[info] Result.fromOption
[info] - should convert Some to Right
[info] - should convert None to Left
[info] Result.sequence
[info] - should convert List[Result] to Result[List]
[info] - should fail on first error
[info] Result.traverse
[info] - should map and sequence
[info] Result.combine
[info] - should combine two results into tuple
[info] - should fail if first fails
[info] - should combine three results
[info] Result.safely
[info] - should wrap successful computation
[info] - should wrap failed computation
[info] Result.fromBoolean
[info] - should return success for true
[info] - should return failure for false
[info] Result.fromBooleanWithValue
[info] - should return value for true
[info] Result.validateAll
[info] - should collect all successes
[info] - should collect all errors
[info] AsyncResult
[info] - should work as Future[Result[A]] type alias
[info] - should hold failures correctly
[info] TryOps
[info] - should convert Success to Right
[info] - should convert Failure to Left
[info] OptionOps
[info] - should convert Some to Right
[info] - should convert None to Left
[info] JwtToken
[info] - should hide value in toString
[info] - should reveal value when requested
[info] OAuthToken
[info] - should hide value in toString
[info] - should reveal value when requested
[info] ConfigReaderTest:
[info] Llm4sConfig.provider
[info] - should expose values for present keys
[info] RecoverableErrorSpec:
[info] APIError
[info] - should create with smart constructor
[info] - should be a RecoverableError
[info] - should include context information
[info] - should handle optional fields
[info] - should support pattern matching with unapply
[info] NetworkError
[info] - should create with cause
[info] - should be a RecoverableError
[info] - should include exception type in context
[info] - should handle missing cause
[info] - should support pattern matching
[info] ServiceError
[info] - should create with HTTP status
[info] - should create with request ID
[info] - should be a RecoverableError
[info] - should provide retry delay
[info] - should identify recoverable HTTP status codes
[info] - should support pattern matching
[info] TimeoutError
[info] - should create with duration
[info] - should be a RecoverableError
[info] - should support withContext
[info] - should support withOperation
[info] - should optionally include cause
[info] ExecutionError
[info] - should create basic error
[info] - should be a RecoverableError
[info] - should support withExitCode
[info] - should support withContext
[info] - should optionally include cause
[info] RateLimitError
[info] - should create basic error
[info] - should create with retry delay
[info] - should be a RecoverableError
[info] - should have higher max retries
[info] - should calculate intelligent retry delay
[info] - should support pattern matching
[info] SystemError
[info] - should create basic error
[info] - should create with cause
[info] - should be a RecoverableError
[info] - should handle missing cause in context
[info] RecoverableError
[info] - should have default retry delay of None
[info] - should have default max retries of 3
[info] - should always report isRecoverable as true
[info] Recoverable errors
[info] - should format correctly
[info] - should include correlation ID when present
[info] LLMError.recoverableErrors
[info] - should filter only recoverable errors
16:30:51.109 [pool-1-thread-1-ScalaTest-running-MCPClientImplSpec] INFO  org.llm4s.mcp.MCPClientImpl -- MCPClientImpl created for server: test-server
[info] MCPClientImplSpec:
[info] MCPClientImpl.getTools
16:30:51.113 [pool-1-thread-1-ScalaTest-running-MCPClientImplSpec] INFO  org.llm4s.mcp.MCPClientImpl -- Server supports protocol version: 2025-06-18
16:30:51.114 [pool-1-thread-1-ScalaTest-running-MCPClientImplSpec] INFO  org.llm4s.mcp.MCPClientImpl -- Successfully initialized MCP client for test-server with protocol 2025-06-18
16:30:51.115 [pool-1-thread-1-ScalaTest-running-MCPClientImplSpec] ERROR org.llm4s.mcp.MCPClientImpl -- Failed to parse tools from test-server: key not found: inputSchema
[info] - should return tools when initialization succeeds
16:30:51.115 [pool-1-thread-1-ScalaTest-running-MCPClientImplSpec] INFO  org.llm4s.mcp.MCPClientImpl -- MCPClientImpl created for server: test-server
16:30:51.116 [pool-1-thread-1-ScalaTest-running-MCPClientImplSpec] ERROR org.llm4s.mcp.MCPClientImpl -- Initialize request failed: Initialization failed
16:30:51.116 [pool-1-thread-1-ScalaTest-running-MCPClientImplSpec] INFO  org.llm4s.mcp.MCPClientImpl -- MCPClientImpl created for server: test-server
[info] - should return empty sequence when initialization fails
16:30:51.117 [pool-1-thread-1-ScalaTest-running-MCPClientImplSpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(test-server) initialized with command: test-command
16:30:51.117 [pool-1-thread-1-ScalaTest-running-MCPClientImplSpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(test-server) starting new process: test-command
16:30:51.123 [pool-1-thread-1-ScalaTest-running-MCPClientImplSpec] ERROR org.llm4s.mcp.StdioTransportImpl -- StdioTransport(test-server) failed to start process: Cannot run program "test-command": error=2, No such file or directory
java.io.IOException: Cannot run program "test-command": error=2, No such file or directory
	at java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1140)
	at java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1074)
	at org.llm4s.mcp.StdioTransportImpl.startNewProcess$$anonfun$1(MCPTransport.scala:658)
	at scala.util.Try$.apply(Try.scala:217)
	at org.llm4s.mcp.StdioTransportImpl.startNewProcess(MCPTransport.scala:692)
	at org.llm4s.mcp.StdioTransportImpl.getOrStartProcess(MCPTransport.scala:648)
	at org.llm4s.mcp.StdioTransportImpl.sendRequest(MCPTransport.scala:846)
	at org.llm4s.mcp.MCPClientImpl.initialize$$anonfun$1(MCPClientImpl.scala:141)
	at scala.util.Either.flatMap(Either.scala:360)
	at org.llm4s.mcp.MCPClientImpl.initialize(MCPClientImpl.scala:116)
	at org.llm4s.mcp.MCPClientImpl.getTools(MCPClientImpl.scala:193)
	at org.llm4s.mcp.MCPClientImplSpec.testFun$proxy3$1(MCPClientImplSpec.scala:100)
	at org.llm4s.mcp.MCPClientImplSpec.$init$$$anonfun$3(MCPClientImplSpec.scala:94)
	at org.scalatest.Transformer.apply$$anonfun$1(Transformer.scala:22)
	at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:31)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:21)
	at org.scalatest.flatspec.AnyFlatSpecLike$$anon$5.apply(AnyFlatSpecLike.scala:1717)
	at org.scalatest.TestSuite.withFixture(TestSuite.scala:196)
	at org.scalatest.TestSuite.withFixture$(TestSuite.scala:138)
	at org.llm4s.mcp.MCPClientImplSpec.org$scalamock$scalatest$AbstractMockFactory$$super$withFixture(MCPClientImplSpec.scala:11)
	at org.scalamock.scalatest.AbstractMockFactory.withFixture$$anonfun$1(AbstractMockFactory.scala:35)
	at org.scalamock.MockFactoryBase.withExpectations(MockFactoryBase.scala:41)
	at org.scalamock.MockFactoryBase.withExpectations$(MockFactoryBase.scala:28)
	at org.llm4s.mcp.MCPClientImplSpec.withExpectations(MCPClientImplSpec.scala:11)
	at org.scalamock.scalatest.AbstractMockFactory.withFixture(AbstractMockFactory.scala:44)
	at org.scalamock.scalatest.AbstractMockFactory.withFixture$(AbstractMockFactory.scala:27)
	at org.llm4s.mcp.MCPClientImplSpec.withFixture(MCPClientImplSpec.scala:11)
	at org.scalatest.flatspec.AnyFlatSpecLike.invokeWithFixture$1(AnyFlatSpecLike.scala:1723)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTest$$anonfun$1(AnyFlatSpecLike.scala:1727)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTest(AnyFlatSpecLike.scala:1727)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTest$(AnyFlatSpecLike.scala:51)
	at org.scalatest.flatspec.AnyFlatSpec.runTest(AnyFlatSpec.scala:1685)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTests$$anonfun$1(AnyFlatSpecLike.scala:1785)
	at org.scalatest.SuperEngine.traverseSubNodes$1$$anonfun$1(Engine.scala:413)
	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)
	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)
	at scala.collection.immutable.List.foreach(List.scala:334)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:429)
	at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390)
	at org.scalatest.SuperEngine.traverseSubNodes$1$$anonfun$1(Engine.scala:427)
	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)
	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)
	at scala.collection.immutable.List.foreach(List.scala:334)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:429)
	at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTests(AnyFlatSpecLike.scala:1785)
	at org.scalatest.flatspec.AnyFlatSpecLike.runTests$(AnyFlatSpecLike.scala:51)
	at org.scalatest.flatspec.AnyFlatSpec.runTests(AnyFlatSpec.scala:1685)
	at org.scalatest.Suite.run(Suite.scala:1114)
	at org.scalatest.Suite.run$(Suite.scala:564)
	at org.scalatest.flatspec.AnyFlatSpec.org$scalatest$flatspec$AnyFlatSpecLike$$super$run(AnyFlatSpec.scala:1685)
	at org.scalatest.flatspec.AnyFlatSpecLike.run$$anonfun$1(AnyFlatSpecLike.scala:1830)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:535)
	at org.scalatest.flatspec.AnyFlatSpecLike.run(AnyFlatSpecLike.scala:1830)
	at org.scalatest.flatspec.AnyFlatSpecLike.run$(AnyFlatSpecLike.scala:51)
	at org.scalatest.flatspec.AnyFlatSpec.run(AnyFlatSpec.scala:1685)
	at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)
	at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:414)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1623)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.base/java.lang.ProcessImpl.forkAndExec(Native Method)
	at java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:319)
	at java.base/java.lang.ProcessImpl.start(ProcessImpl.java:249)
	at java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1111)
	... 67 common frames omitted
16:30:51.123 [pool-1-thread-1-ScalaTest-running-MCPClientImplSpec] ERROR org.llm4s.mcp.MCPClientImpl -- Initialize request failed: Failed to start MCP server process: Cannot run program "test-command": error=2, No such file or directory
[info] - should return empty sequence when no transport is available
16:30:51.124 [pool-1-thread-1-ScalaTest-running-MCPClientImplSpec] INFO  org.llm4s.mcp.MCPClientImpl -- MCPClientImpl created for server: test-server
16:30:51.124 [pool-1-thread-1-ScalaTest-running-MCPClientImplSpec] INFO  org.llm4s.mcp.MCPClientImpl -- Server supports protocol version: 2025-06-18
16:30:51.125 [pool-1-thread-1-ScalaTest-running-MCPClientImplSpec] ERROR org.llm4s.mcp.MCPClientImpl -- Invalid initialization response format
[info] - should handle invalid tool responses
[info] ClientStatusSpec:
[info] - ConnectionStatus.Connected represents healthy state
[info] - ConnectionStatus.Disconnected represents disconnected state
[info] - ConnectionStatus.Connecting represents in-progress connection
[info] - ConnectionStatus.Error captures error message and optional cause
[info] - ConnectionStatus.Error works without cause
[info] - ProviderCapabilities captures provider features
[info] - ClientHealth captures full health status
[info] - ClientHealth defaults work correctly
[info] CrawlerConfigSpec:
[info] CrawlerConfig
[info] - should have sensible defaults
[info] - should support fluent configuration
[info] CrawlerConfig.polite
[info] - should have conservative settings
[info] CrawlerConfig.fast
[info] - should have aggressive settings
[info] CrawlerConfig.singlePage
[info] - should not follow links
[info] CrawlerConfig
[info] - should accept content types configuration
[info] - should accept max queue size configuration
[info] VectorMemoryStoreSpec:
[info] VectorMemoryStore
[info] - should store and retrieve a memory with embedding
[info] - should return None for non-existent memory
[info] - should preserve existing embedding when storing
[info] - should perform semantic search using embeddings
[info] - should return top-K results sorted by similarity
[info] - should apply filter during semantic search
[info] - should recall memories by type
[info] - should recall memories by conversation ID
[info] - should recall memories by entity ID
[info] - should recall memories by time range
[info] - should recall memories by minimum importance
[info] - should delete a memory
[info] - should delete matching memories
[info] - should update a memory
[info] - should re-embed when content changes on update
[info] - should count all memories
[info] - should count memories with filter
[info] - should clear all memories
[info] - should get recent memories in order
[info] - should embed all memories without embeddings
[info] - should provide vector statistics
[info] - should support AND filters
[info] - should support OR filters
[info] - should support NOT filters
[info] - should handle empty search query
[info] - should handle special characters in content
[info] - should handle metadata with special characters
[info] - should handle custom memory types
[info] DocumentExtractorSpec:
[info] DefaultDocumentExtractor
[info] - should extract plain text content
[info] - should extract markdown content
[info] - should extract JSON content as text
[info] - should extract XML content as text
[info] - should extract CSV content as text
[info] - should detect MIME type from bytes and filename
[info] - should detect PDF MIME type
[info] - should report ability to extract text formats
[info] - should report inability to extract binary formats
[info] - should use provided MIME type instead of detection
[info] - should include filename in metadata
[info] - should include byte length in metadata
[info] - should handle empty content gracefully
[info] - should handle non-UTF8 text gracefully
[info] - should extract text from InputStream
[info] - should extract UTF-8 content from InputStream
[info] - should handle empty InputStream
[info] - should use provided MIME type for stream extraction
[info] - should extract text from HTML content
[info] - should extract RST content as plain text
[info] - should handle large text content
[info] - should handle content with special characters
[info] - should handle unknown MIME types in canExtract
[info] - should handle text subtypes in canExtract
[info] MCPTypesSpec:
[info] JsonRpcRequest
[info] - should serialize to JSON correctly
[info] - should serialize without params
[info] - should deserialize from JSON
[info] JsonRpcNotification
[info] - should serialize to JSON correctly
[info] - should serialize without params
[info] JsonRpcResponse
[info] - should serialize successful response
[info] - should serialize error response
[info] - should deserialize from JSON
[info] JsonRpcError
[info] - should serialize with optional data
[info] - should serialize without data
[info] ClientInfo
[info] - should serialize correctly
[info] ServerInfo
[info] - should serialize correctly
[info] MCPCapabilities
[info] - should have sensible defaults
[info] - should serialize to JSON
[info] InitializeRequest
[info] - should serialize correctly
[info] InitializeResponse
[info] - should deserialize correctly
[info] MCPTool
[info] - should serialize correctly
[info] - should deserialize correctly
[info] ToolsListResponse
[info] - should serialize list of tools
[info] - should deserialize empty list
[info] ToolsCallRequest
[info] - should serialize with arguments
[info] - should serialize without arguments
[info] ToolsCallResponse
[info] - should serialize with content
[info] - should serialize error response
[info] MCPContent
[info] - should serialize text content
[info] - should serialize resource content
[info] - should serialize with annotations
[info] ResourceReference
[info] - should serialize with type
[info] - should serialize without type
[info] MCPErrorCodes
[info] - should define standard JSON-RPC error codes
[info] - should define MCP-specific error codes
[info] - should return correct error messages
[info] - should create transport error
[info] - should create timeout error
[info] - should create tool not found error
[info] - should create tool execution error
[info] ContextPrecisionSpec:
[info] ContextPrecision
[info] - should have correct metadata
[info] - should return score 1.0 when relevant doc is at position 1
[info] - should return score 1.0 when all relevant docs are at top positions
[info] - should return lower score when relevant docs are at lower positions
[info] - should return score 0.0 when no contexts are relevant
[info] - should fail when ground truth is missing
[info] - should return score 0.0 when ground truth is empty
[info] - should return score 0.0 when no contexts provided
[info] - should handle JSON response wrapped in markdown code blocks
[info] - should include details about relevance per position in result
[info] TestDatasetSpec:
[info] TestDataset
[info] - should parse JSON with all fields
[info] - should parse JSON with minimal fields
[info] - should parse JSON with null ground_truth
[info] - should convert dataset to JSON
[info] - should filter samples with ground truth
[info] - should filter samples without ground truth
[info] - should take first n samples
[info] - should sample random subset
[info] - should add metadata
[info] - should create empty dataset
[info] - should create single sample dataset
[info] - should save and load dataset from file
[info] - should fail gracefully for invalid JSON
[info] - should fail gracefully for missing file
[info] - should round-trip JSON conversion
16:30:51.205 [pool-1-thread-1-ScalaTest-running-OrchestrationTest] INFO  o.l.agent.orchestration.PlanRunner -- Starting plan execution with 2 nodes and 1 edges
[info] OrchestrationTest:
16:30:51.205 [scala-execution-context-global-234] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed successfully with 2 results
16:30:51.205 [scala-execution-context-global-234] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed
[info] - PlanRunner should execute simple DAG with cancellation support
16:30:51.206 [scala-execution-context-global-234] WARN  o.l.agent.orchestration.Policies$ -- Agent flaky failed on attempt 1 of 5, retrying: NodeExecutionError: Node execution failed [flaky:flaky]: Simulated failure[component=node-execution,nodeId=flaky,nodeName=flaky,recoverable=true]
16:30:51.311 [scala-execution-context-global-75] WARN  o.l.agent.orchestration.Policies$ -- Agent flaky failed on attempt 2 of 5, retrying: NodeExecutionError: Node execution failed [flaky:flaky]: Simulated failure[component=node-execution,nodeId=flaky,nodeName=flaky,recoverable=true]
16:30:51.512 [scala-execution-context-global-234] INFO  o.l.agent.orchestration.Policies$ -- Agent flaky succeeded on attempt 3 of 5
[info] - Policies should use non-blocking delays
[info] - MDCContext should preserve context across async boundaries
[info] - CancellationToken should support cancellation callbacks
16:30:51.516 [pool-1-thread-1-ScalaTest-running-OrchestrationTest] INFO  o.l.agent.orchestration.PlanRunner -- Starting plan execution with 10 nodes and 0 edges
16:30:51.937 [scala-execution-context-global-228] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed successfully with 10 results
16:30:51.937 [scala-execution-context-global-228] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed
[info] - PlanRunner should respect maxConcurrentNodes limit
[info] AssistantErrorSpec:
[info] AssistantError.IOError
[info] - should create with operation
[info] - should create with cause
[info] - should include component and operation in context
[info] - should format correctly
[info] AssistantError.EOFError
[info] - should create with default read operation
[info] - should include reason in context
[info] AssistantError.DisplayError
[info] - should create with display type
[info] - should create with cause
[info] - should include display type in context
[info] AssistantError.SessionError
[info] - should create with session ID and operation
[info] - should include session context
[info] - should create with cause
[info] AssistantError.FileError
[info] - should create with path and operation
[info] - should include file context
[info] AssistantError.SerializationError
[info] - should create with data type and operation
[info] - should include serialization context
[info] AssistantError.CommandParseError
[info] - should create with command and parse operation
[info] - should include command context
[info] AssistantError.sessionNotFound
[info] - should create session not found error
[info] AssistantError.sessionTitleNotFound
[info] - should create session title not found error
[info] AssistantError.fileReadFailed
[info] - should create file read failed error
[info] AssistantError.fileWriteFailed
[info] - should create file write failed error
[info] AssistantError.jsonSerializationFailed
[info] - should create JSON serialization error
[info] AssistantError.jsonDeserializationFailed
[info] - should create JSON deserialization error
[info] AssistantError.consoleInputFailed
[info] - should create console input error
[info] AssistantError.consoleOutputFailed
[info] - should create console output error
[info] AssistantError.emptyCommandTitle
[info] - should create empty title error
[info] AssistantError.unknownCommand
[info] - should create unknown command error
[info] AssistantError
[info] - should format with context
[info] - should format without context when empty
[info] AssistantError subtypes
[info] - should all extend AssistantError
[info] - should be Products and Serializable
[info] DocumentVersionSpec:
[info] DocumentVersion
[info] - should create version with content hash
[info] - should create version with all fields
[info] - should be equal when content hash matches
[info] NonRecoverableErrorSpec:
[info] AuthenticationError
[info] - should create with provider and details
[info] - should create with error code
[info] - should be a NonRecoverableError
[info] - should create unauthorized error
[info] - should create invalid API key error
[info] - should support pattern matching
[info] ValidationError
[info] - should create with single reason
[info] - should create with multiple violations
[info] - should be a NonRecoverableError
[info] - should create required field error
[info] - should create invalid field error
[info] - should support adding violations
[info] - should include violations in context
[info] - should support pattern matching
[info] ConfigurationError
[info] - should create with message
[info] - should create with missing keys
[info] - should be a NonRecoverableError
[info] - should not include missingKeys in context when empty
[info] - should support pattern matching
[info] ProcessingError
[info] - should create with operation and message
[info] - should create with cause
[info] - should be a NonRecoverableError
[info] - should create audio-specific errors
[info] - should support pattern matching
[info] InvalidInputError
[info] - should create with field, value, and reason
[info] - should be a NonRecoverableError
[info] - should include all fields in context
[info] - should support pattern matching
[info] NotFoundError
[info] - should create with message and key
[info] - should be a NonRecoverableError
[info] - should include key in context
[info] ContextError
[info] - should create token budget exceeded error
[info] - should create invalid trimming error
[info] - should create conversation too large error
[info] - should create empty result error
[info] - should create semantic blocking failed error
[info] - should create summarization failed error
[info] - should create compression failed error
[info] - should create pipeline failed error
[info] - should create tool compression failed error
[info] - should create externalization failed error
[info] - should create artifact store failed error
[info] - should create schema compression failed error
[info] - should create LLM compression failed error
[info] - should create token estimation failed error
[info] - should be a NonRecoverableError
[info] - should support pattern matching
[info] TokenizerError
[info] - should create not available error
[info] - should create not found error
[info] - should be a NonRecoverableError
[info] - should include tokenizer ID in context
[info] - should support pattern matching
[info] UnknownError
[info] - should create with message and cause
[info] - should be a NonRecoverableError
[info] - should include exception details in context
[info] - should support pattern matching
[info] SimpleError
[info] - should create with just message
[info] - should be a NonRecoverableError
[info] - should have empty context
[info] - should support pattern matching
[info] NonRecoverableError
[info] - should always report isRecoverable as false
[info] LLMError.nonRecoverableErrors
[info] - should filter only non-recoverable errors
[info] LLMError smart constructors
[info] - should create processing error
[info] - should create invalid image input error
[info] - should create API call failed error
[info] SchemaDefinitionSpec:
[info] StringSchema
[info] - should generate basic JSON schema
[info] - should include enum values when specified
[info] - should include length constraints when specified
[info] - should support chained configuration
[info] NumberSchema
[info] - should generate basic JSON schema
[info] - should generate integer type when isInteger is true
[info] - should include range constraints
[info] - should include exclusive range constraints
[info] - should include multipleOf constraint
[info] IntegerSchema
[info] - should generate integer JSON schema
[info] - should include range constraints
[info] - should include exclusive range constraints
[info] - should include multipleOf constraint
[info] BooleanSchema
[info] - should generate boolean JSON schema
[info] ArraySchema
[info] - should generate array JSON schema with item schema
[info] - should include size constraints
[info] - should include uniqueItems constraint
[info] - should support nested array schemas
[info] ObjectSchema
[info] - should generate object JSON schema with properties
[info] - should mark required fields in required array
[info] - should make all properties required in strict mode
[info] - should support withRequiredField helper
[info] - should support withOptionalField helper
[info] - should include additionalProperties setting
[info] NullableSchema
[info] - should add null to type for simple schema
[info] - should add null to existing type array
[info] - should preserve description from underlying schema
[info] Schema builder
[info] - should create string schema
[info] - should create number schema
[info] - should create integer schema
[info] - should create boolean schema
[info] - should create array schema
[info] - should create object schema
[info] - should create nullable schema
[info] - should create property definition
[info] PropertyDefinition
[info] - should default to required = true
[info] - should allow specifying required = false
[info] MarkdownChunkerSpec:
[info] MarkdownChunker
[info] - should handle empty text
[info] - should return single chunk for short text
[info] - should detect heading levels
[info] - should track heading hierarchy in metadata
[info] - should keep code blocks intact when possible
[info] - should mark code blocks in metadata
[info] - should detect code block language
[info] - should handle code blocks without language
[info] - should split large code blocks when necessary
[info] - should handle nested heading levels
[info] - should handle unclosed code blocks
[info] - should preserve list structure
[info] - should handle mixed content
[info] - should assign sequential indices
[info] ChunkerFactory
[info] - should create markdown chunker
[info] - should create markdown chunker by name
[info] - should create markdown chunker by strategy enum
[info] - should auto-detect markdown content and return MarkdownChunker
[info] AgentStatusSpec:
[info] AgentStatus.InProgress
[info] - should be a singleton
[info] AgentStatus.WaitingForTools
[info] - should be a singleton
[info] AgentStatus.Complete
[info] - should be a singleton
[info] AgentStatus.Failed
[info] - should store error message
[info] - should support equality based on error message
[info] AgentStatus.HandoffRequested
[info] - should store handoff and reason
[info] - should allow None for handoff reason
[info] AgentStatus serialization
[info] - should serialize InProgress to string
[info] - should serialize WaitingForTools to string
[info] - should serialize Complete to string
[info] - should serialize Failed to object with error
[info] AgentStatus deserialization
[info] - should deserialize InProgress
[info] - should deserialize WaitingForTools
[info] - should deserialize Complete
[info] - should deserialize Failed with error
[info] - should handle Failed without error field
[info] AgentStatus.HandoffRequested serialization
[info] - should serialize with handoff ID
[info] - should serialize with null reason when None
[info] - should return Failed status when attempting to deserialize HandoffRequested
[info] AgentStatus deserialization
[info] - should handle unknown status format
[info] - should handle invalid JSON structure
[info] AgentStatus
[info] - should round-trip InProgress
[info] - should round-trip WaitingForTools
[info] - should round-trip Complete
[info] - should round-trip Failed
[info] AgentStatus
[info] - should support exhaustive pattern matching
[info] SimilarityUtilsSpec:
[info] - cosine similarity of identical vectors should be 1.0
[info] - cosine similarity of orthogonal vectors should be 0.0
[info] - cosine similarity of opposite vectors should be -1.0
[info] - cosine similarity of similar vectors should be positive
[info] - cosine similarity handles different magnitude vectors
[info] - cosine similarity with unit vectors
[info] GuardrailSpec:
[info] LengthCheck
[info] - should accept input within bounds
[info] - should reject input that is too short
[info] - should reject input that is too long
[info] - should accept input at exact minimum
[info] - should accept input at exact maximum
[info] LengthCheck.maxOnly
[info] - should only check maximum length
[info] LengthCheck.minOnly
[info] - should only check minimum length
[info] ProfanityFilter
[info] - should accept clean content
[info] - should reject inappropriate content
[info] - should be case-insensitive by default
[info] - should support custom bad words
[info] - should be case-sensitive when configured
[info] JSONValidator
[info] - should accept valid JSON
[info] - should accept valid JSON array
[info] - should reject invalid JSON
[info] - should reject malformed JSON
[info] RegexValidator
[info] - should accept matching content
[info] - should reject non-matching content
[info] - should support custom error messages
[info] RegexValidator.email
[info] - should validate email addresses
[info] RegexValidator.alphanumeric
[info] - should accept only alphanumeric
[info] ToneValidator
[info] - should accept allowed tones
[info] - should reject disallowed tones
[info] ToneValidator.professionalOnly
[info] - should only allow professional tone
[info] CompositeGuardrail.all
[info] - should pass if all guardrails pass
[info] - should fail if any guardrail fails
[info] - should aggregate all errors
[info] CompositeGuardrail.any
[info] - should pass if any guardrail passes
[info] - should fail if all guardrails fail
[info] CompositeGuardrail.sequential
[info] - should run guardrails in sequence
[info] - should short-circuit on first failure
[info] Guardrail.andThen
[info] - should compose guardrails
[info] LLMGuardrailSpec:
[info] LLMGuardrail
[info] - should pass when score is above threshold
[info] - should fail when score is below threshold
[info] - should pass when score equals threshold
[info] - should parse scores with extra whitespace
[info] - should clamp scores above 1.0 to 1.0
[info] - should handle negative scores by stripping non-numeric chars
[info] - should fail gracefully when LLM returns unparseable response
[info] - should propagate LLM client errors
[info] - should include content and prompt in LLM request
[info] LLMToneGuardrail
[info] - should pass for matching tone
[info] - should fail for mismatching tone
[info] - should include allowed tones in evaluation prompt
[info] LLMToneGuardrail.professional
[info] - should create professional tone guardrail
[info] LLMFactualityGuardrail
[info] - should pass for factually accurate content
[info] - should fail for factually inaccurate content
[info] - should include reference context in evaluation prompt
[info] LLMFactualityGuardrail.strict
[info] - should use higher threshold
[info] LLMSafetyGuardrail
[info] - should pass for safe content
[info] - should fail for unsafe content
[info] - should use higher default threshold than other guardrails
[info] LLMSafetyGuardrail.strict
[info] - should use even higher threshold
[info] LLMSafetyGuardrail.withCustomCriteria
[info] - should include custom criteria
[info] LLMQualityGuardrail
[info] - should pass for high quality responses
[info] - should fail for low quality responses
[info] - should include original query in evaluation prompt
[info] LLM guardrails
[info] - should compose with function-based guardrails
[info] - should fail composite if any guardrail fails
[info] - should chain with andThen
[info] LLMConnectProviderTypeSafetyTest:
[info] - OpenAI provider with OpenAIConfig returns OpenAIClient
[info] - OpenRouter provider with OpenAIConfig returns OpenRouterClient
[info] - Azure provider with AzureConfig returns OpenAIClient (Azure-backed)
[info] - Anthropic provider with AnthropicConfig returns AnthropicClient
[info] - Ollama provider with OllamaConfig returns OllamaClient
[info] - OpenAI provider with non-OpenAIConfig should throw IllegalArgumentException
[info] - OpenRouter provider with non-OpenAIConfig should throw IllegalArgumentException
[info] - Azure provider with non-AzureConfig should throw IllegalArgumentException
[info] ReasoningModesSpec:
[info] ReasoningEffort
[info] - should parse valid effort levels from strings
[info] - should be case-insensitive when parsing
[info] - should handle whitespace when parsing
[info] - should return None for invalid strings
[info] - should have correct name values
[info] - should provide default budget tokens for each level
[info] - should contain all values in values sequence
[info] CompletionOptions
[info] - should support withReasoning builder
[info] - should support withBudgetTokens builder
[info] - should chain builders correctly
[info] - should detect when reasoning is enabled
[info] - should calculate effective budget tokens
[info] - should preserve other options when adding reasoning
[info] Completion
[info] - should detect when thinking content is present
[info] - should generate fullContent correctly
[info] - should return just content when no thinking
[info] TokenUsage
[info] - should calculate total output tokens correctly
[info] - should detect when thinking tokens are present
[info] StreamedChunk
[info] - should detect thinking content
[info] - should detect main content
[info] - should handle both content and thinking
[info] Llm4sConfigProviderSpec:
[info] Llm4sConfig.provider
[info] - should load OpenAI config from llm4s.* defaults
[info] CohereRerankerSpec:
[info] RerankRequest
[info] - should create with query and documents
[info] - should support topK parameter
[info] RerankResponse
[info] - should store results and metadata
[info] RerankResult
[info] - should preserve index, score, and document
[info] RerankProviderConfig
[info] - should store configuration
[info] CohereReranker
[info] - should have correct default values
[info] - should create from individual parameters
[info] - should create from config
[info] RerankerFactory
[info] - should create Cohere reranker
[info] - should parse backend from string
[info] RerankerFactory.passthrough
[info] - should preserve original order with decreasing scores
[info] - should respect topK parameter
[info] RerankError
[info] - should extend LLMError
[info] TraceEventSpec:
[info] TraceEvent.AgentInitialized
[info] - should have correct event type
[info] - should serialize to JSON correctly
[info] - should handle empty tools list
[info] TraceEvent.CompletionReceived
[info] - should have correct event type
[info] - should serialize to JSON correctly
[info] TraceEvent.ToolExecuted
[info] - should have correct event type
[info] - should serialize to JSON correctly
[info] - should track failed executions
[info] TraceEvent.ErrorOccurred
[info] - should have correct event type
[info] - should serialize to JSON with error details
[info] TraceEvent.TokenUsageRecorded
[info] - should have correct event type
[info] - should serialize to JSON correctly
[info] TraceEvent.AgentStateUpdated
[info] - should have correct event type
[info] - should serialize to JSON correctly
[info] TraceEvent.CustomEvent
[info] - should have correct event type
[info] - should serialize to JSON correctly
[info] TraceEvent.EmbeddingUsageRecorded
[info] - should have correct event type
[info] - should serialize to JSON correctly
[info] TraceEvent.CostRecorded
[info] - should have correct event type
[info] - should serialize to JSON correctly
[info] TraceEvent.RAGOperationCompleted
[info] - should have correct event type
[info] - should serialize to JSON with optional fields
[info] - should omit optional fields when not provided
[info] TraceEvent.createTraceEvent
[info] - should create a trace creation event
[info] TraceEvent
[info] - should have timestamp on all events
[info] - should serialize all events to JSON
[info] SourceBackedLoaderSpec:
[info] SourceBackedLoader
[info] - should load documents from a DocumentSource
[info] - should include metadata from source
[info] - should add additional metadata
[info] - should detect document hints based on extension
[info] - should include version info from source etag
[info] - should report estimated count from source
[info] - should have a descriptive description
16:30:52.071 [pool-1-thread-1-ScalaTest-running-SourceBackedLoaderSpec] WARN  o.l.r.e.DefaultDocumentExtractor$ -- Tika extraction returned empty text for binary.exe
[info] - should handle extraction failure gracefully
[info] - should handle source listing errors
[info] - should handle document read errors
[info] - should handle empty source
[info] - should propagate source metadata to documents
[info] - should combine with another loader using ++
[info] TypeclassSpec:
[info] Encoder.apply
[info] - should summon implicit encoder
[info] Encoder.encode
[info] - should encode using implicit encoder
[info] Encoder.fromFunction
[info] - should create encoder from function
[info] Encoder.EncoderOps
[info] - should provide encode extension method
[info] LLMCapable[String]
[info] - should convert string to conversation
[info] - should extract string from completion
[info] - should validate non-empty strings
[info] - should reject empty strings
[info] LLMCapable[Conversation]
[info] - should pass through conversation
[info] - should extract conversation from completion
[info] - should validate non-empty conversations
[info] - should reject empty conversations
[info] LLMCapableOps.toLLMConversation
[info] - should use implicit instance
[info] LLMCapableOps.validateForLLM
[info] - should use implicit instance
[info] Custom LLMCapable instance
[info] - should work with case classes
[info] HybridSearcherSpec:
[info] HybridSearcher
[info] - should perform vector-only search
[info] - should perform keyword-only search
[info] - should perform hybrid search with RRF fusion
[info] - should perform hybrid search with weighted score fusion
[info] - should boost results that match both vector and keyword
[info] - should include highlights from keyword search
[info] - should respect metadata filters
[info] - should handle empty results gracefully
[info] - should use default strategy when none specified
[info] HybridSearcher factory
[info] - should create from in-memory stores
[info] - should create from configuration
[info] - should support weighted score configuration
[info] FusionStrategy
[info] - should have sensible RRF default
[info] - should have balanced WeightedScore default
[info] - should reject negative weights
[info] ToolOutputCompressorSpec:
[info] ToolOutputCompressor content type detection
[info] - should identify JSON objects
[info] - should identify JSON arrays
[info] - should identify log content
[info] - should identify error traces
[info] - should identify binary content
[info] ToolOutputCompressor JSON compression
[info] - should remove null values when compressed
[info] - should remove empty strings from JSON
[info] - should truncate large arrays to head + tail
[info] ToolOutputCompressor log compression
[info] - should keep short logs unchanged
[info] - should compress long logs when over inline threshold
[info] ToolOutputCompressor externalization
[info] - should externalize content over threshold
[info] - should create content pointers for externalized content
[info] - should store externalized content in artifact store
[info] InMemoryArtifactStore
[info] - should store and retrieve content
[info] - should return None for missing keys
[info] - should overwrite existing content
[info] ToolOutputCompressor
[info] - should pass through non-tool messages unchanged
[info] - should handle empty message list
[info] - should preserve tool call IDs
[info] - should handle invalid JSON gracefully
[info] - should handle multiple tool messages
[info] KeywordIndexSpec:
[info] KeywordIndex
[info] - should index and retrieve a single document
[info] - should return None for non-existent document
[info] - should index multiple documents in batch
[info] - should update existing document
[info] - should delete a document
[info] - should delete multiple documents
[info] - should clear all documents
[info] - should search for matching documents
[info] - should rank results by relevance (BM25)
[info] - should search with phrase matching
[info] - should search with highlighted snippets
[info] - should filter results by metadata
[info] - should combine filters with AND/OR
[info] - should return correct statistics
[info] - should handle empty queries gracefully
[info] - should handle special characters in content
[info] SQLiteKeywordIndex factory
[info] - should create index from config
[info] - should support file-based persistence
[info] CoreToolsSpec:
[info] DateTimeTool
[info] - should return current date/time in default timezone
[info] - should support custom timezone
[info] - should return error for invalid timezone
[info] CalculatorTool
[info] - should perform addition
[info] - should perform subtraction
[info] - should perform multiplication
[info] - should perform division
[info] - should handle division by zero
[info] - should perform square root
[info] - should handle negative square root
[info] - should calculate power
[info] - should calculate percentage
[info] - should reject unknown operation
[info] UUIDTool
[info] - should generate a UUID
[info] - should generate multiple UUIDs
[info] - should generate standard format UUID
[info] - should generate compact format UUID
[info] JSONTool
[info] - should parse valid JSON
[info] - should return error for invalid JSON
[info] - should format JSON with pretty printing
[info] - should query JSON with path
[info] - should query array elements
[info] - should validate JSON
[info] AgentStateSerializationSpec:
[info] ReasoningEffort serialization
[info] - should serialize None to 'none'
[info] - should serialize Low to 'low'
[info] - should serialize Medium to 'medium'
[info] - should serialize High to 'high'
[info] - should deserialize 'none' to None
[info] - should deserialize 'low' to Low
[info] - should deserialize 'medium' to Medium
[info] - should deserialize 'high' to High
[info] - should round-trip all ReasoningEffort values
[info] - should throw on invalid string
[info] - should throw on non-string value
[info] CompletionOptions serialization
[info] - should preserve all basic fields
[info] - should preserve reasoning field when set
[info] - should preserve budgetTokens field when set
[info] - should preserve both reasoning and budgetTokens together
[info] - should handle None reasoning as null in JSON
[info] - should handle None budgetTokens as null in JSON
[info] AgentState serialization
[info] - should round-trip basic state
[info] - should round-trip state with all CompletionOptions including reasoning
[info] - should preserve conversation with tool messages
[info] AgentStatus serialization
[info] - should serialize InProgress
[info] - should serialize WaitingForTools
[info] - should serialize Complete
[info] - should serialize Failed with error message
[info] - should round-trip all basic statuses
[info] AgentState deserialization
[info] - should handle JSON without reasoning field (backward compat)
[info] Message serialization
[info] - should round-trip UserMessage
[info] - should round-trip SystemMessage
[info] - should round-trip AssistantMessage with content
[info] - should round-trip AssistantMessage with tool calls
[info] - should round-trip ToolMessage
[info] Conversation serialization
[info] - should round-trip empty conversation
[info] - should round-trip multi-message conversation
[info] BuiltinToolsSpec:
[info] BuiltinTools.core
[info] - should include all core utilities
[info] BuiltinTools.safe
[info] - should include core tools plus safe network tools
[info] - should not include shell or file tools
[info] BuiltinTools.withFiles
[info] - should include file system tools
[info] - should not include write or shell tools
[info] BuiltinTools.development
[info] - should include all tools
[info] BuiltinTools.custom
[info] - should allow selective tool inclusion
[info] - should allow excluding search
[info] - should include HTTP when configured
[info] - should include files when configured
[info] - should include write when configured
[info] - should include shell when configured
16:30:52.140 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) initialized with command: bash -c while IFS= read -r line; do
           id=$(echo "$line" | grep -o '"id":"[^"]*"' | cut -d'"' -f4)
           if [ -n "$id" ]; then
             echo "{\"jsonrpc\":\"2.0\",\"id\":\"$id\",\"result\":{\"echo\":\"response-$id\"}}"
           fi
         done
16:30:52.140 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) starting new process: bash -c while IFS= read -r line; do
           id=$(echo "$line" | grep -o '"id":"[^"]*"' | cut -d'"' -f4)
           if [ -n "$id" ]; then
             echo "{\"jsonrpc\":\"2.0\",\"id\":\"$id\",\"result\":{\"echo\":\"response-$id\"}}"
           fi
         done
[info] StdioTransportConcurrencySpec:
[info] StdioTransportImpl
16:31:02.233 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) process started and ready
16:31:02.236 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) writing to stdin: {"jsonrpc":"2.0","id":"warmup","method":"test/warmup"}
16:31:02.249 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) received from stdout: {"jsonrpc":"2.0","id":"warmup","result":{"echo":"response-warmup"}}
16:31:02.252 [pool-4-thread-2] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) writing to stdin: {"jsonrpc":"2.0","id":"concurrent-2","method":"test/method","params":{"value":2}}
16:31:02.252 [pool-4-thread-5] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) writing to stdin: {"jsonrpc":"2.0","id":"concurrent-5","method":"test/method","params":{"value":5}}
16:31:02.252 [pool-4-thread-1] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) writing to stdin: {"jsonrpc":"2.0","id":"concurrent-1","method":"test/method","params":{"value":1}}
16:31:02.252 [pool-4-thread-3] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) writing to stdin: {"jsonrpc":"2.0","id":"concurrent-3","method":"test/method","params":{"value":3}}
16:31:02.253 [pool-4-thread-4] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) writing to stdin: {"jsonrpc":"2.0","id":"concurrent-4","method":"test/method","params":{"value":4}}
16:31:02.263 [pool-4-thread-5] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) received from stdout: {"jsonrpc":"2.0","id":"concurrent-5","result":{"echo":"response-concurrent-5"}}
16:31:02.263 [pool-4-thread-2] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) received from stdout: {"jsonrpc":"2.0","id":"concurrent-2","result":{"echo":"response-concurrent-2"}}
16:31:02.263 [pool-4-thread-5] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) writing to stdin: {"jsonrpc":"2.0","id":"concurrent-7","method":"test/method","params":{"value":7}}
16:31:02.263 [pool-4-thread-2] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) writing to stdin: {"jsonrpc":"2.0","id":"concurrent-6","method":"test/method","params":{"value":6}}
16:31:02.275 [pool-4-thread-1] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) received from stdout: {"jsonrpc":"2.0","id":"concurrent-1","result":{"echo":"response-concurrent-1"}}
16:31:02.275 [pool-4-thread-3] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) received from stdout: {"jsonrpc":"2.0","id":"concurrent-3","result":{"echo":"response-concurrent-3"}}
16:31:02.276 [pool-4-thread-4] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) received from stdout: {"jsonrpc":"2.0","id":"concurrent-4","result":{"echo":"response-concurrent-4"}}
16:31:02.276 [pool-4-thread-1] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) writing to stdin: {"jsonrpc":"2.0","id":"concurrent-8","method":"test/method","params":{"value":8}}
16:31:02.276 [pool-4-thread-3] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) writing to stdin: {"jsonrpc":"2.0","id":"concurrent-9","method":"test/method","params":{"value":9}}
16:31:02.276 [pool-4-thread-4] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) writing to stdin: {"jsonrpc":"2.0","id":"concurrent-10","method":"test/method","params":{"value":10}}
16:31:02.286 [pool-4-thread-5] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) received from stdout: {"jsonrpc":"2.0","id":"concurrent-7","result":{"echo":"response-concurrent-7"}}
16:31:02.286 [pool-4-thread-2] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) received from stdout: {"jsonrpc":"2.0","id":"concurrent-6","result":{"echo":"response-concurrent-6"}}
16:31:02.286 [pool-4-thread-1] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) received from stdout: {"jsonrpc":"2.0","id":"concurrent-8","result":{"echo":"response-concurrent-8"}}
16:31:02.286 [pool-4-thread-3] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) received from stdout: {"jsonrpc":"2.0","id":"concurrent-9","result":{"echo":"response-concurrent-9"}}
16:31:02.286 [pool-4-thread-4] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) received from stdout: {"jsonrpc":"2.0","id":"concurrent-10","result":{"echo":"response-concurrent-10"}}
16:31:02.287 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(echo-server) closing process and streams
[info] - should correctly route responses to concurrent requests
16:31:02.289 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) initialized with command: bash -c while IFS= read -r line; do
           id=$(echo "$line" | grep -o '"id":"[^"]*"' | cut -d'"' -f4)
           if [ -n "$id" ]; then
             echo "{\"jsonrpc\":\"2.0\",\"id\":\"$id\",\"result\":{\"seq\":\"$id\"}}"
           fi
         done
16:31:02.289 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) starting new process: bash -c while IFS= read -r line; do
           id=$(echo "$line" | grep -o '"id":"[^"]*"' | cut -d'"' -f4)
           if [ -n "$id" ]; then
             echo "{\"jsonrpc\":\"2.0\",\"id\":\"$id\",\"result\":{\"seq\":\"$id\"}}"
           fi
         done
16:31:12.364 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) process started and ready
16:31:12.365 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-1","method":"test/method","params":{"index":1}}
16:31:12.375 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-1","result":{"seq":"seq-1"}}
16:31:12.375 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-2","method":"test/method","params":{"index":2}}
16:31:12.387 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-2","result":{"seq":"seq-2"}}
16:31:12.387 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-3","method":"test/method","params":{"index":3}}
16:31:12.399 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-3","result":{"seq":"seq-3"}}
16:31:12.400 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-4","method":"test/method","params":{"index":4}}
16:31:12.411 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-4","result":{"seq":"seq-4"}}
16:31:12.412 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-5","method":"test/method","params":{"index":5}}
16:31:12.421 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-5","result":{"seq":"seq-5"}}
16:31:12.422 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-6","method":"test/method","params":{"index":6}}
16:31:12.434 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-6","result":{"seq":"seq-6"}}
16:31:12.434 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-7","method":"test/method","params":{"index":7}}
16:31:12.445 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-7","result":{"seq":"seq-7"}}
16:31:12.445 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-8","method":"test/method","params":{"index":8}}
16:31:12.457 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-8","result":{"seq":"seq-8"}}
16:31:12.457 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-9","method":"test/method","params":{"index":9}}
16:31:12.470 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-9","result":{"seq":"seq-9"}}
16:31:12.470 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-10","method":"test/method","params":{"index":10}}
16:31:12.482 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-10","result":{"seq":"seq-10"}}
16:31:12.483 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-11","method":"test/method","params":{"index":11}}
16:31:12.495 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-11","result":{"seq":"seq-11"}}
16:31:12.495 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-12","method":"test/method","params":{"index":12}}
16:31:12.508 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-12","result":{"seq":"seq-12"}}
16:31:12.508 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-13","method":"test/method","params":{"index":13}}
16:31:12.520 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-13","result":{"seq":"seq-13"}}
16:31:12.520 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-14","method":"test/method","params":{"index":14}}
16:31:12.533 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-14","result":{"seq":"seq-14"}}
16:31:12.533 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-15","method":"test/method","params":{"index":15}}
16:31:12.543 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-15","result":{"seq":"seq-15"}}
16:31:12.543 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-16","method":"test/method","params":{"index":16}}
16:31:12.553 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-16","result":{"seq":"seq-16"}}
16:31:12.553 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-17","method":"test/method","params":{"index":17}}
16:31:12.564 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-17","result":{"seq":"seq-17"}}
16:31:12.564 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-18","method":"test/method","params":{"index":18}}
16:31:12.574 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-18","result":{"seq":"seq-18"}}
16:31:12.574 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-19","method":"test/method","params":{"index":19}}
16:31:12.587 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-19","result":{"seq":"seq-19"}}
16:31:12.587 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) writing to stdin: {"jsonrpc":"2.0","id":"seq-20","method":"test/method","params":{"index":20}}
16:31:12.599 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) received from stdout: {"jsonrpc":"2.0","id":"seq-20","result":{"seq":"seq-20"}}
16:31:12.600 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(sequential-server) closing process and streams
[info] - should handle rapid sequential requests correctly
16:31:12.601 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) initialized with command: bash -c while IFS= read -r line; do
           id=$(echo "$line" | grep -o '"id":"[^"]*"' | cut -d'"' -f4)
           if [ -n "$id" ]; then
             # Add small random delay to simulate real server processing
             sleep 0.0$((RANDOM % 3))
             echo "{\"jsonrpc\":\"2.0\",\"id\":\"$id\",\"result\":{\"mixed\":\"$id\"}}"
           fi
         done
16:31:12.601 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) starting new process: bash -c while IFS= read -r line; do
           id=$(echo "$line" | grep -o '"id":"[^"]*"' | cut -d'"' -f4)
           if [ -n "$id" ]; then
             # Add small random delay to simulate real server processing
             sleep 0.0$((RANDOM % 3))
             echo "{\"jsonrpc\":\"2.0\",\"id\":\"$id\",\"result\":{\"mixed\":\"$id\"}}"
           fi
         done
16:31:22.617 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) process started and ready
16:31:22.618 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) writing to stdin: {"jsonrpc":"2.0","id":"warmup","method":"test/warmup"}
16:31:22.641 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) received from stdout: {"jsonrpc":"2.0","id":"warmup","result":{"mixed":"warmup"}}
16:31:22.643 [pool-5-thread-3] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) writing to stdin: {"jsonrpc":"2.0","id":"mixed-3","method":"test/method","params":{"wave":3}}
16:31:22.643 [pool-5-thread-1] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) writing to stdin: {"jsonrpc":"2.0","id":"mixed-1","method":"test/method","params":{"wave":1}}
16:31:22.643 [pool-5-thread-2] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) writing to stdin: {"jsonrpc":"2.0","id":"mixed-2","method":"test/method","params":{"wave":2}}
16:31:22.653 [pool-5-thread-3] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) received from stdout: {"jsonrpc":"2.0","id":"mixed-3","result":{"mixed":"mixed-3"}}
16:31:22.654 [pool-5-thread-3] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) writing to stdin: {"jsonrpc":"2.0","id":"mixed-4","method":"test/method","params":{"wave":4}}
16:31:22.691 [pool-5-thread-1] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) received from stdout: {"jsonrpc":"2.0","id":"mixed-1","result":{"mixed":"mixed-1"}}
16:31:22.691 [pool-5-thread-1] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) writing to stdin: {"jsonrpc":"2.0","id":"mixed-5","method":"test/method","params":{"wave":5}}
16:31:22.704 [pool-5-thread-2] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) received from stdout: {"jsonrpc":"2.0","id":"mixed-2","result":{"mixed":"mixed-2"}}
16:31:22.716 [pool-5-thread-3] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) received from stdout: {"jsonrpc":"2.0","id":"mixed-4","result":{"mixed":"mixed-4"}}
16:31:22.716 [pool-5-thread-2] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) writing to stdin: {"jsonrpc":"2.0","id":"mixed-6","method":"test/method","params":{"wave":6}}
16:31:22.741 [pool-5-thread-3] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) writing to stdin: {"jsonrpc":"2.0","id":"mixed-7","method":"test/method","params":{"wave":7}}
16:31:22.751 [pool-5-thread-1] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) received from stdout: {"jsonrpc":"2.0","id":"mixed-5","result":{"mixed":"mixed-5"}}
16:31:22.764 [pool-5-thread-2] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) received from stdout: {"jsonrpc":"2.0","id":"mixed-6","result":{"mixed":"mixed-6"}}
16:31:22.786 [pool-5-thread-3] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) received from stdout: {"jsonrpc":"2.0","id":"mixed-7","result":{"mixed":"mixed-7"}}
16:31:22.786 [pool-5-thread-1] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) writing to stdin: {"jsonrpc":"2.0","id":"mixed-8","method":"test/method","params":{"wave":8}}
16:31:22.809 [pool-5-thread-2] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) writing to stdin: {"jsonrpc":"2.0","id":"mixed-9","method":"test/method","params":{"wave":9}}
16:31:22.809 [pool-5-thread-1] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) received from stdout: {"jsonrpc":"2.0","id":"mixed-8","result":{"mixed":"mixed-8"}}
16:31:22.836 [pool-5-thread-3] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) writing to stdin: {"jsonrpc":"2.0","id":"mixed-10","method":"test/method","params":{"wave":10}}
16:31:22.841 [pool-5-thread-2] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) received from stdout: {"jsonrpc":"2.0","id":"mixed-9","result":{"mixed":"mixed-9"}}
16:31:22.871 [pool-5-thread-1] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) writing to stdin: {"jsonrpc":"2.0","id":"mixed-11","method":"test/method","params":{"wave":11}}
16:31:22.879 [pool-5-thread-3] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) received from stdout: {"jsonrpc":"2.0","id":"mixed-10","result":{"mixed":"mixed-10"}}
16:31:22.879 [pool-5-thread-1] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) received from stdout: {"jsonrpc":"2.0","id":"mixed-11","result":{"mixed":"mixed-11"}}
16:31:22.916 [pool-5-thread-2] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) writing to stdin: {"jsonrpc":"2.0","id":"mixed-12","method":"test/method","params":{"wave":12}}
16:31:22.960 [pool-5-thread-2] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) received from stdout: {"jsonrpc":"2.0","id":"mixed-12","result":{"mixed":"mixed-12"}}
16:31:22.964 [pool-5-thread-3] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) writing to stdin: {"jsonrpc":"2.0","id":"mixed-13","method":"test/method","params":{"wave":13}}
16:31:22.969 [pool-5-thread-1] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) writing to stdin: {"jsonrpc":"2.0","id":"mixed-14","method":"test/method","params":{"wave":14}}
16:31:23.008 [pool-5-thread-3] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) received from stdout: {"jsonrpc":"2.0","id":"mixed-13","result":{"mixed":"mixed-13"}}
16:31:23.019 [pool-5-thread-1] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) received from stdout: {"jsonrpc":"2.0","id":"mixed-14","result":{"mixed":"mixed-14"}}
16:31:23.061 [pool-5-thread-2] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) writing to stdin: {"jsonrpc":"2.0","id":"mixed-15","method":"test/method","params":{"wave":15}}
16:31:23.102 [pool-5-thread-2] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) received from stdout: {"jsonrpc":"2.0","id":"mixed-15","result":{"mixed":"mixed-15"}}
16:31:23.103 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(mixed-server) closing process and streams
[info] - should handle mixed concurrent and sequential requests
16:31:23.105 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(notification-server) initialized with command: bash -c while IFS= read -r line; do
           id=$(echo "$line" | grep -o '"id":"[^"]*"' | cut -d'"' -f4)
           if [ -n "$id" ]; then
             echo "{\"jsonrpc\":\"2.0\",\"id\":\"$id\",\"result\":{\"ok\":true}}"
           fi
           # Notifications (no id) are silently accepted
         done
16:31:23.106 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(notification-server) starting new process: bash -c while IFS= read -r line; do
           id=$(echo "$line" | grep -o '"id":"[^"]*"' | cut -d'"' -f4)
           if [ -n "$id" ]; then
             echo "{\"jsonrpc\":\"2.0\",\"id\":\"$id\",\"result\":{\"ok\":true}}"
           fi
           # Notifications (no id) are silently accepted
         done
16:31:33.212 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(notification-server) process started and ready
16:31:33.214 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(notification-server) writing notification to stdin: {"jsonrpc":"2.0","method":"test/notify","params":{"event":"test"}}
16:31:33.214 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(notification-server) writing to stdin: {"jsonrpc":"2.0","id":"after-notify","method":"test/method"}
16:31:33.237 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(notification-server) received from stdout: {"jsonrpc":"2.0","id":"after-notify","result":{"ok":true}}
16:31:33.237 [pool-1-thread-1-ScalaTest-running-StdioTransportConcurrencySpec] INFO  org.llm4s.mcp.StdioTransportImpl -- StdioTransport(notification-server) closing process and streams
[info] - should correctly handle notifications (which don't expect responses)
16:31:33.241 [pool-1-thread-1-ScalaTest-running-ModelSelectorSpec] INFO  o.l.llmconnect.utils.ModelSelector$ -- [ModelSelector] Image model: openclip-vit-b32 (512 dims)
[info] ModelSelectorSpec:
[info] - selectModel returns error for Text modality
16:31:33.241 [pool-1-thread-1-ScalaTest-running-ModelSelectorSpec] INFO  o.l.llmconnect.utils.ModelSelector$ -- [ModelSelector] Audio model: wav2vec2-base (768 dims)
[info] - selectModel returns config for Image modality
[info] - selectModel returns config for Audio modality
16:31:33.241 [pool-1-thread-1-ScalaTest-running-ModelSelectorSpec] INFO  o.l.llmconnect.utils.ModelSelector$ -- [ModelSelector] Video model: timesformer-base (768 dims)
[info] - selectModel returns config for Video modality
[info] VectorStoreExtendedSpec:
[info] VectorStore.deleteByPrefix
[info] - should delete records matching prefix
[info] - should return 0 when no records match prefix
[info] - should handle empty store
[info] - should handle empty prefix (delete all)
[info] VectorStore.deleteByFilter
[info] - should delete records matching Equals filter
[info] - should delete records matching And filter
[info] - should delete records matching Or filter
[info] - should return 0 when no records match
[info] VectorStore.getBatch
[info] - should retrieve multiple records by IDs
[info] - should skip non-existent IDs
[info] - should return empty for all non-existent IDs
[info] - should handle empty ID list
[info] MetadataFilter.Contains
[info] - should match records containing substring
[info] MetadataFilter.HasKey
[info] - should match records that have the specified key
[info] MetadataFilter.In
[info] - should be expressible using Or filter as fallback
[info] MetadataFilter.Not
[info] - should negate a filter condition
[info] MetadataFilter.All
[info] - should match all records
[info] VectorRecord
[info] - should consider two records equal if same ID and embedding
[info] - should consider records not equal with different embeddings
[info] - should consider records not equal with different IDs
[info] - should report correct dimensions
[info] ScoredRecord
[info] - should validate score is between 0 and 1
[info] - should order by score descending
[info] VectorStoreStats
[info] - should report isEmpty correctly
[info] - should format size correctly
[info] VectorStore
[info] - should handle records with empty content
[info] - should handle records with empty metadata
[info] - should handle special characters in metadata
[info] - should handle single-element embedding
[info] - should handle large batch operations
[info] HtmlContentExtractorSpec:
[info] HtmlContentExtractor.extract
[info] - should extract title from title tag
[info] - should fall back to h1 if no title tag
[info] - should extract meta description
[info] - should extract og:description as fallback
[info] - should extract links from anchor tags
[info] - should filter out non-http links
[info] - should remove navigation elements from content
[info] - should remove script and style elements
[info] - should extract text from main content area
[info] - should handle empty HTML
[info] HtmlContentExtractor.extractLinksOnly
[info] - should extract links without processing content
[info] Llm4sConfigEmbeddingsChunkingSpec:
[info] Llm4sConfig.embeddingsChunking
[info] - should fall back to defaults when no chunking config is provided
[info] - should respect llm4s.embeddings.chunking overrides
[info] DAGSpec:
[info] Node
[info] - should be created with proper agent wrapping
[info] Edge
[info] - should connect nodes with type safety at compile time
[info] Plan.empty
[info] - should create an empty plan
[info] Plan.builder
[info] - should build a valid linear plan
[info] Plan.validate
[info] - should detect valid DAG
[info] Plan.validate
[info] - should detect cycles
[info] Plan.topologicalOrder
[info] - should return correct execution order
[info] Plan.getParallelBatches
[info] - should identify independent nodes
[info] Plan with disconnected components
[info] - should handle multiple entry points
[info] ModelRegistrySpec:
[info] ModelRegistry
16:31:33.313 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry reset
16:31:33.313 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Initializing ModelRegistry with embedded metadata
16:31:33.326 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry initialized with 1754 models
16:31:33.326 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry reset
[info] - should initialize successfully
16:31:33.326 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Initializing ModelRegistry with embedded metadata
16:31:33.336 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry initialized with 1754 models
16:31:33.336 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry reset
[info] - should lookup models by exact ID
16:31:33.337 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Initializing ModelRegistry with embedded metadata
16:31:33.345 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry initialized with 1754 models
16:31:33.345 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry reset
[info] - should lookup models case-insensitively
16:31:33.345 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Initializing ModelRegistry with embedded metadata
16:31:33.353 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry initialized with 1754 models
[info] - should lookup models with provider prefix
16:31:33.354 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry reset
16:31:33.354 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Initializing ModelRegistry with embedded metadata
16:31:33.361 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry initialized with 1754 models
16:31:33.362 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry reset
16:31:33.362 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Initializing ModelRegistry with embedded metadata
[info] - should lookup models by provider and name
16:31:33.369 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry initialized with 1754 models
16:31:33.370 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry reset
[info] - should return error for unknown model
16:31:33.370 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Initializing ModelRegistry with embedded metadata
16:31:33.377 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry initialized with 1754 models
[info] - should list models by provider
16:31:33.378 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry reset
16:31:33.378 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Initializing ModelRegistry with embedded metadata
16:31:33.386 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry initialized with 1754 models
16:31:33.387 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry reset
[info] - should list models by mode
16:31:33.387 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Initializing ModelRegistry with embedded metadata
16:31:33.394 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry initialized with 1754 models
16:31:33.395 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry reset
16:31:33.395 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Initializing ModelRegistry with embedded metadata
[info] - should find models by capability
16:31:33.403 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry initialized with 1754 models
16:31:33.404 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry reset
[info] - should list all providers
16:31:33.404 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Initializing ModelRegistry with embedded metadata
16:31:33.411 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry initialized with 1754 models
16:31:33.411 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Registered custom model: custom-model-123
16:31:33.411 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry reset
[info] - should register custom models
16:31:33.411 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Initializing ModelRegistry with embedded metadata
16:31:33.418 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry initialized with 1754 models
16:31:33.418 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Registered custom model: gpt-4o
[info] - should allow custom models to override embedded models
16:31:33.418 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry reset
16:31:33.418 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Initializing ModelRegistry with embedded metadata
16:31:33.425 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry initialized with 1754 models
[info] - should provide statistics
16:31:33.427 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry reset
16:31:33.427 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Initializing ModelRegistry with embedded metadata
16:31:33.437 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry initialized with 1754 models
16:31:33.437 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Registered 2 custom models
[info] - should register multiple custom models
16:31:33.437 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry reset
16:31:33.437 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Initializing ModelRegistry with embedded metadata
16:31:33.447 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry initialized with 1754 models
16:31:33.447 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Registered custom model: my-unique-test-model-xyz
[info] - should handle fuzzy matching
16:31:33.447 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry reset
16:31:33.448 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Initializing ModelRegistry with embedded metadata
16:31:33.455 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry initialized with 1754 models
16:31:33.455 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Registered 2 custom models
16:31:33.455 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry reset
[info] - should return error for ambiguous fuzzy matches
16:31:33.455 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Initializing ModelRegistry with embedded metadata
16:31:33.462 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- ModelRegistry initialized with 1754 models
16:31:33.462 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Loading custom model metadata from JSON string
16:31:33.463 [pool-1-thread-1-ScalaTest-running-ModelRegistrySpec] INFO  org.llm4s.model.ModelRegistry$ -- Loaded 1 custom models
[info] - should load custom metadata from JSON string
[info] VectorOpsSpec:
[info] VectorOps.cosineSimilarity
[info] - should return 1.0 for identical vectors
[info] - should return -1.0 for opposite vectors
[info] - should return 0.0 for orthogonal vectors
[info] VectorOps.euclideanDistance
[info] - should return 0.0 for identical vectors
[info] - should calculate correct distance
[info] VectorOps.normalize
[info] - should create unit vector
[info] VectorOps.topKBySimilarity
[info] - should return top-K most similar items
[info] LLMClientFactoryTest:
[info] - LLMConnect.getClientResult returns OpenAIClient for openai/ prefix with API key
[info] - LLMConnect.getClientResult returns AnthropicClient for anthropic/ prefix with API key
[info] UrlNormalizerSpec:
[info] UrlNormalizer.normalize
[info] - should lowercase scheme and host
[info] - should remove fragments
[info] - should remove trailing slashes from non-root paths
[info] - should strip query params by default
[info] - should keep query params when configured
[info] - should remove default ports
[info] - should keep non-default ports
[info] - should collapse multiple slashes in path
[info] - should preserve encoded path segments
[info] - should handle empty path
[info] - should return original URL on parse error
[info] UrlNormalizer.resolve
[info] - should resolve relative URLs
[info] - should handle absolute URLs
[info] - should handle protocol-relative URLs
[info] - should return None for malformed base URLs
[info] UrlNormalizer.extractDomain
[info] - should extract domain from URL
[info] - should return None for invalid URLs
[info] UrlNormalizer.isInDomains
[info] - should match exact domains
[info] - should match subdomains
[info] - should not match partial domain names
[info] UrlNormalizer.isValidHttpUrl
[info] - should validate HTTP/HTTPS URLs
[info] PlanRunnerSpec:
[info] PlanRunner
16:31:33.482 [pool-1-thread-1-ScalaTest-running-PlanRunnerSpec] INFO  o.l.agent.orchestration.PlanRunner -- Starting plan execution with 2 nodes and 1 edges
16:31:33.483 [scala-execution-context-global-77] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed successfully with 2 results
16:31:33.483 [scala-execution-context-global-77] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed
[info] - should execute a simple linear plan successfully
[info] PlanRunner
16:31:33.483 [pool-1-thread-1-ScalaTest-running-PlanRunnerSpec] INFO  o.l.agent.orchestration.PlanRunner -- Starting plan execution with 2 nodes and 0 edges
16:31:33.483 [scala-execution-context-global-77] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed successfully with 2 results
16:31:33.483 [scala-execution-context-global-77] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed
[info] - should handle parallel execution
[info] PlanRunner
16:31:33.484 [pool-1-thread-1-ScalaTest-running-PlanRunnerSpec] INFO  o.l.agent.orchestration.PlanRunner -- Starting plan execution with 2 nodes and 2 edges
16:31:33.484 [pool-1-thread-1-ScalaTest-running-PlanRunnerSpec] ERROR o.l.agent.orchestration.PlanRunner -- Plan validation failed: Plan contains cycles
16:31:33.484 [scala-execution-context-global-77] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed
[info] - should handle plan validation errors
16:31:33.484 [pool-1-thread-1-ScalaTest-running-PlanRunnerSpec] INFO  o.l.agent.orchestration.PlanRunner -- Starting plan execution with 2 nodes and 1 edges
[info] PlanRunner
16:31:33.484 [scala-execution-context-global-77] ERROR o.l.agent.orchestration.PlanRunner -- Batch 1 had 1 failures
16:31:33.485 [scala-execution-context-global-77] ERROR o.l.agent.orchestration.PlanRunner -- Plan execution failed: NodeExecutionError(Node execution failed [test-node:failing-agent]: Simulated failure,test-node,failing-agent,None,true)
16:31:33.485 [scala-execution-context-global-77] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed
[info] - should handle node execution failures
16:31:33.485 [pool-1-thread-1-ScalaTest-running-PlanRunnerSpec] INFO  o.l.agent.orchestration.PlanRunner -- Starting plan execution with 1 nodes and 0 edges
[info] PlanRunner
16:31:33.485 [pool-1-thread-1-ScalaTest-running-PlanRunnerSpec] ERROR o.l.agent.orchestration.PlanRunner -- No input available for node
16:31:33.485 [scala-execution-context-global-77] ERROR o.l.agent.orchestration.PlanRunner -- Batch 1 had 1 failures
16:31:33.485 [scala-execution-context-global-234] ERROR o.l.agent.orchestration.PlanRunner -- Plan execution failed: NodeExecutionError(Node execution failed [processor:processor]: No input available for node execution,processor,processor,None,true)
16:31:33.485 [scala-execution-context-global-234] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed
[info] - should handle missing inputs gracefully
[info] PlanRunner
16:31:33.485 [pool-1-thread-1-ScalaTest-running-PlanRunnerSpec] INFO  o.l.agent.orchestration.PlanRunner -- Starting plan execution with 4 nodes and 3 edges
16:31:33.486 [scala-execution-context-global-236] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed successfully with 4 results
16:31:33.486 [scala-execution-context-global-236] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed
[info] - should execute diamond-shaped DAG correctly
16:31:33.486 [pool-1-thread-1-ScalaTest-running-PlanRunnerSpec] INFO  o.l.agent.orchestration.PlanRunner -- Starting plan execution with 1 nodes and 0 edges
[info] PlanRunner
16:31:33.588 [scala-execution-context-global-236] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed successfully with 1 results
16:31:33.588 [scala-execution-context-global-236] INFO  o.l.agent.orchestration.PlanRunner -- Plan execution completed
[info] - should handle slow agents gracefully
[info] EmbeddingClientFactorySpec:
[info] EmbeddingClient.from(provider,cfg)
[info] - should build client for openai without throwing
[info] - should build client for voyage without throwing
[info] - should build client for ollama without throwing
[info] - should build client for ollama with empty apiKey
[info] - should reject unknown provider
[info] MCPToolRegistryHealthCheckSpec:
[info] healthCheck
16:31:33.593 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryHealthCheckSpec] INFO  o.l.m.MCPToolRegistryHealthCheckSpec$TestRegistry -- Initializing MCPToolRegistry with 2 MCP servers and 0 local tools
16:31:33.593 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryHealthCheckSpec] INFO  o.l.m.MCPToolRegistryHealthCheckSpec$TestRegistry -- Performing health check on all MCP servers
16:31:33.593 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryHealthCheckSpec] INFO  o.l.m.MCPToolRegistryHealthCheckSpec$TestRegistry -- Health check completed: 2/2 servers healthy
[info] - should mark all servers healthy when initialization succeeds
16:31:33.593 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryHealthCheckSpec] INFO  o.l.m.MCPToolRegistryHealthCheckSpec$TestRegistry -- Initializing MCPToolRegistry with 2 MCP servers and 0 local tools
16:31:33.593 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryHealthCheckSpec] INFO  o.l.m.MCPToolRegistryHealthCheckSpec$TestRegistry -- Performing health check on all MCP servers
16:31:33.593 [pool-1-thread-1-ScalaTest-running-MCPToolRegistryHealthCheckSpec] INFO  o.l.m.MCPToolRegistryHealthCheckSpec$TestRegistry -- Health check completed: 1/2 servers healthy
[info] - should flag servers as unhealthy when initialization fails
[info] ToolExecutionStrategySpec:
[info] ToolExecutionStrategy.Sequential
[info] - should be a valid strategy
[info] ToolExecutionStrategy.Parallel
[info] - should be a valid strategy
[info] ToolExecutionStrategy.ParallelWithLimit
[info] - should accept positive concurrency limit
[info] - should accept concurrency limit of 1
[info] - should reject zero concurrency limit
[info] - should reject negative concurrency limit
[info] ToolExecutionStrategy.default
[info] - should be Sequential
[info] ToolExecutionStrategy
[info] - should support exhaustive pattern matching
[info] UniversalExtractorSpec:
16:31:33.597 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/test-7186252857649675915.txt (MIME: text/plain)
[info] - extract should read plain text files
16:31:33.598 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/test-2794274629173082882.txt (MIME: text/plain)
[info] - extract should handle file paths with quotes
16:31:33.598 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] ERROR o.l.l.extractors.UniversalExtractor$ -- [FileNotFound] File not found or invalid: /nonexistent/path/file.txt (exists=false, isFile=false, isDir=false)
[info] - extract should return error for non-existent file
16:31:33.598 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/test-6600140877905882998.txt (MIME: text/plain)
[info] - extract should handle empty file
16:31:33.599 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/test-5252398496867844667.txt (MIME: text/plain)
[info] - extract should handle UTF-8 content
16:31:33.600 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/test-3373525508167511303.json (MIME: application/json)
16:31:33.600 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] ERROR o.l.l.extractors.UniversalExtractor$ -- [UnknownType] No text extractor for MIME type: application/json
[info] - extract uses Tika fallback for JSON files
[info] - isTextLike should return true for text MIME types
[info] - isTextLike should return true for application/json
[info] - isTextLike should return true for application/xml
[info] - isTextLike should return true for PDF
[info] - isTextLike should return true for DOCX
[info] - isTextLike should return false for binary MIME types
16:31:33.601 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [ExtractAny] Processing: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/test-7764695093789026274.txt (MIME: text/plain)
16:31:33.602 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] ERROR o.l.l.extractors.UniversalExtractor$ -- [FileNotFound] File not found: /nonexistent/path/file.txt
[info] - extractAny should return TextContent for text files
[info] - extractAny should return error for non-existent file
16:31:33.603 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/test-1391682482284221654.txt (MIME: text/plain)
[info] - extract should handle single-quoted paths
16:31:33.604 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [Extract] Processing file: /var/folders/gc/fw85bzms2bn583tb98_nbxp40000gn/T/test-3897654265542718244.txt (MIME: text/plain)
[info] - extract should trim whitespace from paths
16:31:33.604 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [ExtractFromBytes] Processing: test.txt (MIME: text/plain)
[info] - extractFromBytes should extract plain text from bytes
16:31:33.605 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [ExtractFromBytes] Processing: unicode.txt (MIME: text/plain)
[info] - extractFromBytes should extract UTF-8 content
16:31:33.605 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [ExtractFromBytes] Processing: empty.txt (MIME: text/plain)
[info] - extractFromBytes should handle empty content
16:31:33.605 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [ExtractFromBytes] Processing: data.json (MIME: application/json)
16:31:33.605 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] ERROR o.l.l.extractors.UniversalExtractor$ -- [UnknownType] No text extractor for MIME type: application/json
[info] - extractFromBytes should detect MIME type from filename
[info] - extractFromBytes should use provided MIME type override
16:31:33.605 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [ExtractFromBytes] Processing: unknown.xyz (MIME: text/plain)
16:31:33.606 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [ExtractFromBytes] Processing: test.txt (MIME: text/plain)
[info] - extractFromStream should extract text from stream
16:31:33.606 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [ExtractFromBytes] Processing: russian.txt (MIME: text/plain)
[info] - extractFromStream should handle UTF-8 content
16:31:33.606 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [ExtractFromBytes] Processing: empty.txt (MIME: text/plain)
16:31:33.606 [pool-1-thread-1-ScalaTest-running-UniversalExtractorSpec] INFO  o.l.l.extractors.UniversalExtractor$ -- [ExtractFromBytes] Processing: page.html (MIME: text/html)
[info] - extractFromStream should handle empty stream
[info] - extractFromStream should use provided MIME type
[info] - detectMimeType should detect text/plain from .txt extension
[info] - detectMimeType should detect PDF from magic bytes
[info] - detectMimeType should detect JSON from extension
[info] - detectMimeType should detect HTML from extension
[info] - detectMimeType should handle unknown extension
[info] Llm4sConfigEmbeddingsSpec:
[info] Llm4sConfig.embeddings
[info] - should load OpenAI embeddings config via llm4s.*
[info] - should load VoyageAI embeddings config via llm4s.*
[info] - should load OpenAI embeddings via unified EMBEDDING_MODEL format
[info] - should load Voyage embeddings via unified EMBEDDING_MODEL format
[info] - should load Ollama embeddings via unified EMBEDDING_MODEL format
[info] - should prefer unified model format over legacy provider
[info] - should allow custom base URL with unified format
[info] - should reject invalid embedding model format
[info] - should reject unknown embedding provider in unified format
[info] Llm4sConfig.localEmbeddingModels
[info] - should load local model names via llm4s.*
[info] - should have defaults declared in reference.conf
[info] Run completed in 2 minutes, 25 seconds.
[info] Total number of tests run: 2719
[info] Suites: completed 173, aborted 0
[info] Tests: succeeded 2719, failed 0, canceled 22, ignored 0, pending 0
[info] All tests passed.
[success] Total time: 165 s (0:02:45.0), completed Jan 27, 2026, 4:31:34 PM
