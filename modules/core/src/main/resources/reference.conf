# Unified llm4s configuration namespace
llm4s {
  # Primary model selection, e.g. "openai/gpt-4o", "anthropic/claude-3-7-sonnet-latest", "ollama/llama3.1"
  llm {
    model = ${?LLM_MODEL}
  }

  # OpenAI (also used for OpenRouter via base-url)
  openai {
    # Safe default; can be overridden by env or -D
    base-url = "https://api.openai.com/v1"
    base-url = ${?OPENAI_BASE_URL}
    api-key  = ${?OPENAI_API_KEY}
    organization = ${?OPENAI_ORGANIZATION}
  }

  # Azure OpenAI
  azure {
    endpoint    = ${?AZURE_API_BASE}
    api-key     = ${?AZURE_API_KEY}
    api-version = ${?AZURE_API_VERSION}
  }

  # Anthropic
  anthropic {
    base-url = "https://api.anthropic.com"
    base-url = ${?ANTHROPIC_BASE_URL}
    api-key  = ${?ANTHROPIC_API_KEY}
  }

  # Ollama (local models)
  ollama {
    base-url = ${?OLLAMA_BASE_URL}
  }

  # Tracing: Langfuse (app/runners may use these)
  tracing {
    # Tracing mode: langfuse | console | noop
    mode = "console"
    mode = ${?TRACING_MODE}
    langfuse {
      url        = ${?LANGFUSE_URL}
      public-key = ${?LANGFUSE_PUBLIC_KEY}
      secret-key = ${?LANGFUSE_SECRET_KEY}
      env        = ${?LANGFUSE_ENV}
      release    = ${?LANGFUSE_RELEASE}
      version    = ${?LANGFUSE_VERSION}
    }
  }

  # Embeddings configuration
  embeddings {
    provider   = ${?EMBEDDING_PROVIDER}
    input-path = ${?EMBEDDING_INPUT_PATH}
    query      = ${?EMBEDDING_QUERY}

    openai {
      base-url = ${?OPENAI_EMBEDDING_BASE_URL}
      model    = ${?OPENAI_EMBEDDING_MODEL}
    }

    voyage {
      api-key  = ${?VOYAGE_API_KEY}
      base-url = ${?VOYAGE_EMBEDDING_BASE_URL}
      model    = ${?VOYAGE_EMBEDDING_MODEL}
    }

    chunking {
      size    = ${?CHUNK_SIZE}
      overlap = ${?CHUNK_OVERLAP}
      enabled = ${?CHUNKING_ENABLED}
    }
  }

  # Runner-only convenience (apps may use):
  workspace {
    path = ${?WORKSPACE_PATH}
  }
}
